{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Projet 7 - Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926103421
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import os\n",
    "script_folder = os.path.join(os.getcwd(), \"source_dir\")\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926106137
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Workspace, Dataset\n",
    "\n",
    "subscription_id = 'your_subscription_ID'\n",
    "resource_group = 'OC-P7'\n",
    "workspace_name = 'P7_ML'\n",
    "\n",
    "ws = Workspace(subscription_id, resource_group, workspace_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Dummy entry script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/batch/tasks/shared/LS_root/mounts/clusters/oc-p7-ml-ds3/code/Users/yann.hereng.openclassrooms/source_dir/echo_score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/echo_score.py\n",
    "\n",
    "import json\n",
    "\n",
    "def init():\n",
    "    print('This is init')\n",
    "\n",
    "def run(data):\n",
    "    test = json.loads(data)\n",
    "    print(f'received data {test}')\n",
    "    return(f'test is {test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Local deployment for test and debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Inference configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926111122
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Environment\n",
    "from azureml.core.model import InferenceConfig\n",
    "\n",
    "env = Environment(name='project_environment')\n",
    "inf_config = InferenceConfig(environment=env, source_directory='./source_dir', entry_script='./echo_score.py')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Deployment configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926112466
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import LocalWebservice\n",
    "\n",
    "deploy_config = LocalWebservice.deploy_configuration(port=6789)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Local Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926119523
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.model import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926120648
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "model = Model(workspace=ws,name='LSTM_Glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620815559081
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model LSTM_Glove:1 to /tmp/azureml_vb57cpvm/LSTM_Glove/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7d83ef11f069>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mazureml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeploy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mws\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"myservice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0minf_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeploy_config\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_for_deployment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mservice\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36mdeploy\u001b[0;34m(workspace, name, models, inference_config, deployment_config, deployment_target, overwrite, show_output)\u001b[0m\n\u001b[1;32m   1642\u001b[0m         \u001b[0;31m# Local webservice.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1643\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdeployment_config\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdeployment_config\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLocalWebserviceDeploymentConfiguration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1644\u001b[0;31m             return deployment_config._webservice_type._deploy(workspace, name, models,\n\u001b[0m\u001b[1;32m   1645\u001b[0m                                                               \u001b[0minference_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1646\u001b[0m                                                               deployment_config=deployment_config)\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36m_deploy\u001b[0;34m(workspace, name, models, image_config, deployment_config, wait, inference_config)\u001b[0m\n\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m         \u001b[0mservice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalWebservice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworkspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmust_exist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 739\u001b[0;31m         service.update(models=models,\n\u001b[0m\u001b[1;32m    740\u001b[0m                        \u001b[0mimage_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    741\u001b[0m                        \u001b[0minference_config\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minference_config\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     70\u001b[0m                 raise WebserviceException('Cannot call {}() when service is {}.'.format(func.__name__, self.state),\n\u001b[1;32m     71\u001b[0m                                           logger=module_logger)\n\u001b[0;32m---> 72\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, models, image_config, deployment_config, wait, inference_config)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;31m# Apply the changes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 546\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_collect_models\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    547\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_docker_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/webservice/local.py\u001b[0m in \u001b[0;36m_collect_models\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    659\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Downloading model {} to {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 661\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    662\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \u001b[0;31m# If single-model deployment, set the model path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36mdownload\u001b[0;34m(self, target_dir, exist_ok, exists_ok)\u001b[0m\n\u001b[1;32m   1014\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1015\u001b[0m         \u001b[0;31m# download files using sas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1016\u001b[0;31m         \u001b[0mfile_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_download_model_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msas_to_relative_download_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1017\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1018\u001b[0m             raise WebserviceException(\"Illegal state. Unpack={}, Paths in target_dir is \"\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/core/model.py\u001b[0m in \u001b[0;36m_download_model_files\u001b[0;34m(self, sas_to_relative_download_path, target_dir, exist_ok)\u001b[0m\n\u001b[1;32m    955\u001b[0m                                           \"{}\".format(target_path), logger=module_logger)\n\u001b[1;32m    956\u001b[0m             \u001b[0msas_to_relative_download_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msas\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 957\u001b[0;31m             \u001b[0mdownload_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    958\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_file_utils/file_utils.py\u001b[0m in \u001b[0;36mdownload_file\u001b[0;34m(source_uri, path, max_retries, stream, protocol, session, _validate_check_sum, max_concurrency)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mAzureMLException\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_with_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mazureml_error\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_retry\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexec_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_retries\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_retries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m     \u001b[0;31m# download using requests.Session\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_file_utils/file_utils.py\u001b[0m in \u001b[0;36m_retry\u001b[0;34m(exec_func, clean_up_func, max_retries, exceptions)\u001b[0m\n\u001b[1;32m    435\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmax_retries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mexec_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mexceptions\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrequest_exception\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0mretries\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_file_utils/file_utils.py\u001b[0m in \u001b[0;36mexec_func\u001b[0;34m()\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mexec_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m             metadata_dict = blob_service.get_blob_to_path(container_name=container_name,\n\u001b[0m\u001b[1;32m    212\u001b[0m                                                           \u001b[0mblob_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mblob_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m                                                           \u001b[0mfile_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_vendor/azure_storage/blob/baseblobservice.py\u001b[0m in \u001b[0;36mget_blob_to_path\u001b[0;34m(self, container_name, blob_name, file_path, open_mode, snapshot, start_range, end_range, validate_content, progress_callback, max_connections, lease_id, if_modified_since, if_unmodified_since, if_match, if_none_match, timeout)\u001b[0m\n\u001b[1;32m   1855\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1856\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen_mode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1857\u001b[0;31m             blob = self.get_blob_to_stream(\n\u001b[0m\u001b[1;32m   1858\u001b[0m                 \u001b[0mcontainer_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1859\u001b[0m                 \u001b[0mblob_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_vendor/azure_storage/blob/baseblobservice.py\u001b[0m in \u001b[0;36mget_blob_to_stream\u001b[0;34m(self, container_name, blob_name, stream, snapshot, start_range, end_range, validate_content, progress_callback, max_connections, lease_id, if_modified_since, if_unmodified_since, if_match, if_none_match, timeout)\u001b[0m\n\u001b[1;32m   2066\u001b[0m                 \u001b[0mend_blob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblob_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_range\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2067\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2068\u001b[0;31m             _download_blob_chunks(\n\u001b[0m\u001b[1;32m   2069\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2070\u001b[0m                 \u001b[0mcontainer_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/_vendor/azure_storage/blob/_download_chunking.py\u001b[0m in \u001b[0;36m_download_blob_chunks\u001b[0;34m(blob_service, container_name, blob_name, snapshot, download_size, block_size, progress, start_range, end_range, stream, max_connections, progress_callback, validate_content, lease_id, if_modified_since, if_unmodified_since, if_match, if_none_match, timeout, operation_context)\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0;32mimport\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mexecutor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconcurrent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfutures\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mThreadPoolExecutor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_connections\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexecutor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chunk_offsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdownloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_chunk_offsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult_iterator\u001b[0;34m()\u001b[0m\n\u001b[1;32m    609\u001b[0m                     \u001b[0;31m# Careful not to keep a reference to the popped future\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mfs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_time\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    432\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "service = Model.deploy(ws, \"myservice\", [model] , inf_config, deploy_config)\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926124065
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Test with a query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620815644522
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test is {'query': 'What color is the fox', 'context': 'The quick brown fox jumped over the lazy dog.'}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "uri = service.scoring_uri\n",
    "requests.get('http://localhost:6789')\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "data = {\"query\": \"What color is the fox\", \"context\": \"The quick brown fox jumped over the lazy dog.\"}\n",
    "data = json.dumps(data)\n",
    "response = requests.post(uri, data=data, headers=headers)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "# Final entry script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting /mnt/batch/tasks/shared/LS_root/mounts/clusters/oc-p7-ml-ds3/code/Users/yann.hereng.openclassrooms/source_dir/score.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile $script_folder/score.py\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import keras\n",
    "import nltk\n",
    "\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from azureml.core.model import Model\n",
    "\n",
    "\n",
    "import json\n",
    "\n",
    "def init():\n",
    "    print('***************This is init************************************')\n",
    "    global model # variable needs to be global to be used in run()\n",
    "    model = keras.models.load_model(Model.get_model_path('LSTM_Glove'))\n",
    "\n",
    "def run(request):\n",
    "    #Load data\n",
    "    print(request)    \n",
    "    data_request = pd.read_json(request)\n",
    "    X=tokenizer(data_request['text']).str.join(sep=' ')\n",
    "\n",
    "    #Run inference\n",
    "    y_pred = model.predict(X)\n",
    "    print(y_pred)\n",
    "    return (y_pred.tolist()) # the object returned needs to be serialisable\n",
    "\n",
    "def tokenizer(data, y = None):\n",
    "    '''tokenizes input dataframe considering words of 2 and more characters\n",
    "       and lowercase text and remove numbers\n",
    "    \n",
    "       Parameters\n",
    "       ----------\n",
    "       data : Pandas series to tokenize       \n",
    "       Returns\n",
    "       --------\n",
    "       Pandas series list of tokens'''\n",
    "                      \n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w{2,}')\n",
    "    sentences = data.str.lower()\n",
    "    sentences = sentences.str.replace('\\d+', '',regex=True)\n",
    "    results = sentences.apply(tokenizer.tokenize)\n",
    "  \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Deploy localy final script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "We'll load an image of predifined environment 'AzureML-TensorFlow-2.2-CPU'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Create and customize environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926129417
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "env = Environment.get(workspace=ws, name='AzureML-TensorFlow-2.2-CPU')\n",
    "curated_clone = env.clone(\"customize_curated\") # clone the environment to customize it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926131073
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "# Install nedded packages\n",
    "python_packages=['Keras==2.4.3','nltk','sklearn','tensorflow==2.3.0']\n",
    "for package in python_packages:\n",
    "    curated_clone.python.conda_dependencies.add_pip_package(package)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### Modify inference config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926132972
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "inf_config = InferenceConfig(environment=curated_clone, source_directory='./source_dir', entry_script='./score.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620924414462
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading model LSTM_Glove:1 to /tmp/azureml_myv5i_db/LSTM_Glove/1\n",
      "Generating Docker build context.\n",
      "Package creation Succeeded\n",
      "Logging into Docker registry 5a5bf34d87e743cba82cd0b93b4b143b.azurecr.io\n",
      "Logging into Docker registry 5a5bf34d87e743cba82cd0b93b4b143b.azurecr.io\n",
      "Building Docker image from Dockerfile...\n",
      "Step 1/5 : FROM 5a5bf34d87e743cba82cd0b93b4b143b.azurecr.io/azureml/azureml_44bf330ff8c523d2cf00804f469f8f13\n",
      " ---> 2301ff468a77\n",
      "Step 2/5 : COPY azureml-app /var/azureml-app\n",
      " ---> a5838bafaecd\n",
      "Step 3/5 : RUN mkdir -p '/var/azureml-app' && echo eyJhY2NvdW50Q29udGV4dCI6eyJzdWJzY3JpcHRpb25JZCI6Ijg3ODE3NTFjLTcwZGQtNDQxYS04YzQ1LTIyNzQyMDg4NTFjMCIsInJlc291cmNlR3JvdXBOYW1lIjoib2MtcDciLCJhY2NvdW50TmFtZSI6InA3X21sIiwid29ya3NwYWNlSWQiOiI1YTViZjM0ZC04N2U3LTQzY2ItYTgyYy1kMGI5M2I0YjE0M2IifSwibW9kZWxzIjp7fSwibW9kZWxzSW5mbyI6e319 | base64 --decode > /var/azureml-app/model_config_map.json\n",
      " ---> Running in ff4bb9db1829\n",
      " ---> 7b345a270a49\n",
      "Step 4/5 : RUN mv '/var/azureml-app/tmpxjuwyrgi.py' /var/azureml-app/main.py\n",
      " ---> Running in b6d57e64c588\n",
      " ---> 25887629e359\n",
      "Step 5/5 : CMD [\"runsvdir\",\"/var/runit\"]\n",
      " ---> Running in aad0862dabb5\n",
      " ---> dce3a34467ff\n",
      "Successfully built dce3a34467ff\n",
      "Successfully tagged myservice:latest\n",
      "Container (name:elegant_knuth, id:28ba2e53b2d572308a44fbbc98da381b440b688a1b164c09a0c3f7d4a35c03d2) cannot be killed.\n",
      "Container has been successfully cleaned up.\n",
      "Image sha256:8a42197d989863f70478f09109e60a068662445152b0af40c6e7f8f155985e14 successfully removed.\n",
      "Starting Docker container...\n",
      "Docker container running.\n",
      "Checking container health...\n",
      "Local webservice is running at http://localhost:6789\n",
      "/bin/bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2021-05-13T16:46:30,611237936+00:00 - nginx/run \n",
      "/bin/bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2021-05-13T16:46:30,615961254+00:00 - rsyslog/run \n",
      "/bin/bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2021-05-13T16:46:30,618660064+00:00 - iot-server/run \n",
      "bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "2021-05-13T16:46:30,622485078+00:00 - gunicorn/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "/bin/bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2021-05-13T16:46:30,702732177+00:00 - iot-server/finish 1 0\n",
      "2021-05-13T16:46:30,704168483+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (16)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "2021-05-13 16:46:31.696247: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib:/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib:\n",
      "2021-05-13 16:46:31.696284: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-05-13 16:46:34,705 | root | INFO | Starting up app insights client\n",
      "2021-05-13 16:46:34,705 | root | INFO | Starting up request id generator\n",
      "2021-05-13 16:46:34,705 | root | INFO | Starting up app insight hooks\n",
      "2021-05-13 16:46:34,705 | root | INFO | Invoking user's init function\n",
      "2021-05-13 16:46:36.227663: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib:/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib:\n",
      "2021-05-13 16:46:36.227719: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-05-13 16:46:36.227767: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (805967cf1726): /proc/driver/nvidia/version does not exist\n",
      "2021-05-13 16:46:36.228019: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-05-13 16:46:36.235784: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2294680000 Hz\n",
      "2021-05-13 16:46:36.236116: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5c82560 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-13 16:46:36.236142: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "***************This is init************************************\n",
      "2021-05-13 16:46:54,498 | root | INFO | Users's init has completed successfully\n",
      "2021-05-13 16:46:54,501 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-05-13 16:46:54,501 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-05-13 16:46:54,502 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "\n",
    "service = Model.deploy(ws, \"myservice\", [model], inf_config, deploy_config)\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "use service.reload() when modifying script without restarting the whole service\n",
    "\n",
    "requests.get('http://localhost:6789') to test liveness of service\n",
    "\n",
    "print(service.get_logs()) to see logs and debug\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620925048099
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container has been successfully cleaned up.\n",
      "Starting Docker container...\n",
      "Docker container running.\n"
     ]
    }
   ],
   "source": [
    "service.reload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926147018
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926148188
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "request = {\"target\":{\"1516037\":1,\"589923\":0,\"213819\":0,\"10047\":0,\"1330460\":1},\n",
    "        \"text\":{\"1516037\":\"Wow, its later than I feel, better wrap up another twitteriffic day. night -all  \",\n",
    "                 \"589923\":\"@lemonissimo I think the reason I twitted so much in Italy, there was so much to do &amp; see! Here it's just working through videos... \",\n",
    "                 \"213819\":\"@GericaQuinn ahhhhh! dude u suck! lmao. jk! but i love my little davidkins! haha. i wanna pop n' lock on him  lol\",\n",
    "                 \"10047\":\"...aaaand there goes that great day  RIP Mrs Wever\",\"1330460\":\"another morning joe free morning ahhhh ... sun ... birds singing ... nice! \",\n",
    "                 \"363111\":\"@cdouglasroberts.... awww  Im across the state in Knoxville.\"}}\n",
    "request=json.dumps(request)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620925072501
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "uri = service.scoring_uri\n",
    "headers = {'Content-Type': 'application/json'}\n",
    "response = requests.post(uri, data=request,headers=headers)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620924843919
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2021-05-13T16:46:30,611237936+00:00 - nginx/run \n",
      "/bin/bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2021-05-13T16:46:30,615961254+00:00 - rsyslog/run \n",
      "/bin/bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2021-05-13T16:46:30,618660064+00:00 - iot-server/run \n",
      "bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "2021-05-13T16:46:30,622485078+00:00 - gunicorn/run \n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "/bin/bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2021-05-13T16:46:30,702732177+00:00 - iot-server/finish 1 0\n",
      "2021-05-13T16:46:30,704168483+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (16)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 41\n",
      "2021-05-13 16:46:31.696247: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib:/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib:\n",
      "2021-05-13 16:46:31.696284: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-05-13 16:46:34,705 | root | INFO | Starting up app insights client\n",
      "2021-05-13 16:46:34,705 | root | INFO | Starting up request id generator\n",
      "2021-05-13 16:46:34,705 | root | INFO | Starting up app insight hooks\n",
      "2021-05-13 16:46:34,705 | root | INFO | Invoking user's init function\n",
      "2021-05-13 16:46:36.227663: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib:/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib:\n",
      "2021-05-13 16:46:36.227719: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-05-13 16:46:36.227767: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (805967cf1726): /proc/driver/nvidia/version does not exist\n",
      "2021-05-13 16:46:36.228019: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-05-13 16:46:36.235784: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2294680000 Hz\n",
      "2021-05-13 16:46:36.236116: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x5c82560 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-13 16:46:36.236142: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "***************This is init************************************\n",
      "2021-05-13 16:46:54,498 | root | INFO | Users's init has completed successfully\n",
      "2021-05-13 16:46:54,501 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-05-13 16:46:54,501 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-05-13 16:46:54,502 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "2021-05-13 16:53:40,909 | root | INFO | Validation Request Content-Type\n",
      "2021-05-13 16:53:40,909 | root | INFO | Scoring Timer is set to 3600.0 seconds\n",
      "{\"target\": {\"1516037\": 1, \"589923\": 0, \"213819\": 0, \"10047\": 0, \"1330460\": 1}, \"text\": {\"1516037\": \"Wow, its later than I feel, better wrap up another twitteriffic day. night -all  \", \"589923\": \"@lemonissimo I think the reason I twitted so much in Italy, there was so much to do &amp; see! Here it's just working through videos... \", \"213819\": \"@GericaQuinn ahhhhh! dude u suck! lmao. jk! but i love my little davidkins! haha. i wanna pop n' lock on him  lol\", \"10047\": \"...aaaand there goes that great day  RIP Mrs Wever\", \"1330460\": \"another morning joe free morning ahhhh ... sun ... birds singing ... nice! \", \"363111\": \"@cdouglasroberts.... awww  Im across the state in Knoxville.\"}}\n",
      "2021-05-13 16:53:40,959 | root | ERROR | Encountered Exception: Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/data/util/structure.py\", line 93, in normalize_element\n",
      "    spec = type_spec_from_value(t, use_fallback=False)\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/data/util/structure.py\", line 466, in type_spec_from_value\n",
      "    (element, type(element).__name__))\n",
      "TypeError: Could not build a TypeSpec for 1516037    [wow, its, later, than, feel, better, wrap, up...\n",
      "589923     [lemonissimo, think, the, reason, twitted, so,...\n",
      "213819     [gericaquinn, ahhhhh, dude, suck, lmao, jk, bu...\n",
      "10047      [aaaand, there, goes, that, great, day, rip, m...\n",
      "1330460    [another, morning, joe, free, morning, ahhhh, ...\n",
      "363111     [cdouglasroberts, awww, im, across, the, state...\n",
      "Name: text, dtype: object with type Series\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/var/azureml-server/synchronous/routes.py\", line 64, in run_scoring\n",
      "    response = invoke_user_with_timer(service_input, request_headers)\n",
      "  File \"/var/azureml-server/synchronous/routes.py\", line 97, in invoke_user_with_timer\n",
      "    result = user_main.run(**params)\n",
      "  File \"/var/azureml-app/source_dir/./score.py\", line 27, in run\n",
      "    y_pred = model.predict(X)\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 130, in _method_wrapper\n",
      "    return method(self, *args, **kwargs)\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1579, in predict\n",
      "    steps_per_execution=self._steps_per_execution)\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 1117, in __init__\n",
      "    model=model)\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 364, in __init__\n",
      "    dataset = self.slice_inputs(indices_dataset, inputs)\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/keras/engine/data_adapter.py\", line 390, in slice_inputs\n",
      "    dataset_ops.DatasetV2.from_tensors(inputs).repeat()\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 604, in from_tensors\n",
      "    return TensorDataset(tensors)\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 2982, in __init__\n",
      "    element = structure.normalize_element(element)\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/data/util/structure.py\", line 98, in normalize_element\n",
      "    ops.convert_to_tensor(t, name=\"component_%d\" % i))\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1499, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 338, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 264, in constant\n",
      "    allow_broadcast=True)\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 275, in _constant_impl\n",
      "    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 300, in _constant_eager_impl\n",
      "    t = convert_to_eager_tensor(value, ctx, dtype)\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/tensorflow/python/framework/constant_op.py\", line 98, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "ValueError: Failed to convert a NumPy array to a Tensor (Unsupported object type list).\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/flask/app.py\", line 1832, in full_dispatch_request\n",
      "    rv = self.dispatch_request()\n",
      "  File \"/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/python3.6/site-packages/flask/app.py\", line 1818, in dispatch_request\n",
      "    return self.view_functions[rule.endpoint](**req.view_args)\n",
      "  File \"/var/azureml-server/synchronous/routes.py\", line 43, in score_realtime\n",
      "    return run_scoring(service_input, request.headers, request.environ.get('REQUEST_ID', '00000000-0000-0000-0000-000000000000'))\n",
      "  File \"/var/azureml-server/synchronous/routes.py\", line 77, in run_scoring\n",
      "    raise RunFunctionException(str(exc))\n",
      "run_function_exception.RunFunctionException\n",
      "\n",
      "2021-05-13 16:53:40,959 | root | INFO | 500\n",
      "127.0.0.1 - - [13/May/2021:16:53:40 +0000] \"POST /score HTTP/1.0\" 500 75 \"-\" \"python-requests/2.25.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620816531515
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: /azureml-envs/azureml_426e3ece822f802c0fe0da3258bc8612/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_426e3ece822f802c0fe0da3258bc8612/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_426e3ece822f802c0fe0da3258bc8612/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2021-05-12T10:48:13,950909430+00:00 - iot-server/run \n",
      "2021-05-12T10:48:13,953190764+00:00 - nginx/run \n",
      "/bin/bash: /azureml-envs/azureml_426e3ece822f802c0fe0da3258bc8612/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2021-05-12T10:48:13,959343358+00:00 - gunicorn/run \n",
      "2021-05-12T10:48:13,962803010+00:00 - rsyslog/run \n",
      "bash: /azureml-envs/azureml_426e3ece822f802c0fe0da3258bc8612/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "/bin/bash: /azureml-envs/azureml_426e3ece822f802c0fe0da3258bc8612/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2021-05-12T10:48:14,022368420+00:00 - iot-server/finish 1 0\n",
      "2021-05-12T10:48:14,023491938+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "Starting gunicorn 19.9.0\n",
      "Listening at: http://127.0.0.1:31311 (15)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 44\n",
      "2021-05-12 10:48:14.811961: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_426e3ece822f802c0fe0da3258bc8612/lib:/azureml-envs/azureml_426e3ece822f802c0fe0da3258bc8612/lib:\n",
      "2021-05-12 10:48:14.811994: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-05-12 10:48:17,181 | root | INFO | Starting up app insights client\n",
      "2021-05-12 10:48:17,181 | root | INFO | Starting up request id generator\n",
      "2021-05-12 10:48:17,181 | root | INFO | Starting up app insight hooks\n",
      "2021-05-12 10:48:17,181 | root | INFO | Invoking user's init function\n",
      "2021-05-12 10:48:18.808905: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_426e3ece822f802c0fe0da3258bc8612/lib:/azureml-envs/azureml_426e3ece822f802c0fe0da3258bc8612/lib:\n",
      "2021-05-12 10:48:18.808939: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-05-12 10:48:18.808959: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (28ba2e53b2d5): /proc/driver/nvidia/version does not exist\n",
      "2021-05-12 10:48:18.809148: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-05-12 10:48:18.815469: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2593905000 Hz\n",
      "2021-05-12 10:48:18.815761: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4cb3a90 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-12 10:48:18.815785: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "***************This is init************************************\n",
      "2021-05-12 10:48:34,279 | root | INFO | Users's init has completed successfully\n",
      "2021-05-12 10:48:34,281 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-05-12 10:48:34,281 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-05-12 10:48:34,282 | root | INFO | Scoring timeout setting is not found. Use default timeout: 3600000 ms\n",
      "2021-05-12 10:48:47,767 | root | INFO | Validation Request Content-Type\n",
      "2021-05-12 10:48:47,768 | root | INFO | Scoring Timer is set to 3600.0 seconds\n",
      "{\"target\": {\"1516037\": 1, \"589923\": 0, \"213819\": 0, \"10047\": 0, \"1330460\": 1}, \"text\": {\"1516037\": \"Wow, its later than I feel, better wrap up another twitteriffic day. night -all  \", \"589923\": \"@lemonissimo I think the reason I twitted so much in Italy, there was so much to do &amp; see! Here it's just working through videos... \", \"213819\": \"@GericaQuinn ahhhhh! dude u suck! lmao. jk! but i love my little davidkins! haha. i wanna pop n' lock on him  lol\", \"10047\": \"...aaaand there goes that great day  RIP Mrs Wever\", \"1330460\": \"another morning joe free morning ahhhh ... sun ... birds singing ... nice! \", \"363111\": \"@cdouglasroberts.... awww  Im across the state in Knoxville.\"}}\n",
      "[[0.6778625 ]\n",
      " [0.3400945 ]\n",
      " [0.72275054]\n",
      " [0.22147086]\n",
      " [0.91370904]\n",
      " [0.1112121 ]]\n",
      "2021-05-12 10:48:48,237 | root | INFO | 200\n",
      "127.0.0.1 - - [12/May/2021:10:48:48 +0000] \"POST /score HTTP/1.0\" 200 134 \"-\" \"python-requests/2.25.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620925077742
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6983094811439514],\n",
       " [0.4235050082206726],\n",
       " [0.6183003783226013],\n",
       " [0.2214709222316742],\n",
       " [0.9137091636657715],\n",
       " [0.11121213436126709]]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "## Deploy in the cloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "source": [
    "### use ACI for deployment config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926154488
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core.webservice import AciWebservice\n",
    "\n",
    "deployment_config = AciWebservice.deploy_configuration(cpu_cores = 0.5, memory_gb = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926381511
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tips: You can try get_logs(): https://aka.ms/debugimage#dockerlog or local deployment: https://aka.ms/debugimage#debug-locally to debug if deployment takes longer than 10 minutes.\n",
      "Running\n",
      "2021-05-13 17:15:58+00:00 Creating Container Registry if not exists.\n",
      "2021-05-13 17:15:58+00:00 Registering the environment.\n",
      "2021-05-13 17:16:00+00:00 Use the existing image.\n",
      "2021-05-13 17:16:00+00:00 Generating deployment configuration.\n",
      "2021-05-13 17:16:02+00:00 Submitting deployment to compute..\n",
      "2021-05-13 17:16:10+00:00 Checking the status of deployment myservice..\n",
      "2021-05-13 17:18:35+00:00 Checking the status of inference endpoint myservice.\n",
      "Succeeded\n",
      "ACI service creation operation finished, operation \"Succeeded\"\n",
      "/bin/bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "/bin/bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2021-05-13T17:18:27,348398796+00:00 - gunicorn/run \n",
      "2021-05-13T17:18:27,348957396+00:00 - iot-server/run \n",
      "2021-05-13T17:18:27,349603997+00:00 - rsyslog/run \n",
      "bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by bash)\n",
      "2021-05-13T17:18:27,394627136+00:00 - nginx/run \n",
      "Starting gunicorn 20.1.0\n",
      "Listening at: http://127.0.0.1:31311 (13)\n",
      "Using worker: sync\n",
      "worker timeout is set to 300\n",
      "Booting worker with pid: 35\n",
      "EdgeHubConnectionString and IOTEDGE_IOTHUBHOSTNAME are not set. Exiting...\n",
      "2021-05-13T17:18:28,369313689+00:00 - iot-server/finish 1 0\n",
      "2021-05-13T17:18:28,370514790+00:00 - Exit code 1 is normal. Not restarting iot-server.\n",
      "/bin/bash: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib/libtinfo.so.5: no version information available (required by /bin/bash)\n",
      "2021-05-13 17:18:29.876038: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib:/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib:\n",
      "2021-05-13 17:18:29.876084: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "SPARK_HOME not set. Skipping PySpark Initialization.\n",
      "Initializing logger\n",
      "2021-05-13 17:18:35,774 | root | INFO | Starting up app insights client\n",
      "2021-05-13 17:18:35,775 | root | INFO | Starting up request id generator\n",
      "2021-05-13 17:18:35,775 | root | INFO | Starting up app insight hooks\n",
      "2021-05-13 17:18:35,775 | root | INFO | Invoking user's init function\n",
      "2021-05-13 17:18:53.590940: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib:/azureml-envs/azureml_8fb2b84aef302194159e21d427136a88/lib:\n",
      "2021-05-13 17:18:53.590989: W tensorflow/stream_executor/cuda/cuda_driver.cc:312] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-05-13 17:18:53.591014: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (wk-caas-8ca100227a804297b86a26d87ec1c431-ac9e3a3cd75d907b56390e): /proc/driver/nvidia/version does not exist\n",
      "2021-05-13 17:18:53.591247: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-05-13 17:18:53.599940: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2394450000 Hz\n",
      "2021-05-13 17:18:53.600629: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x4cab8b0 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2021-05-13 17:18:53.600695: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "***************This is init************************************\n",
      "2021-05-13 17:19:29,598 | root | INFO | Users's init has completed successfully\n",
      "2021-05-13 17:19:29,621 | root | INFO | Skipping middleware: dbg_model_info as it's not enabled.\n",
      "2021-05-13 17:19:29,621 | root | INFO | Skipping middleware: dbg_resource_usage as it's not enabled.\n",
      "2021-05-13 17:19:29,621 | root | INFO | Scoring timeout is found from os.environ: 60000 ms\n",
      "2021-05-13 17:19:40,391 | root | INFO | Swagger file not present\n",
      "2021-05-13 17:19:40,391 | root | INFO | 404\n",
      "127.0.0.1 - - [13/May/2021:17:19:40 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "2021-05-13 17:19:41,129 | root | INFO | Swagger file not present\n",
      "2021-05-13 17:19:41,129 | root | INFO | 404\n",
      "127.0.0.1 - - [13/May/2021:17:19:41 +0000] \"GET /swagger.json HTTP/1.0\" 404 19 \"-\" \"Go-http-client/1.1\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "service = Model.deploy(ws, \"myservice\",[model], inference_config=inf_config, deployment_config=deployment_config )\n",
    "service.wait_for_deployment(show_output=True)\n",
    "print(service.get_logs())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926513672
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": [
    "from azureml.core import Webservice\n",
    "\n",
    "service = Webservice(workspace=ws, name='myservice')\n",
    "scoring_uri = service.scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620926514484
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'http://24d13703-5fe9-40cd-acd4-efeace756110.westeurope.azurecontainer.io/score'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scoring_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620913527579
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'headers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-e5eaa6af23ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscoring_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'headers' is not defined"
     ]
    }
   ],
   "source": [
    "resp = requests.post(scoring_uri, data=request, headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620913529515
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Response [200]>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "gather": {
     "logged": 1620913531625
    },
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.6778625249862671],\n",
       " [0.3400944471359253],\n",
       " [0.7227505445480347],\n",
       " [0.2214709222316742],\n",
       " [0.9137091636657715],\n",
       " [0.11121213436126709]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resp.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": false,
     "source_hidden": false
    },
    "nteract": {
     "transient": {
      "deleting": false
     }
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python38-azureml"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "microsoft": {
   "host": {
    "AzureML": {
     "notebookHasBeenCompleted": true
    }
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
