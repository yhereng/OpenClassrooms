{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"black\"><font size=\"7\"><br>\n",
    "     Project 7 - Advanced Model\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"D:/Data OC/P7/sentiment140/training.1600000.processed.noemoticon.csv\",header=None,names=['target','text'],usecols=[0,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to noramlize the target, reformat and save for futur use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = data['target']/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype({'target':'int32'},copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/data_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/data_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a common datasets for comapring performances across the three approachs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_common = data.sample(n=1600,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_common.to_csv('data/data_common.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1516037</th>\n",
       "      <td>1</td>\n",
       "      <td>Wow, its later than I feel, better wrap up ano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589923</th>\n",
       "      <td>0</td>\n",
       "      <td>@lemonissimo I think the reason I twitted so m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213819</th>\n",
       "      <td>0</td>\n",
       "      <td>@GericaQuinn ahhhhh! dude u suck! lmao. jk! bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10047</th>\n",
       "      <td>0</td>\n",
       "      <td>...aaaand there goes that great day  RIP Mrs W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330460</th>\n",
       "      <td>1</td>\n",
       "      <td>another morning joe free morning ahhhh ... sun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622620</th>\n",
       "      <td>0</td>\n",
       "      <td>Damn packing trumps Xsport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232219</th>\n",
       "      <td>0</td>\n",
       "      <td>bout 2 call it a NIGHT... madd TIRED..gotta he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368574</th>\n",
       "      <td>1</td>\n",
       "      <td>@IneffableNothin I love Pandora, but I am real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441029</th>\n",
       "      <td>0</td>\n",
       "      <td>@simoncurtis wish i could</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393237</th>\n",
       "      <td>1</td>\n",
       "      <td>@GulcinG Hala  in arabic.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text\n",
       "1516037       1  Wow, its later than I feel, better wrap up ano...\n",
       "589923        0  @lemonissimo I think the reason I twitted so m...\n",
       "213819        0  @GericaQuinn ahhhhh! dude u suck! lmao. jk! bu...\n",
       "10047         0  ...aaaand there goes that great day  RIP Mrs W...\n",
       "1330460       1  another morning joe free morning ahhhh ... sun...\n",
       "...         ...                                                ...\n",
       "622620        0                        Damn packing trumps Xsport \n",
       "232219        0  bout 2 call it a NIGHT... madd TIRED..gotta he...\n",
       "1368574       1  @IneffableNothin I love Pandora, but I am real...\n",
       "441029        0                         @simoncurtis wish i could \n",
       "1393237       1                          @GulcinG Hala  in arabic.\n",
       "\n",
       "[1600 rows x 2 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating Json file for Azure deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_common.to_json('data/data_common.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = pd.read_json('data/data_common.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1516037</th>\n",
       "      <td>1</td>\n",
       "      <td>Wow, its later than I feel, better wrap up ano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589923</th>\n",
       "      <td>0</td>\n",
       "      <td>@lemonissimo I think the reason I twitted so m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213819</th>\n",
       "      <td>0</td>\n",
       "      <td>@GericaQuinn ahhhhh! dude u suck! lmao. jk! bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10047</th>\n",
       "      <td>0</td>\n",
       "      <td>...aaaand there goes that great day  RIP Mrs W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330460</th>\n",
       "      <td>1</td>\n",
       "      <td>another morning joe free morning ahhhh ... sun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622620</th>\n",
       "      <td>0</td>\n",
       "      <td>Damn packing trumps Xsport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232219</th>\n",
       "      <td>0</td>\n",
       "      <td>bout 2 call it a NIGHT... madd TIRED..gotta he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368574</th>\n",
       "      <td>1</td>\n",
       "      <td>@IneffableNothin I love Pandora, but I am real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441029</th>\n",
       "      <td>0</td>\n",
       "      <td>@simoncurtis wish i could</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393237</th>\n",
       "      <td>1</td>\n",
       "      <td>@GulcinG Hala  in arabic.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text\n",
       "1516037       1  Wow, its later than I feel, better wrap up ano...\n",
       "589923        0  @lemonissimo I think the reason I twitted so m...\n",
       "213819        0  @GericaQuinn ahhhhh! dude u suck! lmao. jk! bu...\n",
       "10047         0  ...aaaand there goes that great day  RIP Mrs W...\n",
       "1330460       1  another morning joe free morning ahhhh ... sun...\n",
       "...         ...                                                ...\n",
       "622620        0                        Damn packing trumps Xsport \n",
       "232219        0  bout 2 call it a NIGHT... madd TIRED..gotta he...\n",
       "1368574       1  @IneffableNothin I love Pandora, but I am real...\n",
       "441029        0                         @simoncurtis wish i could \n",
       "1393237       1                          @GulcinG Hala  in arabic.\n",
       "\n",
       "[1600 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing common dataset from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(index=data_common.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1598400, 2)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/data_training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data['target'])\n",
    "plt.title('target distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acuuracy is a good metric for measuring a balanced classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of words per tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_text = data.text.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words =[len(text) for text in splitted_text.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEICAYAAAB1f3LfAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAZv0lEQVR4nO3da5RlZX3n8e9PWi7KRZDGAI02KqOiyxuIKMagrUIcJ/gCnc6Kgg7ILINGjTGCyRpHIyuSiRFNAsqSCOIFGDRKvDMgbYwEbLwEAVl25NItLd0KamEE0/ifF/spOV1UF6d716mq0/X9rHXW2fvZl/Pfp6vP7+xnX06qCkmSttWD5rsASdJ4M0gkSb0YJJKkXgwSSVIvBokkqReDRJLUi0GisZTk3CTvmqfXTpIPJ7kzydXzUUOr48gk6+br9aVJBolmRZKbk9ye5KEDbScmuWIeyxqV5wAvBJZV1WHzXcxCk+SKJCfO8Wu+KsnX5vI1dR+DRLNpCfCG+S5iayXZYSsXeRRwc1X9YhT1TCfJkrl6ra2xDe+dtkMGiWbT/wH+JMnDpk5IsjxJDX4gDn5zbd8o/yXJe5P8NMkPkjy7ta9NsiHJ8VNWu3eSS5NMJFmV5FED6358m3ZHkhuTvHxg2rlJzkry+SS/AJ43Tb37JbmkLb8myWta+wnAh4BnJbkryTumWfaWJIe04Ve07T64jZ+Y5NNteKckZyS5rT3OSLJTm3ZkknVJ3prkR8CHk+zSar8zyfXAM6a87luT/LC9HzcmWTHdP1JbxwdG8d4lOQ34beDv2vvzd0nekeRv2/QHJ/lFkr9q47skuTvJnm388CRfb38D30ly5MC690hyTpL1bTvflWSHJE8APjDwb/LT6bZbI1RVPnz0fgA3Ay8APgW8q7WdCFzRhpcDBSwZWOYK4MQ2/CpgE/BqYAfgXcCtwN8DOwEvAiaAXdv857bx57bp7wO+1qY9FFjb1rUEeDrwY+CJA8v+DDiC7svUztNszyrgTGBn4KnARmDFQK1fm+G9+Ajw5jZ8NvDvwGsHpr2pDb8T+FdgH2Ap8HXgL9q0I9v7cXrbvl2AdwP/DOwFHAB8F1jX5n9c2+b9Bt7vx2yhvlG/d7/5d23jzweubcPPbu/HVQPTvtOG9wd+Ary4rfuFbXxpm/5p4IOtxn2Aq4H/Ocy/iY/RPtwj0Wz7X8DrkyzdhmVvqqoPV9W9wIV0H5bvrKp7qurLwK+Axw7M/7mq+mpV3QP8Gd030gOAl9B1PX24qjZV1TeBTwLHDiz7mar6l6r6dVXdPVhEW8dzgLdW1d1V9W26vZBXDrkdq4DfacO/DfzlwPjvtOkAf9C2b0NVbQTeMeU1fg28vW3/L4GXA6dV1R1VtRZ4/8C899KFwsFJHlxVN1fVv89Q40jeuy24EjgoycPpwuscYP8ku055P14BfL6qPt/WfSmwGnhxkkcAvwu8sap+UVUbgPcCK4d4fY2YQaJZVVXfBT4LnLINi98+MPzLtr6pbbsOjK8deN27gDuA/eiOYTyzdY/8tHV1/AHwW9MtO439gDuqamKg7Ra6b8zDWAX8dpLfotu7uhA4IslyYA/g2wOvc8uU19hvYHzjlA/q/abU/Ztlq2oN8EbgfwMbklyQZHBdU43qvbufFoKr6ULjuXTvz9fp9moGg+RRwMumvPZzgH3btAcD6wemfZBuz0TzbEEewNPYezvwTeA9A22TB6YfAvy8DQ9+OG2LAyYH2rfbvYDb6D7oVlXVC2dYdqbbXt8G7JVkt4EweSTww2GKqqo1Sf4D+CPgq1U10Y5znETX/fLrgdd5FHDdwGvcNkON6+m2eXD+wdf9OPDxJLvTfciezpb3okb13m1p+iq6bqynAd9o40cBhwFfbfOsBc6vqtdMXTjJvsA9wN5VtWkbatIIuUeiWde+HV9I90E62baR7oP4Fe0A6f8AHtPzpV6c5DlJdgT+gq7ffS3dHtF/SfLKdnD3wUme0Q7KDlP/WrpvzH+ZZOckTwZOAD62FbWtAl7Hfd+2r5gyDvAJ4M+TLE2yN1234EdnWOdFwKlJ9kyyDHj95IQkj0vy/Haw/m66vbd7Z1jXSN675nbg0VPaVgHHAddX1a9ox1HoujM3tnk+Cvy3JEe1v5Gd20kHy6pqPfBl4D1Jdk/yoCSPSTLZZXg7sKxtj+aYQaJReSfdQdFBrwHeQncA9Yl0H9Z9fJxu7+cO4BC6LhjaXsSL6PrPbwN+xH0HrYf1+3QHrG8D/pHuWMWlW7H8KmA37vu2PXUcuhMKVgP/BlxLtxc300WW76DrzrqJ7kP1/IFpO9EdjP8x3fbuA7xthnWN8r17H3BsO7ts8jjO1+lOGJjc/uvpAu8370cLsmNa3Rvp9lDewn2fU8cBO7Zl7wQupuv2Aricbk/tR0l+vBW1ahakyj1CaTFJci7d2V5/Pt+1aPvgHokkqReDRJLUi11bkqRe3CORJPWy6K4j2XvvvWv58uXzXYYkjZVrrrnmx1U17R0rFl2QLF++nNWrV893GZI0VpLcsqVpdm1JknoxSCRJvRgkkqReDBJJUi8GiSSpF4NEktSLQSJJ6sUgkST1YpAsYFXFxMQE3g9N0kJmkCxgd911FyvP+Dx33XXXb9oMF0kLjUGywC3ZaZfNxqcLF0maTwbJGJoaLpI0nwySBcIuK0njyiBZILa1y8oAkjTfDJIFZFu6rDxmImm+GSTbAY+ZSJpPBokkqReDRJLUi0EiSerFIJEk9WKQSJJ6MUi2Q15bImkuGSTbIa8tkTSXDJLtlNeWSJorBokkqReDRJLUi0EiSeplpEGS5E1Jrkvy3SSfSLJzkr2SXJrk++15z4H5T02yJsmNSY4aaD8kybVt2vuTpLXvlOTC1n5VkuWj3J7Z4llVkrYnIwuSJPsDfwQcWlVPAnYAVgKnAJdV1UHAZW2cJAe36U8EjgbOTLJDW91ZwEnAQe1xdGs/Abizqh4LvBc4fVTbM5vm46wqw0vSqIy6a2sJsEuSJcBDgNuAY4Dz2vTzgJe24WOAC6rqnqq6CVgDHJZkX2D3qrqyuk/Bj0xZZnJdFwMrJvdWFrq5PqvKU4IljcrIgqSqfgj8NXArsB74WVV9GXhEVa1v86wH9mmL7A+sHVjFuta2fxue2r7ZMlW1CfgZ8PCptSQ5KcnqJKs3btw4Oxs4hjwlWNIojLJra0+6PYYDgf2AhyZ5xUyLTNNWM7TPtMzmDVVnV9WhVXXo0qVLZy5ckrRVRtm19QLgpqraWFX/CXwKeDZwe+uuoj1vaPOvAw4YWH4ZXVfYujY8tX2zZVr32R7AHSPZGknStEYZJLcChyd5SDtusQK4AbgEOL7NczzwmTZ8CbCynYl1IN1B9atb99dEksPbeo6bsszkuo4FLi+PJkvSnFoyqhVX1VVJLga+CWwCvgWcDewKXJTkBLqweVmb/7okFwHXt/lPrqp72+peC5wL7AJ8oT0AzgHOT7KGbk9k5ai2R5I0vZEFCUBVvR14+5Tme+j2Tqab/zTgtGnaVwNPmqb9bloQSZLmh1e2S5J6MUgkSb0YJJKkXgySRczbpkiaDQbJIuZtUyTNBoNkkfO2KZL6MkgkSb0YJJKkXgwSSVIvBokkqReDRJLUi0EiSerFINFmvEhR0tYySLQZL1KUtLUMEt2PFylK2hoGiSSpF4NEktSLQSJJ6sUgkST1YpBIknoxSCRJvRgkI+YFfpK2dwbJiG0PF/gZhpJmYpDMgXG/wG97CENJo2OQaCjjHoaSRscgkST1YpBIknoxSCRJvRgkkqReDBJJUi8GiSSpF4NE28SLFCVNMki0TbxIUdIkg0TbzIsUJYFBIknqySCRJPVikEiSehlpkCR5WJKLk3wvyQ1JnpVkrySXJvl+e95zYP5Tk6xJcmOSowbaD0lybZv2/iRp7TslubC1X5Vk+Si3R5J0f6PeI3kf8MWqejzwFOAG4BTgsqo6CLisjZPkYGAl8ETgaODMJDu09ZwFnAQc1B5Ht/YTgDur6rHAe4HTR7w9kqQpRhYkSXYHngucA1BVv6qqnwLHAOe12c4DXtqGjwEuqKp7quomYA1wWJJ9gd2r6srqLlr4yJRlJtd1MbBicm9FkjQ3RrlH8mhgI/DhJN9K8qEkDwUeUVXrAdrzPm3+/YG1A8uva237t+Gp7ZstU1WbgJ8BDx/N5uiBeJGitDiNMkiWAE8HzqqqpwG/oHVjbcF0exI1Q/tMy2y+4uSkJKuTrN64cePMVWubeZGitDiNMkjWAeuq6qo2fjFdsNzeuqtozxsG5j9gYPllwG2tfdk07Zstk2QJsAdwx9RCqursqjq0qg5dunTpLGyatsSLFKXFZ2RBUlU/AtYmeVxrWgFcD1wCHN/ajgc+04YvAVa2M7EOpDuofnXr/ppIcng7/nHclGUm13UscHnZryJJc2rJiNf/euBjSXYEfgC8mi68LkpyAnAr8DKAqrouyUV0YbMJOLmq7m3reS1wLrAL8IX2gO5A/vlJ1tDtiawc8fZIkqYYaZBU1beBQ6eZtGIL858GnDZN+2rgSdO0300LIknS/PDKdklSLwaJJKkXg0Qj43Ul0uJgkGhkvK5EWhwMEo2U15VI2z+DRJLUi0EiSerFIJEk9WKQaE55Jpe0/TFINKc8k0va/hgkmnOeySVtXwwSSVIvBskssv9f0mI0VJAkOWKYtsXO/v9tYwBL423YPZK/HbJt0bP/f+tNF8ATExNMTEzMY1WShjXj75EkeRbwbGBpkj8emLQ7sMMoC9PiYgBL4+uBfthqR2DXNt9uA+0/p/tpW0nSIjdjkFTVKmBVknOr6pY5qkmSNEaG/andnZKcDSwfXKaqnj+KoiRJ42PYIPm/wAeADwH3jq4cSdK4GTZINlXVWSOtRJI0loY9/fefkvxhkn2T7DX5GGll0gCvNZEWrmGD5HjgLcDXgWvaY/WoipKmmu5aE8NFWhiGCpKqOnCax6NHXZw0aOq1Jt5JQFoYhjpGkuS46dqr6iOzW460dbyQUZp/wx5sf8bA8M7ACuCbgEEiSYvcUEFSVa8fHE+yB3D+SCqSJI2Vbb2N/H8AB81mIdJs8AC8NPeGvY38PyW5pD0+B9wIfGa0pUlbzwPw0twb9hjJXw8MbwJuqap1I6hH6s0D8NLcGvb031XA9+juALwn8KtRFiVJGh/Ddm29HLgaeBnwcuCqJN5GXpI0dNfWnwHPqKoNAEmWAv8PuHhUhUmSxsOwZ209aDJEmp9sxbKSpO3YsHskX0zyJeATbfy/A58fTUnS7Koq7rrrLnbddVeSzHc50nZnxr2KJI9NckRVvQX4IPBk4CnAlcDZc1Cf1JunBEuj9UDdU2cAEwBV9amq+uOqehPd3sgZoy1Nmj2eEiyNzgMFyfKq+repjVW1mu5ndyVJi9wDBcnOM0wb6itekh2SfCvJZ9v4XkkuTfL99rznwLynJlmT5MYkRw20H5Lk2jbt/Wkd3Ul2SnJha78qyfJhapIkzZ4HCpJvJHnN1MYkJ9D9uNUw3gDcMDB+CnBZVR0EXNbGSXIwsBJ4InA0cGaSHdoyZwEn0d3f66A2HeAE4M6qeizwXuD0IWuSJM2SBwqSNwKvTnJFkve0xyrgRLqAmFGSZcB/BT400HwMcF4bPg946UD7BVV1T1XdBKwBDkuyL7B7VV1Z3Z34PjJlmcl1XQysmNxbkSTNjRlP/62q24FnJ3ke8KTW/LmqunzI9Z8B/CndrVUmPaKq1rf1r0+yT2vfH/jXgfnWtbb/bMNT2yeXWdvWtSnJz4CHAz8eLCLJSXR7NDzykY8csnRJ0jCG/T2SrwBf2ZoVJ3kJsKGqrkly5DCLTPfSM7TPtMzmDVVn005XPvTQQ72/uCTNomEvSNwWRwC/l+TFdAftd0/yUeD2JPu2vZF9gckr5tcBBwwsvwy4rbUvm6Z9cJl1SZYAewB3jGqDJEn3N7LbnFTVqVW1rKqW0x1Ev7yqXgFcAhzfZjue+37X5BJgZTsT60C6g+pXt26wiSSHt+Mfx01ZZnJdx7bXcI9DkubQKPdItuTdwEXtzK9b6e4oTFVdl+Qi4Hq63zw5uarubcu8FjiX7pTjL7QHwDnA+UnW0O2JrJyrjZAkdeYkSKrqCuCKNvwTYMUW5jsNOG2a9tXcd7B/sP1uWhBJw/LeW9Ls8g6+WnS895Y0uwwSLUree0uaPQaJJKkXg0SS1ItBIknqxSCRJPVikEiSejFIJEm9GCSSpF4MEklSLwaJJKkXg0SS1ItBIknqxSCRJPVikEiSejFIJEm9GCSSpF4MEonuVxMnJiaoqvkuRRo7BomEv5oo9WGQSI2/mihtG4NEktSLQSJJ6sUgkST1YpBIknoxSCRJvRgkkqReDBJJUi8GiSSpF4NkG3lLDUnqGCTbyFtqSFLHIOnBW2pIkkEiSerJIJEk9WKQSJJ6MUgkSb0YJJKkXgwSSVIvIwuSJAck+UqSG5Jcl+QNrX2vJJcm+X573nNgmVOTrElyY5KjBtoPSXJtm/b+JGntOyW5sLVflWT5qLZHi48XnUrDGeUeySbgzVX1BOBw4OQkBwOnAJdV1UHAZW2cNm0l8ETgaODMJDu0dZ0FnAQc1B5Ht/YTgDur6rHAe4HTR7g9WmS86FQazsiCpKrWV9U32/AEcAOwP3AMcF6b7TzgpW34GOCCqrqnqm4C1gCHJdkX2L2qrqzuq+FHpiwzua6LgRWTeyvSbPCiU+mBzckxktbl9DTgKuARVbUeurAB9mmz7Q+sHVhsXWvbvw1Pbd9smaraBPwMePg0r39SktVJVm/cuHGWtkqSBHMQJEl2BT4JvLGqfj7TrNO01QztMy2zeUPV2VV1aFUdunTp0gcqWZK0FUYaJEkeTBciH6uqT7Xm21t3Fe15Q2tfBxwwsPgy4LbWvmya9s2WSbIE2AO4Y/a3RJK0JaM8ayvAOcANVfU3A5MuAY5vw8cDnxloX9nOxDqQ7qD61a37ayLJ4W2dx01ZZnJdxwKXl6fYSNKcWjLCdR8BvBK4Nsm3W9vbgHcDFyU5AbgVeBlAVV2X5CLgerozvk6uqnvbcq8FzgV2Ab7QHtAF1flJ1tDtiawc4fZIkqYxsiCpqq8x/TEMgBVbWOY04LRp2lcDT5qm/W5aEEmS5odXtkuSejFIJEm9GCSSpF4MEklSLwaJJKkXg0SS1ItBIknqxSCRJPVikEiSejFIpK3gryZK92eQSFvBX02U7s8gkbaSv5oobc4gkST1YpBIknoxSCRJvRgkkqReDBJJUi8GiSSpF4NEktSLQSJJ6sUgkST1YpBIknoxSCRJvRgkUk/eEViLnUEi9eQdgbXYGSTSLPCOwFrMDJIh2X0hSdMzSIZk94UkTc8g2Qp2X0jS/RkkkqReDBJJUi8GiSSpF4NEGgHP8tNiYpBII+BZflpMDBJpRDzLT4uFQSJJ6sUgkeaIx020vTJIpDnicRNtr8Y+SJIcneTGJGuSnDLf9UgzmXrcxL0UbQ/GOkiS7AD8PfC7wMHA7yc5eH6rkoY3dS/FYNE4WjLfBfR0GLCmqn4AkOQC4Bjg+lG82KZ7fsnExAQAExMTm43PV9tCqWMUtQ1aSHXNdtvU51ed+WXO/cMXsdtuuyHNplH9TWWcv/kkORY4uqpObOOvBJ5ZVa+bMt9JwElt9HHAjUOsfm/gx7NY7nwY922w/vk37ttg/bPnUVW1dLoJ475Hkmna7peMVXU2cPZWrThZXVWHbmthC8G4b4P1z79x3wbrnxtjfYwEWAccMDC+DLhtnmqRpEVp3IPkG8BBSQ5MsiOwErhknmuSpEVlrLu2qmpTktcBXwJ2AP6hqq6bpdVvVVfYAjXu22D982/ct8H658BYH2yXJM2/ce/akiTNM4NEktSLQTKNcbztSpJ/SLIhyXcH2vZKcmmS77fnPeezxi1JckCSryS5Icl1Sd7Q2seifoAkOye5Osl32ja8o7WPzTZAd7eIJN9K8tk2Pjb1J7k5ybVJvp1kdWsbm/oBkjwsycVJvtf+PzxrHLbBIJlijG+7ci5w9JS2U4DLquog4LI2vhBtAt5cVU8ADgdObu/5uNQPcA/w/Kp6CvBU4OgkhzNe2wDwBuCGgfFxq/95VfXUgWsvxq3+9wFfrKrHA0+h+7dY+NtQVT4GHsCzgC8NjJ8KnDrfdQ1Z+3LguwPjNwL7tuF9gRvnu8Yht+MzwAvHuP6HAN8EnjlO20B3HdZlwPOBz47b3xBwM7D3lLZxqn934CbaSVDjtA3ukdzf/sDagfF1rW0cPaKq1gO0533muZ4HlGQ58DTgKsas/tYt9G1gA3BpVY3bNpwB/Cnw64G2caq/gC8nuabdFgnGq/5HAxuBD7fuxQ8leShjsA0Gyf0NddsVzb4kuwKfBN5YVT+f73q2VlXdW1VPpftmf1iSJ81zSUNL8hJgQ1VdM9+19HBEVT2drlv65CTPne+CttIS4OnAWVX1NOAXLMRurGkYJPe3Pd125fYk+wK05w3zXM8WJXkwXYh8rKo+1ZrHpv5BVfVT4Aq6Y1bjsg1HAL+X5GbgAuD5ST7K+NRPVd3WnjcA/0h3d/CxqZ/us2dd25MFuJguWBb8Nhgk97c93XblEuD4Nnw83bGHBSdJgHOAG6rqbwYmjUX9AEmWJnlYG94FeAHwPcZkG6rq1KpaVlXL6f7mL6+qVzAm9Sd5aJLdJoeBFwHfZUzqB6iqHwFrkzyuNa2g+0mMBb8NXtk+jSQvpusvnrztymnzW9EDS/IJ4Ei6207fDrwd+DRwEfBI4FbgZVV1xzyVuEVJngP8M3At9/XPv43uOMmCrx8gyZOB8+j+Zh4EXFRV70zycMZkGyYlORL4k6p6ybjUn+TRdHsh0HURfbyqThuX+icleSrwIWBH4AfAq2l/TyzgbTBIJEm92LUlSerFIJEk9WKQSJJ6MUgkSb0YJJKkXgwSSVIvBokkqZf/D38QBBhp7C4rAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Number of words per tweet')\n",
    "sns.histplot(nb_words)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionnary = {}\n",
    "for sentence in splitted_text:\n",
    "    for word in sentence:\n",
    "        if word in dictionnary.keys():\n",
    "            dictionnary[word]+=1\n",
    "        else:\n",
    "            dictionnary[word]=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pd.DataFrame.from_dict(dictionnary,orient='index',columns=['nb_occur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1349319, 1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20193, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[vocab['nb_occur']>46].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65637, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[vocab['nb_occur']>10].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(data, y = None):\n",
    "    '''tokenizes input dataframe considering words of 2 and more characters\n",
    "       and lowercase text and remove numbers\n",
    "    \n",
    "       Parameters\n",
    "       ----------\n",
    "       data : Pandas series to tokenize\n",
    "       \n",
    "       Returns\n",
    "       --------\n",
    "       Pandas series list of tokens'''\n",
    "              \n",
    "        \n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w{2,}')\n",
    "    sentences = data.str.lower()\n",
    "    sentences = sentences.str.replace('\\d+', '',regex=True)\n",
    "    results = sentences.apply(tokenizer.tokenize)\n",
    "  \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a transformer for pipeline integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_transformer = FunctionTransformer(func=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(data, y = None, stemmer = PorterStemmer()):\n",
    "    ''' Stems data using stemmer returns stems as a list of strings'''\n",
    "\n",
    "\n",
    "    def stem_sentence(tokenized_sentence):\n",
    "        stems = [stemmer.stem(i) for i in tokenized_sentence]\n",
    "        return stems\n",
    "    \n",
    "    return data.apply(stem_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a transformer for pipeline integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer_transformer = FunctionTransformer(func=stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(data, y = None, lemmatizer = WordNetLemmatizer()):\n",
    "    \n",
    "    def get_wordnet_pos(word):\n",
    "    #Map POS tag to first character lemmatize() accepts\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "    def lem_sentence(tokenized_sentence):\n",
    "        lems = [lemmatizer.lemmatize(i,pos=get_wordnet_pos(i)) for i in tokenized_sentence]\n",
    "        return lems \n",
    "\n",
    "    \n",
    "    return data.apply(lem_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a transformer for pipeline integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer_transformer = FunctionTransformer(func=lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(data, stopwords = nltk.corpus.stopwords.words('english')):\n",
    "    '''Remove stopwords from data'''\n",
    "\n",
    "    # remove stopwords from stems and create a new column\n",
    "    results = [[stem for stem in stems if (\n",
    "        not(stem in stopwords))] for stems in data]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a transformer for pipeline integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords_transformer = FunctionTransformer(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_stem = Pipeline([('Tokenizer',tokenizer_transformer),\n",
    "                      ('Stemmer',stemmer_transformer),\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lem = Pipeline([('Tokenizer',tokenizer_transformer),\n",
    "                      ('lemmatizer',lemmatizer_transformer),\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fastext_Transformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = FT_gensim(size=50,min_count=10,)     \n",
    "        \n",
    "        \n",
    "    def build_doc2vec_corpus(self,texts):\n",
    "        '''Returns a training corpus in the appropriate gensim Taggeddocument format'''\n",
    "        results = []\n",
    "        for tag,text in enumerate(texts):\n",
    "            results.append(gensim.models.doc2vec.TaggedDocument(text,[tag]))\n",
    "        return results\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        self.train_corpus = list(self.build_doc2vec_corpus(X))\n",
    "        self.model.build_vocab(sentences=X.values)\n",
    "        self.model.train(X.values,\n",
    "                         epochs=self.model.epochs,\n",
    "                         total_examples=self.model.corpus_count,\n",
    "                         total_words=self.model.corpus_total_words\n",
    "                        )\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def vectorized_sentence(self,sentence):\n",
    "        wordvecs_sent = [self.model.wv[word] for word in sentence]\n",
    "        meanvec_sent = np.array(wordvecs_sent).mean(axis=0)\n",
    "        return meanvec_sent\n",
    "        \n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self.vectorized_sentence(text) for text in X]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre trained Glove Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll use the glove pretrained vector with a dimension of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = gensim.downloader.load('glove-twitter-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentence_pretrained(sentence,Keyedvectors= glove_vectors):\n",
    "    wordvecs_sent = [Keyedvectors[word] for word in sentence if word in Keyedvectors]\n",
    "    if len(wordvecs_sent)>0:\n",
    "        meanvec_sent = np.array(wordvecs_sent).mean(axis=0)\n",
    "    else:\n",
    "        meanvec_sent = np.zeros(Keyedvectors.vector_size)\n",
    "    return meanvec_sent\n",
    "\n",
    "def vectorize_corpus_glove(data):\n",
    "    return [vectorize_sentence_pretrained(text) for text in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Glove_transformer = FunctionTransformer(func=vectorize_corpus_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Doc2vec_Transformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = gensim.models.doc2vec.Doc2Vec(vector_size=100, min_count=10, epochs=60)        \n",
    "        self.train_corpus=[]\n",
    "        \n",
    "    def build_doc2vec_corpus(self,texts):\n",
    "        '''Returns a training corpus in the appropriate gensim Taggeddocument format'''\n",
    "        results = []\n",
    "        for tag,text in enumerate(texts):\n",
    "            results.append(gensim.models.doc2vec.TaggedDocument(text,[tag]))\n",
    "        return results\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        self.train_corpus = list(self.build_doc2vec_corpus(X))\n",
    "        self.model.build_vocab(self.train_corpus)\n",
    "        self.model.train(self.train_corpus, total_examples=self.model.corpus_count, epochs=self.model.epochs)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self.model.infer_vector(text) for text in X]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing preprocessings with Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score,auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling dataset for reducing training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a sample dataset for testing\n",
    "data_sample = data.sample(n=10000,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data_sample['text']\n",
    "y = data_sample['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000,)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe for storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_performances=pd.DataFrame(columns=['training_time (s)','Accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='Fasttext - No preprocess'\n",
    "\n",
    "pipe_fastext = Pipeline([    ('preprocessing',tokenizer_transformer),\n",
    "                             ('embedding',Fastext_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])\n",
    "\n",
    "start = time.time()\n",
    "pipe_fastext.fit(X_train,y_train)\n",
    "stop = time.time()\n",
    "\n",
    "y_pred = pipe_fastext.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time (s)</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fasttext - No preprocess</th>\n",
       "      <td>29.219006</td>\n",
       "      <td>0.6105</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          training_time (s)  Accuracy\n",
       "Fasttext - No preprocess          29.219006    0.6105"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='Fasttext - Lemmatization'\n",
    "\n",
    "pipe_lem_fastext = Pipeline([('preprocessing',pipe_lem),\n",
    "                             ('embedding',Fastext_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pipe_lem_fastext.fit(X_train,y_train)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_lem_fastext.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Fasttext - stemming'\n",
    "\n",
    "pipe_stem_fastext = Pipeline([('preprocessing',pipe_stem),\n",
    "                             ('embedding',Fastext_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pipe_stem_fastext.fit(X_train,y_train)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_stem_fastext.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time (s)</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fasttext - No preprocess</th>\n",
       "      <td>23.022785</td>\n",
       "      <td>0.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fasttext - stemming</th>\n",
       "      <td>7.574217</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          training_time (s)  Accuracy\n",
       "Fasttext - No preprocess          23.022785     0.510\n",
       "Fasttext - stemming                7.574217     0.515"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre trained Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='Glove - No preprocess'\n",
    "\n",
    "pipe_glove = Pipeline([      ('preprocessing',tokenizer_transformer),\n",
    "                             ('embedding',Glove_transformer),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])\n",
    "\n",
    "start = time.time()\n",
    "pipe_glove.fit(X_train,y_train)\n",
    "stop = time.time()\n",
    "\n",
    "y_pred = pipe_glove.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wtih lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Glove - lemmatization'\n",
    "\n",
    "pipe_lem_glove = Pipeline([('preprocessing',pipe_lem),\n",
    "                             ('embedding',Glove_transformer),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pipe_lem_glove.fit(X_train,y_train)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_lem_glove.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wtih stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Glove - stemming'\n",
    "\n",
    "pipe_stem_glove = Pipeline([('preprocessing',pipe_stem),\n",
    "                             ('embedding',Glove_transformer),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pipe_stem_glove.fit(X_train,y_train)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_stem_glove.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='Doc2vec - No preprocess'\n",
    "\n",
    "pipe_doc2vec = Pipeline([    ('preprocessing',tokenizer_transformer),\n",
    "                             ('embedding',Doc2vec_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])\n",
    "\n",
    "start = time.time()\n",
    "pipe_doc2vec.fit(X_train,y_train)\n",
    "stop = time.time()\n",
    "\n",
    "y_pred = pipe_doc2vec.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wtih lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Doc2vec - lemmatization'\n",
    "\n",
    "pipe_lem_doc2vec = Pipeline([('preprocessing',pipe_lem),\n",
    "                             ('embedding',Doc2vec_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pipe_lem_doc2vec.fit(X_train,y_train)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_lem_doc2vec.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wtih stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Doc2vec - stemming'\n",
    "\n",
    "pipe_stem_doc2vec = Pipeline([('preprocessing',pipe_stem),\n",
    "                             ('embedding',Doc2vec_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pipe_stem_doc2vec.fit(X_train,y_train)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_stem_doc2vec.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time (s)</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fasttext - No preprocess</th>\n",
       "      <td>29.219006</td>\n",
       "      <td>0.6105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fasttext - Lemmatization</th>\n",
       "      <td>68.166595</td>\n",
       "      <td>0.6055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glove - No preprocess</th>\n",
       "      <td>34.748743</td>\n",
       "      <td>0.7485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glove - lemmatization</th>\n",
       "      <td>55.533927</td>\n",
       "      <td>0.7550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glove - stemming</th>\n",
       "      <td>21.035625</td>\n",
       "      <td>0.7230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2vec - No preprocess</th>\n",
       "      <td>48.887063</td>\n",
       "      <td>0.6955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2vec - lemmatization</th>\n",
       "      <td>104.267337</td>\n",
       "      <td>0.6920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2vec - stemming</th>\n",
       "      <td>52.889242</td>\n",
       "      <td>0.7185</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          training_time (s)  Accuracy\n",
       "Fasttext - No preprocess          29.219006    0.6105\n",
       "Fasttext - Lemmatization          68.166595    0.6055\n",
       "Glove - No preprocess             34.748743    0.7485\n",
       "Glove - lemmatization             55.533927    0.7550\n",
       "Glove - stemming                  21.035625    0.7230\n",
       "Doc2vec - No preprocess           48.887063    0.6955\n",
       "Doc2vec - lemmatization          104.267337    0.6920\n",
       "Doc2vec - stemming                52.889242    0.7185"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing text data to fit Keras requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the NN needs an input matrix with documents represented as an interger list, each interger is a word. we'll choose sequence length to be tweet_length(based on EDA it makes sense, if less than tweet_length use 0 padding) and vocabulary size max_token (based on preliminary EDA). We'll use Keras' vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_length = 30\n",
    "max_tokens = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a sample dataset for testing\n",
    "data_sample = data.sample(n=15000,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data_sample['text']\n",
    "y = data_sample['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sets(X_train,X_test,vocab_length=20000,tweet_length=30):\n",
    "    '''Compute and return the vectors of the documents in X_train and X_test with a fixed length'''\n",
    "    vectorizer = TextVectorization(max_tokens=vocab_length,output_sequence_length=tweet_length)\n",
    "    vectorizer.adapt(X_train.values)\n",
    "    voc = vectorizer.get_vocabulary() # vocabulary for futur use\n",
    "    word_index = dict(zip(voc, range(len(voc)))) # word index for futur use\n",
    "    return (vectorizer(X_train.values),vectorizer(X_test.values),voc,word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, voc_raw, word_index_raw = vectorize_sets(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    vocab_length=max_tokens,\n",
    "    tweet_length=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect, X_test_vect, voc, word_index = vectorize_sets(\n",
    "    tokenizer_transformer.transform(X_train).str.join(sep=' '),\n",
    "    tokenizer_transformer.transform(X_test).str.join(sep=' '),\n",
    "    vocab_length=max_tokens,\n",
    "    tweet_length=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect_stem, X_test_vect_stem, voc_stem, word_index_stem = vectorize_sets(\n",
    "    stemmer_transformer.transform(tokenizer_transformer.transform(X_train)).str.join(sep=' '),\n",
    "    stemmer_transformer.transform(tokenizer_transformer.transform(X_test)).str.join(sep=' '),\n",
    "    vocab_length=max_tokens,\n",
    "    tweet_length=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect_lem, X_test_vect_lem, voc_lem, word_index_lem = vectorize_sets(\n",
    "    lemmatizer_transformer.transform(tokenizer_transformer.transform(X_train)).str.join(sep=' '),\n",
    "    lemmatizer_transformer.transform(tokenizer_transformer.transform(X_test)).str.join(sep=' '),\n",
    "    vocab_length=max_tokens,\n",
    "    tweet_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " raw vocab length 22953 \n",
      " no processing vocab length 20564 \n",
      " stem vocab length 17599 \n",
      " lem vocab length 18460\n"
     ]
    }
   ],
   "source": [
    "print(f' raw vocab length {len(voc_raw)} \\n no processing vocab length {len(voc)} \\n stem vocab length {len(voc_stem)} \\n lem vocab length {len(voc_lem)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing preprocessing on a simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances=pd.DataFrame(columns=['AUC','Accuracy','Epoch max reach'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           2295300   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 24008     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,319,317\n",
      "Trainable params: 2,319,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'simple NN - raw text'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(voc_raw),100 ,input_length = tweet_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "12/12 [==============================] - 1s 84ms/step - loss: 0.6917 - accuracy: 0.5300 - auc: 0.5400 - val_loss: 0.6884 - val_accuracy: 0.5550 - val_auc: 0.5970\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.6723 - accuracy: 0.6783 - auc: 0.7552 - val_loss: 0.6779 - val_accuracy: 0.5847 - val_auc: 0.6608\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.6335 - accuracy: 0.7729 - auc: 0.8596 - val_loss: 0.6536 - val_accuracy: 0.6737 - val_auc: 0.7418\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.5618 - accuracy: 0.8538 - auc: 0.9300 - val_loss: 0.6185 - val_accuracy: 0.6947 - val_auc: 0.7690\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 1s 65ms/step - loss: 0.4623 - accuracy: 0.8898 - auc: 0.9540 - val_loss: 0.5817 - val_accuracy: 0.7150 - val_auc: 0.7841\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.3554 - accuracy: 0.9202 - auc: 0.9728 - val_loss: 0.5545 - val_accuracy: 0.7277 - val_auc: 0.7983\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.2621 - accuracy: 0.9469 - auc: 0.9863 - val_loss: 0.5397 - val_accuracy: 0.7333 - val_auc: 0.8083\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.1883 - accuracy: 0.9679 - auc: 0.9941 - val_loss: 0.5298 - val_accuracy: 0.7463 - val_auc: 0.8136\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 1s 64ms/step - loss: 0.1343 - accuracy: 0.9795 - auc: 0.9977 - val_loss: 0.5310 - val_accuracy: 0.7493 - val_auc: 0.8144\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0974 - accuracy: 0.9876 - auc: 0.9991 - val_loss: 0.5360 - val_accuracy: 0.7467 - val_auc: 0.8136\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0727 - accuracy: 0.9914 - auc: 0.9996 - val_loss: 0.5431 - val_accuracy: 0.7407 - val_auc: 0.8119\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0556 - accuracy: 0.9948 - auc: 0.9998 - val_loss: 0.5542 - val_accuracy: 0.7403 - val_auc: 0.8102\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.0429 - accuracy: 0.9958 - auc: 0.9999 - val_loss: 0.5637 - val_accuracy: 0.7407 - val_auc: 0.8089\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.0345 - accuracy: 0.9968 - auc: 0.9999 - val_loss: 0.5780 - val_accuracy: 0.7387 - val_auc: 0.8070\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0283 - accuracy: 0.9974 - auc: 1.0000 - val_loss: 0.5878 - val_accuracy: 0.7350 - val_auc: 0.8058\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_raw, y_train, batch_size=1024, epochs=15, validation_data=(X_test_raw, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>0.814432</td>\n",
       "      <td>0.749333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.445643</td>\n",
       "      <td>6.637676</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           AUC  Accuracy  Epoch max reach  \\\n",
       "simple NN - raw text  0.814432  0.749333              8.0   \n",
       "\n",
       "                      total training time  training time to opt  \n",
       "simple NN - raw text            12.445643              6.637676  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 30, 100)           2056400   \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 24008     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,080,417\n",
      "Trainable params: 2,080,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'simple NN - Basic preprocessing'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "12/12 [==============================] - 1s 72ms/step - loss: 0.6922 - accuracy: 0.5347 - auc: 0.5360 - val_loss: 0.6893 - val_accuracy: 0.5690 - val_auc: 0.6001\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.6763 - accuracy: 0.6695 - auc: 0.7381 - val_loss: 0.6799 - val_accuracy: 0.6153 - val_auc: 0.6823\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 1s 53ms/step - loss: 0.6371 - accuracy: 0.7940 - auc: 0.8793 - val_loss: 0.6518 - val_accuracy: 0.7013 - val_auc: 0.7605\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.5522 - accuracy: 0.8660 - auc: 0.9362 - val_loss: 0.6030 - val_accuracy: 0.7180 - val_auc: 0.7835\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.4298 - accuracy: 0.8908 - auc: 0.9570 - val_loss: 0.5602 - val_accuracy: 0.7200 - val_auc: 0.8001\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.3106 - accuracy: 0.9242 - auc: 0.9776 - val_loss: 0.5354 - val_accuracy: 0.7303 - val_auc: 0.8106\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 1s 51ms/step - loss: 0.2173 - accuracy: 0.9547 - auc: 0.9905 - val_loss: 0.5339 - val_accuracy: 0.7270 - val_auc: 0.8153\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.1520 - accuracy: 0.9727 - auc: 0.9963 - val_loss: 0.5256 - val_accuracy: 0.7317 - val_auc: 0.8170\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.1068 - accuracy: 0.9845 - auc: 0.9986 - val_loss: 0.5328 - val_accuracy: 0.7260 - val_auc: 0.8151\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0777 - accuracy: 0.9895 - auc: 0.9994 - val_loss: 0.5434 - val_accuracy: 0.7273 - val_auc: 0.8125\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.0585 - accuracy: 0.9927 - auc: 0.9997 - val_loss: 0.5556 - val_accuracy: 0.7273 - val_auc: 0.8106\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.0441 - accuracy: 0.9948 - auc: 0.9998 - val_loss: 0.5714 - val_accuracy: 0.7263 - val_auc: 0.8083\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0336 - accuracy: 0.9962 - auc: 0.9999 - val_loss: 0.5888 - val_accuracy: 0.7250 - val_auc: 0.8061\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.0271 - accuracy: 0.9971 - auc: 1.0000 - val_loss: 0.6060 - val_accuracy: 0.7290 - val_auc: 0.8042\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.0215 - accuracy: 0.9983 - auc: 1.0000 - val_loss: 0.6220 - val_accuracy: 0.7273 - val_auc: 0.8023\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=15, validation_data=(X_test_vect, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>0.814432</td>\n",
       "      <td>0.749333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.445643</td>\n",
       "      <td>6.637676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>0.817025</td>\n",
       "      <td>0.731667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.445507</td>\n",
       "      <td>5.341237</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      AUC  Accuracy  Epoch max reach  \\\n",
       "simple NN - raw text             0.814432  0.749333              8.0   \n",
       "simple NN - Basic preprocessing  0.817025  0.731667              7.0   \n",
       "\n",
       "                                 total training time  training time to opt  \n",
       "simple NN - raw text                       12.445643              6.637676  \n",
       "simple NN - Basic preprocessing            11.445507              5.341237  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 30, 100)           1759900   \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 8)                 24008     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,783,917\n",
      "Trainable params: 1,783,917\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'simple NN - Stemming'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(voc_stem),100 ,input_length = tweet_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "12/12 [==============================] - 1s 67ms/step - loss: 0.6920 - accuracy: 0.5178 - auc: 0.5325 - val_loss: 0.6879 - val_accuracy: 0.5663 - val_auc: 0.6230\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.6714 - accuracy: 0.6823 - auc: 0.7615 - val_loss: 0.6747 - val_accuracy: 0.5823 - val_auc: 0.7126\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.6258 - accuracy: 0.8077 - auc: 0.8939 - val_loss: 0.6404 - val_accuracy: 0.7093 - val_auc: 0.7755\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.5434 - accuracy: 0.8570 - auc: 0.9296 - val_loss: 0.5928 - val_accuracy: 0.7263 - val_auc: 0.7972\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.4375 - accuracy: 0.8826 - auc: 0.9503 - val_loss: 0.5510 - val_accuracy: 0.7370 - val_auc: 0.8092\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.3353 - accuracy: 0.9125 - auc: 0.9697 - val_loss: 0.5283 - val_accuracy: 0.7377 - val_auc: 0.8185\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.2510 - accuracy: 0.9387 - auc: 0.9843 - val_loss: 0.5188 - val_accuracy: 0.7437 - val_auc: 0.8228\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.1858 - accuracy: 0.9607 - auc: 0.9927 - val_loss: 0.5166 - val_accuracy: 0.7433 - val_auc: 0.8231\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 1s 46ms/step - loss: 0.1386 - accuracy: 0.9726 - auc: 0.9965 - val_loss: 0.5254 - val_accuracy: 0.7420 - val_auc: 0.8209\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.1047 - accuracy: 0.9825 - auc: 0.9984 - val_loss: 0.5408 - val_accuracy: 0.7363 - val_auc: 0.8172\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.0806 - accuracy: 0.9876 - auc: 0.9992 - val_loss: 0.5498 - val_accuracy: 0.7340 - val_auc: 0.8152\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 1s 47ms/step - loss: 0.0631 - accuracy: 0.9912 - auc: 0.9996 - val_loss: 0.5604 - val_accuracy: 0.7310 - val_auc: 0.8125\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.0508 - accuracy: 0.9937 - auc: 0.9998 - val_loss: 0.5703 - val_accuracy: 0.7320 - val_auc: 0.8106\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 1s 48ms/step - loss: 0.0418 - accuracy: 0.9947 - auc: 0.9998 - val_loss: 0.5884 - val_accuracy: 0.7260 - val_auc: 0.8085\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 1s 49ms/step - loss: 0.0349 - accuracy: 0.9962 - auc: 0.9999 - val_loss: 0.6027 - val_accuracy: 0.7253 - val_auc: 0.8062\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect_stem, y_train, batch_size=1024, epochs=15, validation_data=(X_test_vect_stem, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_4 (Embedding)      (None, 30, 100)           1846000   \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 8)                 24008     \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 1,870,017\n",
      "Trainable params: 1,870,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'simple NN - Lemmatization'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(voc_lem),100 ,input_length = tweet_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "12/12 [==============================] - 1s 71ms/step - loss: 0.6924 - accuracy: 0.5162 - auc: 0.5299 - val_loss: 0.6903 - val_accuracy: 0.5253 - val_auc: 0.6114\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 1s 50ms/step - loss: 0.6801 - accuracy: 0.6773 - auc: 0.7484 - val_loss: 0.6802 - val_accuracy: 0.6460 - val_auc: 0.6969\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 1s 54ms/step - loss: 0.6480 - accuracy: 0.7847 - auc: 0.8710 - val_loss: 0.6534 - val_accuracy: 0.7040 - val_auc: 0.7701\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.5770 - accuracy: 0.8388 - auc: 0.9150 - val_loss: 0.6038 - val_accuracy: 0.7170 - val_auc: 0.7928\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.4671 - accuracy: 0.8683 - auc: 0.9411 - val_loss: 0.5563 - val_accuracy: 0.7377 - val_auc: 0.8072\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.3560 - accuracy: 0.8983 - auc: 0.9639 - val_loss: 0.5290 - val_accuracy: 0.7383 - val_auc: 0.8184\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 1s 52ms/step - loss: 0.2625 - accuracy: 0.9342 - auc: 0.9819 - val_loss: 0.5163 - val_accuracy: 0.7473 - val_auc: 0.8239\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.1912 - accuracy: 0.9572 - auc: 0.9920 - val_loss: 0.5166 - val_accuracy: 0.7463 - val_auc: 0.8239\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.1398 - accuracy: 0.9743 - auc: 0.9964 - val_loss: 0.5254 - val_accuracy: 0.7423 - val_auc: 0.8210\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.1036 - accuracy: 0.9831 - auc: 0.9984 - val_loss: 0.5330 - val_accuracy: 0.7393 - val_auc: 0.8190\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0786 - accuracy: 0.9887 - auc: 0.9992 - val_loss: 0.5464 - val_accuracy: 0.7387 - val_auc: 0.8158\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.0614 - accuracy: 0.9917 - auc: 0.9996 - val_loss: 0.5589 - val_accuracy: 0.7387 - val_auc: 0.8141\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 1s 68ms/step - loss: 0.0492 - accuracy: 0.9934 - auc: 0.9998 - val_loss: 0.5743 - val_accuracy: 0.7327 - val_auc: 0.8110\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.0400 - accuracy: 0.9959 - auc: 0.9999 - val_loss: 0.5870 - val_accuracy: 0.7323 - val_auc: 0.8095\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 1s 55ms/step - loss: 0.0336 - accuracy: 0.9962 - auc: 0.9999 - val_loss: 0.6006 - val_accuracy: 0.7267 - val_auc: 0.8080\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect_lem, y_train, batch_size=1024, epochs=15, validation_data=(X_test_vect_lem, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Preprocessing performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>0.814432</td>\n",
       "      <td>0.749333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.445643</td>\n",
       "      <td>6.637676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>0.817025</td>\n",
       "      <td>0.731667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.445507</td>\n",
       "      <td>5.341237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Stemming</th>\n",
       "      <td>0.823142</td>\n",
       "      <td>0.743667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.423989</td>\n",
       "      <td>4.169596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Lemmatization</th>\n",
       "      <td>0.823922</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.959692</td>\n",
       "      <td>4.783877</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      AUC  Accuracy  Epoch max reach  \\\n",
       "simple NN - raw text             0.814432  0.749333              8.0   \n",
       "simple NN - Basic preprocessing  0.817025  0.731667              7.0   \n",
       "simple NN - Stemming             0.823142  0.743667              6.0   \n",
       "simple NN - Lemmatization        0.823922  0.747333              6.0   \n",
       "\n",
       "                                 total training time  training time to opt  \n",
       "simple NN - raw text                       12.445643              6.637676  \n",
       "simple NN - Basic preprocessing            11.445507              5.341237  \n",
       "simple NN - Stemming                       10.423989              4.169596  \n",
       "simple NN - Lemmatization                  11.959692              4.783877  "
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances.to_pickle('data/models_performances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = pd.read_pickle('data/models_performances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the embedding matrix ( word / coeff matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Glove embedding shows better results, we'll use it from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(\"D:/Data OC/P7/glove.twitter.27B.100d.txt\",encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the embedding matrix which can be used in a Keras Embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 13745 words (6819 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "misses_word=[]\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        misses_word.append(word)\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['trvsbrkr',\n",
       " 'trekkerguy',\n",
       " 'tplayer',\n",
       " 'toooooo',\n",
       " 'tittch',\n",
       " 'thxy',\n",
       " 'threeter',\n",
       " 'thodae',\n",
       " 'thisgoeshere',\n",
       " 'therealjordin',\n",
       " 'thepistol',\n",
       " 'thenikster',\n",
       " 'thedebbyryan',\n",
       " 'thebrandicyrus',\n",
       " 'theapostate',\n",
       " 'teemwilliams',\n",
       " 'tdlq',\n",
       " 'tamizh',\n",
       " 'synwpn',\n",
       " 'symphnysldr',\n",
       " 'sweetlilmzmia',\n",
       " 'statisticsio',\n",
       " 'soooooooooooo',\n",
       " 'solangeknowles',\n",
       " 'skibumbrian',\n",
       " 'silverlines',\n",
       " 'shushhh',\n",
       " 'shlokas',\n",
       " 'sheshines',\n",
       " 'shaunjumpnow',\n",
       " 'sharontweet',\n",
       " 'serenebalance',\n",
       " 'scientistno',\n",
       " 'sashactlc',\n",
       " 'saramorgan',\n",
       " 'saramooney',\n",
       " 'samjmoody',\n",
       " 'sadannyfan',\n",
       " 'rubyrose',\n",
       " 'rissaya',\n",
       " 'riskybusinessmb',\n",
       " 'riandawson',\n",
       " 'retrorewind',\n",
       " 'realhughjackman',\n",
       " 'qqwyd',\n",
       " 'pseudosophical',\n",
       " 'pinkbunny',\n",
       " 'pieshopgirl',\n",
       " 'pickoo',\n",
       " 'photoshopltd',\n",
       " 'phoneee',\n",
       " 'peterfacinelli',\n",
       " 'patriciaco',\n",
       " 'partyyy',\n",
       " 'owwww',\n",
       " 'otherijustine',\n",
       " 'otalia',\n",
       " 'orxq',\n",
       " 'nkairplay',\n",
       " 'nicolerichie',\n",
       " 'neverrr',\n",
       " 'neosolrkstr',\n",
       " 'nemonemesis',\n",
       " 'nathanfillion',\n",
       " 'nahhh',\n",
       " 'musicmuch',\n",
       " 'mrskutcher',\n",
       " 'mrscrob',\n",
       " 'moonsinger',\n",
       " 'moonfrye',\n",
       " 'monkeysnuggles',\n",
       " 'misswiz',\n",
       " 'misssarcastic',\n",
       " 'missnina',\n",
       " 'mishacollins',\n",
       " 'micstand',\n",
       " 'meeeee',\n",
       " 'mcpamy',\n",
       " 'mattpro',\n",
       " 'markmizuno',\n",
       " 'marcocali',\n",
       " 'mandacrow',\n",
       " 'majornelson',\n",
       " 'mailiw',\n",
       " 'loveeee',\n",
       " 'lostininaka',\n",
       " 'longggg',\n",
       " 'lkhamilton',\n",
       " 'littleren',\n",
       " 'linnetwoods',\n",
       " 'lghocq',\n",
       " 'langfordperry',\n",
       " 'lalavazquez',\n",
       " 'kriscolvin',\n",
       " 'krisallenmusic',\n",
       " 'knkartha',\n",
       " 'kimsherrell',\n",
       " 'khushiall',\n",
       " 'kalebnation',\n",
       " 'justdemi']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misses_word[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "import keras\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    input_length=tweet_length,\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 30, 100)           2056600   \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 24008     \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,080,617\n",
      "Trainable params: 24,017\n",
      "Non-trainable params: 2,056,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'simple NN - GLoVe embedding'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "12/12 [==============================] - 1s 43ms/step - loss: 0.6894 - accuracy: 0.5556 - auc: 0.5688 - val_loss: 0.6645 - val_accuracy: 0.6253 - val_auc: 0.6681\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.6383 - accuracy: 0.6531 - auc: 0.7138 - val_loss: 0.6238 - val_accuracy: 0.6767 - val_auc: 0.7395\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.5920 - accuracy: 0.6982 - auc: 0.7706 - val_loss: 0.5960 - val_accuracy: 0.6970 - val_auc: 0.7565\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.5566 - accuracy: 0.7234 - auc: 0.7978 - val_loss: 0.5798 - val_accuracy: 0.7050 - val_auc: 0.7689\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 0s 17ms/step - loss: 0.5288 - accuracy: 0.7462 - auc: 0.8216 - val_loss: 0.5696 - val_accuracy: 0.7097 - val_auc: 0.7770\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 0s 20ms/step - loss: 0.5073 - accuracy: 0.7605 - auc: 0.8388 - val_loss: 0.5643 - val_accuracy: 0.7120 - val_auc: 0.7812\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 0s 19ms/step - loss: 0.4891 - accuracy: 0.7761 - auc: 0.8534 - val_loss: 0.5616 - val_accuracy: 0.7107 - val_auc: 0.7844\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.4735 - accuracy: 0.7862 - auc: 0.8645 - val_loss: 0.5593 - val_accuracy: 0.7143 - val_auc: 0.7870\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.4611 - accuracy: 0.7947 - auc: 0.8732 - val_loss: 0.5600 - val_accuracy: 0.7160 - val_auc: 0.7876\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4482 - accuracy: 0.8008 - auc: 0.8817 - val_loss: 0.5606 - val_accuracy: 0.7197 - val_auc: 0.7886\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.4373 - accuracy: 0.8084 - auc: 0.8883 - val_loss: 0.5608 - val_accuracy: 0.7180 - val_auc: 0.7880\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4277 - accuracy: 0.8151 - auc: 0.8936 - val_loss: 0.5627 - val_accuracy: 0.7200 - val_auc: 0.7880\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4184 - accuracy: 0.8207 - auc: 0.8997 - val_loss: 0.5665 - val_accuracy: 0.7197 - val_auc: 0.7878\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4110 - accuracy: 0.8236 - auc: 0.9031 - val_loss: 0.5660 - val_accuracy: 0.7173 - val_auc: 0.7875\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.4027 - accuracy: 0.8281 - auc: 0.9081 - val_loss: 0.5687 - val_accuracy: 0.7143 - val_auc: 0.7872\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.3944 - accuracy: 0.8352 - auc: 0.9123 - val_loss: 0.5715 - val_accuracy: 0.7153 - val_auc: 0.7864\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.3874 - accuracy: 0.8367 - auc: 0.9158 - val_loss: 0.5759 - val_accuracy: 0.7143 - val_auc: 0.7861\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 0s 13ms/step - loss: 0.3802 - accuracy: 0.8416 - auc: 0.9198 - val_loss: 0.5773 - val_accuracy: 0.7113 - val_auc: 0.7855\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 0.3739 - accuracy: 0.8448 - auc: 0.9228 - val_loss: 0.5819 - val_accuracy: 0.7163 - val_auc: 0.7844\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3668 - accuracy: 0.8486 - auc: 0.9262 - val_loss: 0.5824 - val_accuracy: 0.7153 - val_auc: 0.7838\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.3609 - accuracy: 0.8518 - auc: 0.9289 - val_loss: 0.5863 - val_accuracy: 0.7167 - val_auc: 0.7833\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.3544 - accuracy: 0.8562 - auc: 0.9320 - val_loss: 0.5885 - val_accuracy: 0.7157 - val_auc: 0.7828\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.3487 - accuracy: 0.8589 - auc: 0.9347 - val_loss: 0.5959 - val_accuracy: 0.7150 - val_auc: 0.7817\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3432 - accuracy: 0.8622 - auc: 0.9372 - val_loss: 0.5972 - val_accuracy: 0.7173 - val_auc: 0.7815\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3375 - accuracy: 0.8670 - auc: 0.9395 - val_loss: 0.6066 - val_accuracy: 0.7130 - val_auc: 0.7805\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3317 - accuracy: 0.8689 - auc: 0.9421 - val_loss: 0.6074 - val_accuracy: 0.7133 - val_auc: 0.7797\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3258 - accuracy: 0.8727 - auc: 0.9447 - val_loss: 0.6084 - val_accuracy: 0.7133 - val_auc: 0.7783\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 0.3206 - accuracy: 0.8759 - auc: 0.9466 - val_loss: 0.6113 - val_accuracy: 0.7113 - val_auc: 0.7778\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3154 - accuracy: 0.8788 - auc: 0.9488 - val_loss: 0.6167 - val_accuracy: 0.7120 - val_auc: 0.7768\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 0s 15ms/step - loss: 0.3102 - accuracy: 0.8821 - auc: 0.9506 - val_loss: 0.6223 - val_accuracy: 0.7120 - val_auc: 0.7767\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>0.814432</td>\n",
       "      <td>0.749333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.445643</td>\n",
       "      <td>6.637676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>0.817025</td>\n",
       "      <td>0.731667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.445507</td>\n",
       "      <td>5.341237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Stemming</th>\n",
       "      <td>0.823142</td>\n",
       "      <td>0.743667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.423989</td>\n",
       "      <td>4.169596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Lemmatization</th>\n",
       "      <td>0.823922</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.959692</td>\n",
       "      <td>4.783877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - GLoVe embedding</th>\n",
       "      <td>0.788596</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.094175</td>\n",
       "      <td>2.601198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      AUC  Accuracy  Epoch max reach  \\\n",
       "simple NN - raw text             0.814432  0.749333              8.0   \n",
       "simple NN - Basic preprocessing  0.817025  0.731667              7.0   \n",
       "simple NN - Stemming             0.823142  0.743667              6.0   \n",
       "simple NN - Lemmatization        0.823922  0.747333              6.0   \n",
       "simple NN - GLoVe embedding      0.788596  0.720000             11.0   \n",
       "\n",
       "                                 total training time  training time to opt  \n",
       "simple NN - raw text                       12.445643              6.637676  \n",
       "simple NN - Basic preprocessing            11.445507              5.341237  \n",
       "simple NN - Stemming                       10.423989              4.169596  \n",
       "simple NN - Lemmatization                  11.959692              4.783877  \n",
       "simple NN - GLoVe embedding                 7.094175              2.601198  "
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 30, 100)           2056400   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,098,705\n",
      "Trainable params: 2,098,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'LSTM - Own embedding '\n",
    "\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(LSTM(lstm_out,dropout=0.4))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 0.6935 - accuracy: 0.5008 - auc: 0.5000 - val_loss: 0.6931 - val_accuracy: 0.5027 - val_auc: 0.5362\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 3s 261ms/step - loss: 0.6926 - accuracy: 0.5077 - auc: 0.5303 - val_loss: 0.6914 - val_accuracy: 0.5383 - val_auc: 0.5682\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 3s 264ms/step - loss: 0.6705 - accuracy: 0.5973 - auc: 0.6439 - val_loss: 0.6039 - val_accuracy: 0.6797 - val_auc: 0.7438\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 3s 257ms/step - loss: 0.5270 - accuracy: 0.7512 - auc: 0.8180 - val_loss: 0.5339 - val_accuracy: 0.7290 - val_auc: 0.8170\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 3s 263ms/step - loss: 0.3967 - accuracy: 0.8363 - auc: 0.9017 - val_loss: 0.5285 - val_accuracy: 0.7443 - val_auc: 0.8279\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 3s 267ms/step - loss: 0.2826 - accuracy: 0.8921 - auc: 0.9497 - val_loss: 0.5824 - val_accuracy: 0.7377 - val_auc: 0.8240\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 3s 255ms/step - loss: 0.2062 - accuracy: 0.9265 - auc: 0.9719 - val_loss: 0.6616 - val_accuracy: 0.7223 - val_auc: 0.8121\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.1506 - accuracy: 0.9498 - auc: 0.9839 - val_loss: 0.7022 - val_accuracy: 0.7167 - val_auc: 0.7954\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 3s 287ms/step - loss: 0.1215 - accuracy: 0.9604 - auc: 0.9884 - val_loss: 0.8243 - val_accuracy: 0.7087 - val_auc: 0.7849\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 4s 299ms/step - loss: 0.1001 - accuracy: 0.9679 - auc: 0.9914 - val_loss: 0.9267 - val_accuracy: 0.7000 - val_auc: 0.7790\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 3s 290ms/step - loss: 0.0806 - accuracy: 0.9738 - auc: 0.9942 - val_loss: 0.9165 - val_accuracy: 0.7070 - val_auc: 0.7778\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 3s 279ms/step - loss: 0.0671 - accuracy: 0.9786 - auc: 0.9957 - val_loss: 1.0056 - val_accuracy: 0.6933 - val_auc: 0.7669\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 3s 291ms/step - loss: 0.0613 - accuracy: 0.9812 - auc: 0.9959 - val_loss: 1.0036 - val_accuracy: 0.6963 - val_auc: 0.7710\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 4s 328ms/step - loss: 0.0531 - accuracy: 0.9845 - auc: 0.9959 - val_loss: 1.1520 - val_accuracy: 0.7020 - val_auc: 0.7632\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 4s 304ms/step - loss: 0.0510 - accuracy: 0.9848 - auc: 0.9970 - val_loss: 1.1835 - val_accuracy: 0.6927 - val_auc: 0.7584\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 4s 301ms/step - loss: 0.0517 - accuracy: 0.9830 - auc: 0.9966 - val_loss: 1.0910 - val_accuracy: 0.6850 - val_auc: 0.7591\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 4s 308ms/step - loss: 0.0464 - accuracy: 0.9851 - auc: 0.9971 - val_loss: 1.1595 - val_accuracy: 0.7003 - val_auc: 0.7603\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 0.0482 - accuracy: 0.9849 - auc: 0.9968 - val_loss: 1.1664 - val_accuracy: 0.7017 - val_auc: 0.7578\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 4s 307ms/step - loss: 0.0452 - accuracy: 0.9859 - auc: 0.9972 - val_loss: 1.1009 - val_accuracy: 0.6897 - val_auc: 0.7578\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 4s 294ms/step - loss: 0.0398 - accuracy: 0.9886 - auc: 0.9974 - val_loss: 1.2157 - val_accuracy: 0.6880 - val_auc: 0.7523\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 4s 302ms/step - loss: 0.0356 - accuracy: 0.9902 - auc: 0.9976 - val_loss: 1.1774 - val_accuracy: 0.6967 - val_auc: 0.7522\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 4s 309ms/step - loss: 0.0329 - accuracy: 0.9903 - auc: 0.9980 - val_loss: 1.3417 - val_accuracy: 0.6923 - val_auc: 0.7422\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 4s 305ms/step - loss: 0.0318 - accuracy: 0.9905 - auc: 0.9982 - val_loss: 1.2879 - val_accuracy: 0.6847 - val_auc: 0.7440\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 4s 338ms/step - loss: 0.0313 - accuracy: 0.9916 - auc: 0.9981 - val_loss: 1.3380 - val_accuracy: 0.6837 - val_auc: 0.7409\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 4s 317ms/step - loss: 0.0297 - accuracy: 0.9913 - auc: 0.9983 - val_loss: 1.3668 - val_accuracy: 0.6897 - val_auc: 0.7417\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 3s 269ms/step - loss: 0.0324 - accuracy: 0.9912 - auc: 0.9979 - val_loss: 1.4158 - val_accuracy: 0.6820 - val_auc: 0.7351\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 3s 281ms/step - loss: 0.0311 - accuracy: 0.9918 - auc: 0.9983 - val_loss: 1.5064 - val_accuracy: 0.6840 - val_auc: 0.7316\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.0331 - accuracy: 0.9895 - auc: 0.9979 - val_loss: 1.4353 - val_accuracy: 0.6753 - val_auc: 0.7299\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 3s 284ms/step - loss: 0.0301 - accuracy: 0.9907 - auc: 0.9983 - val_loss: 1.4228 - val_accuracy: 0.6813 - val_auc: 0.7328\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 4s 293ms/step - loss: 0.0277 - accuracy: 0.9911 - auc: 0.9984 - val_loss: 1.5097 - val_accuracy: 0.6863 - val_auc: 0.7295\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>0.814432</td>\n",
       "      <td>0.749333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.445643</td>\n",
       "      <td>6.637676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>0.817025</td>\n",
       "      <td>0.731667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.445507</td>\n",
       "      <td>5.341237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Stemming</th>\n",
       "      <td>0.823142</td>\n",
       "      <td>0.743667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.423989</td>\n",
       "      <td>4.169596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Lemmatization</th>\n",
       "      <td>0.823922</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.959692</td>\n",
       "      <td>4.783877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - GLoVe embedding</th>\n",
       "      <td>0.788596</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.094175</td>\n",
       "      <td>2.601198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - Own embedding</th>\n",
       "      <td>0.827899</td>\n",
       "      <td>0.744333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>116.729051</td>\n",
       "      <td>15.563873</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      AUC  Accuracy  Epoch max reach  \\\n",
       "simple NN - raw text             0.814432  0.749333              8.0   \n",
       "simple NN - Basic preprocessing  0.817025  0.731667              7.0   \n",
       "simple NN - Stemming             0.823142  0.743667              6.0   \n",
       "simple NN - Lemmatization        0.823922  0.747333              6.0   \n",
       "simple NN - GLoVe embedding      0.788596  0.720000             11.0   \n",
       "LSTM - Own embedding             0.827899  0.744333              4.0   \n",
       "\n",
       "                                 total training time  training time to opt  \n",
       "simple NN - raw text                       12.445643              6.637676  \n",
       "simple NN - Basic preprocessing            11.445507              5.341237  \n",
       "simple NN - Stemming                       10.423989              4.169596  \n",
       "simple NN - Lemmatization                  11.959692              4.783877  \n",
       "simple NN - GLoVe embedding                 7.094175              2.601198  \n",
       "LSTM - Own embedding                      116.729051             15.563873  "
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With GLoVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 30, 100)           2056600   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 2,098,905\n",
      "Trainable params: 42,305\n",
      "Non-trainable params: 2,056,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=0.2))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "12/12 [==============================] - 3s 286ms/step - loss: 0.6901 - accuracy: 0.5266 - auc: 0.5452 - val_loss: 0.6837 - val_accuracy: 0.5343 - val_auc: 0.6937\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 3s 250ms/step - loss: 0.6417 - accuracy: 0.6422 - auc: 0.7118 - val_loss: 0.5901 - val_accuracy: 0.7023 - val_auc: 0.7640\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 3s 228ms/step - loss: 0.5763 - accuracy: 0.7069 - auc: 0.7704 - val_loss: 0.5536 - val_accuracy: 0.7217 - val_auc: 0.7974\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 3s 230ms/step - loss: 0.5468 - accuracy: 0.7274 - auc: 0.7980 - val_loss: 0.5310 - val_accuracy: 0.7353 - val_auc: 0.8142\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 3s 225ms/step - loss: 0.5303 - accuracy: 0.7334 - auc: 0.8139 - val_loss: 0.5243 - val_accuracy: 0.7387 - val_auc: 0.8213\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 3s 229ms/step - loss: 0.5233 - accuracy: 0.7387 - auc: 0.8192 - val_loss: 0.5168 - val_accuracy: 0.7453 - val_auc: 0.8248\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 3s 235ms/step - loss: 0.5160 - accuracy: 0.7473 - auc: 0.8243 - val_loss: 0.5125 - val_accuracy: 0.7473 - val_auc: 0.8275\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 3s 233ms/step - loss: 0.5110 - accuracy: 0.7486 - auc: 0.8277 - val_loss: 0.5089 - val_accuracy: 0.7530 - val_auc: 0.8304\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 3s 236ms/step - loss: 0.5062 - accuracy: 0.7513 - auc: 0.8314 - val_loss: 0.5084 - val_accuracy: 0.7470 - val_auc: 0.8336\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 3s 248ms/step - loss: 0.5049 - accuracy: 0.7508 - auc: 0.8314 - val_loss: 0.5207 - val_accuracy: 0.7407 - val_auc: 0.8332\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 3s 262ms/step - loss: 0.4971 - accuracy: 0.7539 - auc: 0.8373 - val_loss: 0.4993 - val_accuracy: 0.7577 - val_auc: 0.8378\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 4s 310ms/step - loss: 0.4895 - accuracy: 0.7614 - auc: 0.8425 - val_loss: 0.4937 - val_accuracy: 0.7587 - val_auc: 0.8415\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 3s 230ms/step - loss: 0.4792 - accuracy: 0.7700 - auc: 0.8504 - val_loss: 0.5006 - val_accuracy: 0.7570 - val_auc: 0.8404\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 3s 221ms/step - loss: 0.4758 - accuracy: 0.7702 - auc: 0.8526 - val_loss: 0.4950 - val_accuracy: 0.7557 - val_auc: 0.8432\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 3s 219ms/step - loss: 0.4730 - accuracy: 0.7734 - auc: 0.8545 - val_loss: 0.4924 - val_accuracy: 0.7640 - val_auc: 0.8453\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 0.4677 - accuracy: 0.7779 - auc: 0.8578 - val_loss: 0.4919 - val_accuracy: 0.7647 - val_auc: 0.8454\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 3s 230ms/step - loss: 0.4610 - accuracy: 0.7807 - auc: 0.8631 - val_loss: 0.4834 - val_accuracy: 0.7683 - val_auc: 0.8485\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 3s 245ms/step - loss: 0.4591 - accuracy: 0.7788 - auc: 0.8642 - val_loss: 0.4842 - val_accuracy: 0.7693 - val_auc: 0.8478\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 3s 249ms/step - loss: 0.4576 - accuracy: 0.7824 - auc: 0.8654 - val_loss: 0.4982 - val_accuracy: 0.7637 - val_auc: 0.8490\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 3s 230ms/step - loss: 0.4470 - accuracy: 0.7924 - auc: 0.8723 - val_loss: 0.4877 - val_accuracy: 0.7673 - val_auc: 0.8487\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 3s 252ms/step - loss: 0.4410 - accuracy: 0.7945 - auc: 0.8755 - val_loss: 0.4845 - val_accuracy: 0.7667 - val_auc: 0.8480\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 3s 236ms/step - loss: 0.4374 - accuracy: 0.7949 - auc: 0.8779 - val_loss: 0.4936 - val_accuracy: 0.7653 - val_auc: 0.8481\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 3s 276ms/step - loss: 0.4329 - accuracy: 0.7981 - auc: 0.8811 - val_loss: 0.4880 - val_accuracy: 0.7700 - val_auc: 0.8483\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 3s 263ms/step - loss: 0.4260 - accuracy: 0.8034 - auc: 0.8852 - val_loss: 0.4894 - val_accuracy: 0.7643 - val_auc: 0.8464\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 3s 247ms/step - loss: 0.4256 - accuracy: 0.8050 - auc: 0.8854 - val_loss: 0.4965 - val_accuracy: 0.7650 - val_auc: 0.8467\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 3s 239ms/step - loss: 0.4185 - accuracy: 0.8092 - auc: 0.8892 - val_loss: 0.4908 - val_accuracy: 0.7653 - val_auc: 0.8486\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 3s 226ms/step - loss: 0.4180 - accuracy: 0.8053 - auc: 0.8894 - val_loss: 0.4966 - val_accuracy: 0.7637 - val_auc: 0.8472\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 3s 223ms/step - loss: 0.4128 - accuracy: 0.8076 - auc: 0.8926 - val_loss: 0.5064 - val_accuracy: 0.7660 - val_auc: 0.8499\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 3s 234ms/step - loss: 0.4082 - accuracy: 0.8152 - auc: 0.8952 - val_loss: 0.5096 - val_accuracy: 0.7670 - val_auc: 0.8476\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 3s 225ms/step - loss: 0.4120 - accuracy: 0.8133 - auc: 0.8929 - val_loss: 0.5007 - val_accuracy: 0.7687 - val_auc: 0.8478\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "acc = hist.history['accuracy']\n",
    "val = hist.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, '-', label='Training accuracy')\n",
    "plt.plot(epochs, val, ':', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>0.814432</td>\n",
       "      <td>0.749333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.445643</td>\n",
       "      <td>6.637676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>0.817025</td>\n",
       "      <td>0.731667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.445507</td>\n",
       "      <td>5.341237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Stemming</th>\n",
       "      <td>0.823142</td>\n",
       "      <td>0.743667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.423989</td>\n",
       "      <td>4.169596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Lemmatization</th>\n",
       "      <td>0.823922</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.959692</td>\n",
       "      <td>4.783877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - GLoVe embedding</th>\n",
       "      <td>0.788596</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.094175</td>\n",
       "      <td>2.601198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - Own embedding</th>\n",
       "      <td>0.827899</td>\n",
       "      <td>0.744333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>116.729051</td>\n",
       "      <td>15.563873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.849900</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>96.783377</td>\n",
       "      <td>70.974476</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      AUC  Accuracy  Epoch max reach  \\\n",
       "simple NN - raw text             0.814432  0.749333              8.0   \n",
       "simple NN - Basic preprocessing  0.817025  0.731667              7.0   \n",
       "simple NN - Stemming             0.823142  0.743667              6.0   \n",
       "simple NN - Lemmatization        0.823922  0.747333              6.0   \n",
       "simple NN - GLoVe embedding      0.788596  0.720000             11.0   \n",
       "LSTM - Own embedding             0.827899  0.744333              4.0   \n",
       "LSTM - GLoVe embedding           0.849900  0.770000             22.0   \n",
       "\n",
       "                                 total training time  training time to opt  \n",
       "simple NN - raw text                       12.445643              6.637676  \n",
       "simple NN - Basic preprocessing            11.445507              5.341237  \n",
       "simple NN - Stemming                       10.423989              4.169596  \n",
       "simple NN - Lemmatization                  11.959692              4.783877  \n",
       "simple NN - GLoVe embedding                 7.094175              2.601198  \n",
       "LSTM - Own embedding                      116.729051             15.563873  \n",
       "LSTM - GLoVe embedding                     96.783377             70.974476  "
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      (None, 30, 100)           2056600   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,141,209\n",
      "Trainable params: 84,609\n",
      "Non-trainable params: 2,056,600\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'biLSTM - GLoVe embedding'\n",
    "\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(Bidirectional(LSTM(lstm_out,dropout=0.2)))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "12/12 [==============================] - 6s 537ms/step - loss: 0.6701 - accuracy: 0.5965 - auc: 0.6507 - val_loss: 0.6352 - val_accuracy: 0.6737 - val_auc: 0.7465\n",
      "Epoch 2/30\n",
      "12/12 [==============================] - 5s 400ms/step - loss: 0.6066 - accuracy: 0.6827 - auc: 0.7446 - val_loss: 0.5706 - val_accuracy: 0.7123 - val_auc: 0.7773\n",
      "Epoch 3/30\n",
      "12/12 [==============================] - 6s 469ms/step - loss: 0.5521 - accuracy: 0.7179 - auc: 0.7909 - val_loss: 0.5389 - val_accuracy: 0.7293 - val_auc: 0.8035\n",
      "Epoch 4/30\n",
      "12/12 [==============================] - 5s 448ms/step - loss: 0.5323 - accuracy: 0.7298 - auc: 0.8089 - val_loss: 0.5258 - val_accuracy: 0.7343 - val_auc: 0.8179\n",
      "Epoch 5/30\n",
      "12/12 [==============================] - 5s 426ms/step - loss: 0.5159 - accuracy: 0.7436 - auc: 0.8234 - val_loss: 0.5238 - val_accuracy: 0.7420 - val_auc: 0.8219\n",
      "Epoch 6/30\n",
      "12/12 [==============================] - 6s 468ms/step - loss: 0.5098 - accuracy: 0.7473 - auc: 0.8277 - val_loss: 0.5167 - val_accuracy: 0.7430 - val_auc: 0.8266\n",
      "Epoch 7/30\n",
      "12/12 [==============================] - 5s 457ms/step - loss: 0.5000 - accuracy: 0.7521 - auc: 0.8352 - val_loss: 0.5082 - val_accuracy: 0.7503 - val_auc: 0.8299\n",
      "Epoch 8/30\n",
      "12/12 [==============================] - 6s 462ms/step - loss: 0.4975 - accuracy: 0.7567 - auc: 0.8371 - val_loss: 0.5043 - val_accuracy: 0.7470 - val_auc: 0.8336\n",
      "Epoch 9/30\n",
      "12/12 [==============================] - 5s 456ms/step - loss: 0.4893 - accuracy: 0.7618 - auc: 0.8431 - val_loss: 0.5020 - val_accuracy: 0.7603 - val_auc: 0.8362\n",
      "Epoch 10/30\n",
      "12/12 [==============================] - 5s 430ms/step - loss: 0.4856 - accuracy: 0.7653 - auc: 0.8461 - val_loss: 0.5005 - val_accuracy: 0.7563 - val_auc: 0.8379\n",
      "Epoch 11/30\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 0.4835 - accuracy: 0.7643 - auc: 0.8471 - val_loss: 0.4974 - val_accuracy: 0.7570 - val_auc: 0.8399\n",
      "Epoch 12/30\n",
      "12/12 [==============================] - 5s 449ms/step - loss: 0.4749 - accuracy: 0.7698 - auc: 0.8531 - val_loss: 0.5032 - val_accuracy: 0.7547 - val_auc: 0.8415\n",
      "Epoch 13/30\n",
      "12/12 [==============================] - 5s 399ms/step - loss: 0.4738 - accuracy: 0.7754 - auc: 0.8540 - val_loss: 0.4913 - val_accuracy: 0.7617 - val_auc: 0.8428\n",
      "Epoch 14/30\n",
      "12/12 [==============================] - 5s 417ms/step - loss: 0.4613 - accuracy: 0.7803 - auc: 0.8630 - val_loss: 0.4937 - val_accuracy: 0.7643 - val_auc: 0.8452\n",
      "Epoch 15/30\n",
      "12/12 [==============================] - 5s 431ms/step - loss: 0.4575 - accuracy: 0.7801 - auc: 0.8653 - val_loss: 0.4889 - val_accuracy: 0.7667 - val_auc: 0.8465\n",
      "Epoch 16/30\n",
      "12/12 [==============================] - 5s 426ms/step - loss: 0.4492 - accuracy: 0.7861 - auc: 0.8704 - val_loss: 0.4849 - val_accuracy: 0.7643 - val_auc: 0.8476\n",
      "Epoch 17/30\n",
      "12/12 [==============================] - 5s 437ms/step - loss: 0.4443 - accuracy: 0.7890 - auc: 0.8732 - val_loss: 0.5136 - val_accuracy: 0.7533 - val_auc: 0.8450\n",
      "Epoch 18/30\n",
      "12/12 [==============================] - 5s 439ms/step - loss: 0.4409 - accuracy: 0.7889 - auc: 0.8754 - val_loss: 0.4863 - val_accuracy: 0.7723 - val_auc: 0.8494\n",
      "Epoch 19/30\n",
      "12/12 [==============================] - 5s 425ms/step - loss: 0.4357 - accuracy: 0.7923 - auc: 0.8786 - val_loss: 0.4948 - val_accuracy: 0.7663 - val_auc: 0.8488\n",
      "Epoch 20/30\n",
      "12/12 [==============================] - 6s 472ms/step - loss: 0.4265 - accuracy: 0.8030 - auc: 0.8845 - val_loss: 0.4873 - val_accuracy: 0.7703 - val_auc: 0.8498\n",
      "Epoch 21/30\n",
      "12/12 [==============================] - 5s 432ms/step - loss: 0.4277 - accuracy: 0.8005 - auc: 0.8838 - val_loss: 0.4927 - val_accuracy: 0.7647 - val_auc: 0.8497\n",
      "Epoch 22/30\n",
      "12/12 [==============================] - 5s 441ms/step - loss: 0.4180 - accuracy: 0.8084 - auc: 0.8891 - val_loss: 0.4861 - val_accuracy: 0.7697 - val_auc: 0.8501\n",
      "Epoch 23/30\n",
      "12/12 [==============================] - 5s 453ms/step - loss: 0.4092 - accuracy: 0.8119 - auc: 0.8945 - val_loss: 0.4924 - val_accuracy: 0.7743 - val_auc: 0.8503\n",
      "Epoch 24/30\n",
      "12/12 [==============================] - 5s 433ms/step - loss: 0.4088 - accuracy: 0.8102 - auc: 0.8943 - val_loss: 0.4908 - val_accuracy: 0.7723 - val_auc: 0.8489\n",
      "Epoch 25/30\n",
      "12/12 [==============================] - 5s 455ms/step - loss: 0.4044 - accuracy: 0.8160 - auc: 0.8976 - val_loss: 0.5033 - val_accuracy: 0.7627 - val_auc: 0.8488\n",
      "Epoch 26/30\n",
      "12/12 [==============================] - 5s 452ms/step - loss: 0.3997 - accuracy: 0.8180 - auc: 0.8998 - val_loss: 0.4966 - val_accuracy: 0.7700 - val_auc: 0.8487\n",
      "Epoch 27/30\n",
      "12/12 [==============================] - 5s 443ms/step - loss: 0.3949 - accuracy: 0.8174 - auc: 0.9020 - val_loss: 0.4974 - val_accuracy: 0.7710 - val_auc: 0.8481\n",
      "Epoch 28/30\n",
      "12/12 [==============================] - 5s 458ms/step - loss: 0.3933 - accuracy: 0.8202 - auc: 0.9029 - val_loss: 0.5121 - val_accuracy: 0.7610 - val_auc: 0.8509\n",
      "Epoch 29/30\n",
      "12/12 [==============================] - 6s 474ms/step - loss: 0.3867 - accuracy: 0.8235 - auc: 0.9066 - val_loss: 0.4968 - val_accuracy: 0.7703 - val_auc: 0.8502\n",
      "Epoch 30/30\n",
      "12/12 [==============================] - 5s 427ms/step - loss: 0.3776 - accuracy: 0.8311 - auc: 0.9113 - val_loss: 0.4974 - val_accuracy: 0.7693 - val_auc: 0.8496\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances.to_excel('data/perf_1K.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "acc = hist.history['accuracy']\n",
    "val = hist.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, '-', label='Training accuracy')\n",
    "plt.plot(epochs, val, ':', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>0.814432</td>\n",
       "      <td>0.749333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.445643</td>\n",
       "      <td>6.637676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>0.817025</td>\n",
       "      <td>0.731667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>11.445507</td>\n",
       "      <td>5.341237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Stemming</th>\n",
       "      <td>0.823142</td>\n",
       "      <td>0.743667</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.423989</td>\n",
       "      <td>4.169596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Lemmatization</th>\n",
       "      <td>0.823922</td>\n",
       "      <td>0.747333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.959692</td>\n",
       "      <td>4.783877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - GLoVe embedding</th>\n",
       "      <td>0.788596</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>11.0</td>\n",
       "      <td>7.094175</td>\n",
       "      <td>2.601198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - Own embedding</th>\n",
       "      <td>0.827899</td>\n",
       "      <td>0.744333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>116.729051</td>\n",
       "      <td>15.563873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.849900</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>96.783377</td>\n",
       "      <td>70.974476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biLSTM - GLoVe embedding</th>\n",
       "      <td>0.850876</td>\n",
       "      <td>0.774333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>226.873566</td>\n",
       "      <td>166.373948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      AUC  Accuracy  Epoch max reach  \\\n",
       "simple NN - raw text             0.814432  0.749333              8.0   \n",
       "simple NN - Basic preprocessing  0.817025  0.731667              7.0   \n",
       "simple NN - Stemming             0.823142  0.743667              6.0   \n",
       "simple NN - Lemmatization        0.823922  0.747333              6.0   \n",
       "simple NN - GLoVe embedding      0.788596  0.720000             11.0   \n",
       "LSTM - Own embedding             0.827899  0.744333              4.0   \n",
       "LSTM - GLoVe embedding           0.849900  0.770000             22.0   \n",
       "biLSTM - GLoVe embedding         0.850876  0.774333             22.0   \n",
       "\n",
       "                                 total training time  training time to opt  \n",
       "simple NN - raw text                       12.445643              6.637676  \n",
       "simple NN - Basic preprocessing            11.445507              5.341237  \n",
       "simple NN - Stemming                       10.423989              4.169596  \n",
       "simple NN - Lemmatization                  11.959692              4.783877  \n",
       "simple NN - GLoVe embedding                 7.094175              2.601198  \n",
       "LSTM - Own embedding                      116.729051             15.563873  \n",
       "LSTM - GLoVe embedding                     96.783377             70.974476  \n",
       "biLSTM - GLoVe embedding                  226.873566            166.373948  "
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will whoose LSTM+Glove as our best model based on accuracy and training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of ressource limitation, we'll not perform a cross validation and gridsearch on hyperparameter, insted we'll just try different values and compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparamters_performances=pd.DataFrame(columns=['AUC','Accuracy_val','Epoch max reach'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "dp=0.2\n",
    "lr=0.001\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=dp))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy','AUC'])\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test),verbose=0)\n",
    "stop = time.time()\n",
    "\n",
    "hyperparamters_performances = hyperparamters_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "                    'dropout':dp,\n",
    "                    'learning_rate':lr,\n",
    "                    'lstm_out': lstm_out,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy_val': max(hist.history['val_accuracy']),\n",
    "              'Accuracy_test': max(hist.history['accuracy']), \n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "dp=0.2\n",
    "lr=0.01\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=dp))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy','AUC'])\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test),verbose=0)\n",
    "stop = time.time()\n",
    "\n",
    "hyperparamters_performances = hyperparamters_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "                    'dropout':dp,\n",
    "                    'learning_rate':lr,\n",
    "                    'lstm_out': lstm_out,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy_val': max(hist.history['val_accuracy']),\n",
    "              'Accuracy_test': max(hist.history['accuracy']),   \n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "dp=0.2\n",
    "lr=0.1\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=dp))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy','AUC'])\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test),verbose=0)\n",
    "stop = time.time()\n",
    "\n",
    "hyperparamters_performances = hyperparamters_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "                    'dropout':dp,\n",
    "                    'learning_rate':lr,\n",
    "                    'lstm_out': lstm_out,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy_val': max(hist.history['val_accuracy']),\n",
    "              'Accuracy_test': max(hist.history['accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy_val</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>lstm_out</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.850971</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.810750</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64.0</td>\n",
       "      <td>84.270123</td>\n",
       "      <td>70.225103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.856207</td>\n",
       "      <td>0.774333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.911583</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64.0</td>\n",
       "      <td>85.980738</td>\n",
       "      <td>17.196148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.831401</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.758833</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>64.0</td>\n",
       "      <td>91.059850</td>\n",
       "      <td>57.671238</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             AUC  Accuracy_val  Epoch max reach  \\\n",
       "LSTM - GLoVe embedding  0.850971      0.769000             25.0   \n",
       "LSTM - GLoVe embedding  0.856207      0.774333              6.0   \n",
       "LSTM - GLoVe embedding  0.831401      0.754000             19.0   \n",
       "\n",
       "                        Accuracy_test  dropout  learning_rate  lstm_out  \\\n",
       "LSTM - GLoVe embedding       0.810750      0.2          0.001      64.0   \n",
       "LSTM - GLoVe embedding       0.911583      0.2          0.010      64.0   \n",
       "LSTM - GLoVe embedding       0.758833      0.2          0.100      64.0   \n",
       "\n",
       "                        total training time  training time to opt  \n",
       "LSTM - GLoVe embedding            84.270123             70.225103  \n",
       "LSTM - GLoVe embedding            85.980738             17.196148  \n",
       "LSTM - GLoVe embedding            91.059850             57.671238  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparamters_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "dp=0\n",
    "lr=0.01\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=dp))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy','AUC'])\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=60, validation_data=(X_test_vect, y_test),verbose=0)\n",
    "stop = time.time()\n",
    "\n",
    "hyperparamters_performances = hyperparamters_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "                    'dropout':dp,\n",
    "                    'learning_rate':lr,\n",
    "                    'lstm_out': lstm_out,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy_val': max(hist.history['val_accuracy']),\n",
    "              'Accuracy_test': max(hist.history['accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "dp=0.1\n",
    "lr=0.01\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=dp))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy','AUC'])\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test),verbose=0)\n",
    "stop = time.time()\n",
    "\n",
    "hyperparamters_performances = hyperparamters_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "                    'dropout':dp,\n",
    "                    'learning_rate':lr,\n",
    "                    'lstm_out': lstm_out,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy_val': max(hist.history['val_accuracy']),\n",
    "              'Accuracy_test': max(hist.history['accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "dp=0.4\n",
    "lr=0.01\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=dp))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy','AUC'])\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test),verbose=0)\n",
    "stop = time.time()\n",
    "\n",
    "hyperparamters_performances = hyperparamters_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "                    'dropout':dp,\n",
    "                    'learning_rate':lr,\n",
    "                    'lstm_out': lstm_out,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy_val': max(hist.history['val_accuracy']),\n",
    "              'Accuracy_test': max(hist.history['accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "dp=0.8\n",
    "lr=0.01\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=dp))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy','AUC'])\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test),verbose=0)\n",
    "stop = time.time()\n",
    "\n",
    "hyperparamters_performances = hyperparamters_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "                    'dropout':dp,\n",
    "                    'learning_rate':lr,\n",
    "                    'lstm_out': lstm_out,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy_val': max(hist.history['val_accuracy']),\n",
    "              'Accuracy_test': max(hist.history['accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy_val</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>lstm_out</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.850971</td>\n",
       "      <td>0.769000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.810750</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64.0</td>\n",
       "      <td>84.270123</td>\n",
       "      <td>70.225103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.856207</td>\n",
       "      <td>0.774333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.911583</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64.0</td>\n",
       "      <td>85.980738</td>\n",
       "      <td>17.196148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.831401</td>\n",
       "      <td>0.754000</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.758833</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>64.0</td>\n",
       "      <td>91.059850</td>\n",
       "      <td>57.671238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.857739</td>\n",
       "      <td>0.776333</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.988583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64.0</td>\n",
       "      <td>141.047381</td>\n",
       "      <td>9.403159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.857067</td>\n",
       "      <td>0.780667</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.955167</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64.0</td>\n",
       "      <td>114.911483</td>\n",
       "      <td>49.794976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.865676</td>\n",
       "      <td>0.788000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.838333</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64.0</td>\n",
       "      <td>111.909359</td>\n",
       "      <td>67.145615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.835527</td>\n",
       "      <td>0.758333</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.704250</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64.0</td>\n",
       "      <td>90.931730</td>\n",
       "      <td>72.745384</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             AUC  Accuracy_val  Epoch max reach  \\\n",
       "LSTM - GLoVe embedding  0.850971      0.769000             25.0   \n",
       "LSTM - GLoVe embedding  0.856207      0.774333              6.0   \n",
       "LSTM - GLoVe embedding  0.831401      0.754000             19.0   \n",
       "LSTM - GLoVe embedding  0.857739      0.776333              4.0   \n",
       "LSTM - GLoVe embedding  0.857067      0.780667             13.0   \n",
       "LSTM - GLoVe embedding  0.865676      0.788000             18.0   \n",
       "LSTM - GLoVe embedding  0.835527      0.758333             24.0   \n",
       "\n",
       "                        Accuracy_test  dropout  learning_rate  lstm_out  \\\n",
       "LSTM - GLoVe embedding       0.810750      0.2          0.001      64.0   \n",
       "LSTM - GLoVe embedding       0.911583      0.2          0.010      64.0   \n",
       "LSTM - GLoVe embedding       0.758833      0.2          0.100      64.0   \n",
       "LSTM - GLoVe embedding       0.988583      0.0          0.010      64.0   \n",
       "LSTM - GLoVe embedding       0.955167      0.1          0.010      64.0   \n",
       "LSTM - GLoVe embedding       0.838333      0.4          0.010      64.0   \n",
       "LSTM - GLoVe embedding       0.704250      0.8          0.010      64.0   \n",
       "\n",
       "                        total training time  training time to opt  \n",
       "LSTM - GLoVe embedding            84.270123             70.225103  \n",
       "LSTM - GLoVe embedding            85.980738             17.196148  \n",
       "LSTM - GLoVe embedding            91.059850             57.671238  \n",
       "LSTM - GLoVe embedding           141.047381              9.403159  \n",
       "LSTM - GLoVe embedding           114.911483             49.794976  \n",
       "LSTM - GLoVe embedding           111.909359             67.145615  \n",
       "LSTM - GLoVe embedding            90.931730             72.745384  "
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparamters_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparamters_performances.to_excel('data/hyp_perf_15K.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "408.767px",
    "left": "1625px",
    "right": "20px",
    "top": "120px",
    "width": "275px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
