{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"black\"><font size=\"7\"><br>\n",
    "     Project 7 - Advanced Model\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"D:/Data OC/P7/sentiment140/training.1600000.processed.noemoticon.csv\",header=None,names=['target','text'],usecols=[0,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = data['target']/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype({'target':'int32'},copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-1fefe5df47d9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_pickle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'data/data'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "data.to_pickle('data/data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data['target'])\n",
    "plt.title('target distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acuuracy is a good metric for measuring a balanced classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of words per tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_text = data.text.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words =[len(text) for text in splitted_text.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Number of words per tweet')\n",
    "sns.histplot(nb_words)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionnary = {}\n",
    "for sentence in splitted_text:\n",
    "    for word in sentence:\n",
    "        if word in dictionnary.keys():\n",
    "            dictionnary[word]+=1\n",
    "        else:\n",
    "            dictionnary[word]=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pd.DataFrame.from_dict(dictionnary,orient='index',columns=['nb_occur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1350277, 1)"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20209, 1)"
      ]
     },
     "execution_count": 310,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[vocab['nb_occur']>46].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(113823, 1)"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[vocab['nb_occur']>5].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(data, y = None):\n",
    "    '''tokenizes input dataframe considering words of 2 and more characters\n",
    "       and lowercase text and remove numbers\n",
    "    \n",
    "       Parameters\n",
    "       ----------\n",
    "       data : Pandas series to tokenize\n",
    "       \n",
    "       Returns\n",
    "       --------\n",
    "       Pandas series list of tokens'''\n",
    "              \n",
    "        \n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w{2,}')\n",
    "    sentences = data.str.lower()\n",
    "    sentences = sentences.str.replace('\\d+', '',regex=True)\n",
    "    results = sentences.apply(tokenizer.tokenize)\n",
    "  \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a transformer for pipeline integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_transformer = FunctionTransformer(func=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(data, y = None, stemmer = PorterStemmer()):\n",
    "    ''' Stems data using stemmer returns stems as a list of strings'''\n",
    "\n",
    "\n",
    "    def stem_sentence(tokenized_sentence):\n",
    "        stems = [stemmer.stem(i) for i in tokenized_sentence]\n",
    "        return stems\n",
    "    \n",
    "    return data.apply(stem_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a transformer for pipeline integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer_transformer = FunctionTransformer(func=stemmer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "542872     @TomFelton Given the state of the Australian c...\n",
       "515784     Eurgh, trying to get free Xfactor tickets but ...\n",
       "627433     Stuck in rush hour traffic being forced to enh...\n",
       "1373960                             got new eyebrows!! yay! \n",
       "1298704    @deniseneil Sorry to dash your daydreams, but ...\n",
       "                                 ...                        \n",
       "108505     At the plaza  bout to head home gotta clean al...\n",
       "786857     @birriepie i wanted to go late night but no on...\n",
       "1587469                  @gigsandtours did i win tickets :| \n",
       "460257                                   where's  my fro yo \n",
       "660488                       @YellowHail oh i see  pahaa xxx\n",
       "Name: text, Length: 40000, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = stemmer_transformer.transform(tokenizer_transformer.transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "542872     tomfelton given the state of the australian cr...\n",
       "515784     eurgh tri to get free xfactor ticket but it se...\n",
       "627433     stuck in rush hour traffic be forc to enhal th...\n",
       "1373960                                  got new eyebrow yay\n",
       "1298704    deniseneil sorri to dash your daydream but she...\n",
       "                                 ...                        \n",
       "108505     at the plaza bout to head home gotta clean all...\n",
       "786857     birriepi want to go late night but no one woul...\n",
       "1587469                           gigsandtour did win ticket\n",
       "460257                                       where my fro yo\n",
       "660488                           yellowhail oh see pahaa xxx\n",
       "Name: text, Length: 40000, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.str.join(sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(data, y = None, lemmatizer = WordNetLemmatizer()):\n",
    "    \n",
    "    def get_wordnet_pos(word):\n",
    "    #Map POS tag to first character lemmatize() accepts\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "    def lem_sentence(tokenized_sentence):\n",
    "        lems = [lemmatizer.lemmatize(i,pos=get_wordnet_pos(i)) for i in tokenized_sentence]\n",
    "        return lems \n",
    "\n",
    "    \n",
    "    return data.apply(lem_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a transformer for pipeline integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer_transformer = FunctionTransformer(func=lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(data, stopwords = nltk.corpus.stopwords.words('english')):\n",
    "    '''Remove stopwords from data'''\n",
    "\n",
    "    # remove stopwords from stems and create a new column\n",
    "    results = [[stem for stem in stems if (\n",
    "        not(stem in stopwords))] for stems in data]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a transformer for pipeline integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords_transformer = FunctionTransformer(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_stem = Pipeline([('Tokenizer',tokenizer_transformer),\n",
    "                      ('Stemmer',stemmer_transformer),\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lem = Pipeline([('Tokenizer',tokenizer_transformer),\n",
    "                      ('lemmatizer',lemmatizer_transformer),\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fastext_Transformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = FT_gensim(size=50,min_count=10,)     \n",
    "        \n",
    "        \n",
    "    def build_doc2vec_corpus(self,texts):\n",
    "        '''Returns a training corpus in the appropriate gensim Taggeddocument format'''\n",
    "        results = []\n",
    "        for tag,text in enumerate(texts):\n",
    "            results.append(gensim.models.doc2vec.TaggedDocument(text,[tag]))\n",
    "        return results\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        self.train_corpus = list(self.build_doc2vec_corpus(X))\n",
    "        self.model.build_vocab(sentences=X.values)\n",
    "        self.model.train(X.values,\n",
    "                         epochs=self.model.epochs,\n",
    "                         total_examples=self.model.corpus_count,\n",
    "                         total_words=self.model.corpus_total_words\n",
    "                        )\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def vectorized_sentence(self,sentence):\n",
    "        wordvecs_sent = [self.model.wv[word] for word in sentence]\n",
    "        meanvec_sent = np.array(wordvecs_sent).mean(axis=0)\n",
    "        return meanvec_sent\n",
    "        \n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self.vectorized_sentence(text) for text in X]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre trained Glove Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll use the glove pretrained vector with a dimension of 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = gensim.downloader.load('glove-twitter-50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentence_pretrained(sentence,Keyedvectors= glove_vectors):\n",
    "    wordvecs_sent = [Keyedvectors[word] for word in sentence if word in Keyedvectors]\n",
    "    if len(wordvecs_sent)>0:\n",
    "        meanvec_sent = np.array(wordvecs_sent).mean(axis=0)\n",
    "    else:\n",
    "        meanvec_sent = np.zeros(Keyedvectors.vector_size)\n",
    "    return meanvec_sent\n",
    "\n",
    "def vectorize_corpus_glove(data):\n",
    "    return [vectorize_sentence_pretrained(text) for text in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Glove_transformer = FunctionTransformer(func=vectorize_corpus_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Doc2vec_Transformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = gensim.models.doc2vec.Doc2Vec(vector_size=50, min_count=10, epochs=60)        \n",
    "        self.train_corpus=[]\n",
    "        \n",
    "    def build_doc2vec_corpus(self,texts):\n",
    "        '''Returns a training corpus in the appropriate gensim Taggeddocument format'''\n",
    "        results = []\n",
    "        for tag,text in enumerate(texts):\n",
    "            results.append(gensim.models.doc2vec.TaggedDocument(text,[tag]))\n",
    "        return results\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        self.train_corpus = list(self.build_doc2vec_corpus(X))\n",
    "        self.model.build_vocab(self.train_corpus)\n",
    "        self.model.train(self.train_corpus, total_examples=self.model.corpus_count, epochs=self.model.epochs)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self.model.infer_vector(text) for text in X]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing preprocessings with Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a sample dataset for testing\n",
    "data_sample = data.sample(n=50000,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data_sample['text']\n",
    "y = data_sample['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Pipeline' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-217-474fb22fa155>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m pipe_lem_fastext = Pipeline([('preprocessing',pipe_lem),\n\u001b[0m\u001b[0;32m      2\u001b[0m                              \u001b[1;33m(\u001b[0m\u001b[1;34m'embedding'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFastext_Transformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                              \u001b[1;33m(\u001b[0m\u001b[1;34m'scaler'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                              ('classifier', LogisticRegression(C=1e-2))])\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Pipeline' is not defined"
     ]
    }
   ],
   "source": [
    "pipe_lem_fastext = Pipeline([('preprocessing',pipe_lem),\n",
    "                             ('embedding',Fastext_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe_lem_fastext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-218-c6cb8b291c1f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpipe_lem_fastext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mstop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Training time: {stop - start}s\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe_lem_fastext' is not defined"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pipe_lem_fastext.fit(X_train,y_train)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5985"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lem_fastext.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_stem_fastext = Pipeline([('preprocessing',pipe_stem),\n",
    "                             ('embedding',Fastext_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 8.224512815475464s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pipe_stem_fastext.fit(X_train,y_train)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.628"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_stem_fastext.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre trained Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wtih lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lem_glove = Pipeline([('preprocessing',pipe_lem),\n",
    "                             ('embedding',Glove_transformer),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 59.26274061203003s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pipe_lem_glove.fit(X_train,y_train)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7095"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lem_glove.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wtih stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_stem_glove = Pipeline([('preprocessing',pipe_stem),\n",
    "                             ('embedding',Glove_transformer),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 2.961422920227051s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pipe_stem_glove.fit(X_train,y_train)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6775"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_stem_glove.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wtih lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lem_doc2vec = Pipeline([('preprocessing',pipe_lem),\n",
    "                             ('embedding',Doc2vec_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 114.40022587776184s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pipe_lem_doc2vec.fit(X_train,y_train)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.673"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_lem_doc2vec.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wtih stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_stem_doc2vec = Pipeline([('preprocessing',pipe_stem),\n",
    "                             ('embedding',Doc2vec_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time: 58.13902759552002s\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "pipe_stem_doc2vec.fit(X_train,y_train)\n",
    "stop = time.time()\n",
    "print(f\"Training time: {stop - start}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.667"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_stem_doc2vec.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing text data to fit Keras requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the NN needs an input matrix with documents represented as an interger list, each interger is a word. we'll choose sequence length to be tweet_length(based on EDA it makes sense, if less than tweet_length use 0 padding) and vocabulary size max_token (based on preliminary EDA). We'll use Keras' vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_length = 30\n",
    "max_tokens = 40000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=max_tokens,output_sequence_length=tweet_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer.adapt(X_train.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to get the word corresponding to the integer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'retrorewind'"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_vocabulary()[7837]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to vectorize a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  4, 772, 826,  15,   4, 149,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0]], dtype=int64)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = vectorizer([[\"the cat sat on the school\"]])\n",
    "output.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sets(X_train,X_test,vocab_length=20000,tweet_length=30):\n",
    "    '''Compute and return the vectors of the documents in X_train and X_test with a fixed length'''\n",
    "    vectorizer = TextVectorization(max_tokens=vocab_length,output_sequence_length=tweet_length)\n",
    "    vectorizer.adapt(X_train.values)\n",
    "    voc = vectorizer.get_vocabulary() # vocabulary for futur use\n",
    "    word_index = dict(zip(voc, range(len(voc)))) # word index for futur use\n",
    "    return (vectorizer(X_train.values),vectorizer (X_test.values),voc,word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "183058     I can lose a lover but i cant lose a friend.  ...\n",
       "951667     @tayswift http://twitpic.com/2xtsl - Trace is ...\n",
       "886358     @andyclemmensen i have to agree with you on th...\n",
       "1171979    @mekster The BBQ part of it failed, we ended u...\n",
       "532978       @krisps  my awesome parade has been stormed on.\n",
       "                                 ...                        \n",
       "155641     @easymak caribou's a coffee chain up here. it'...\n",
       "263360           @playgrounds lmao you're breaking my heart \n",
       "648876              These gym sessions are killing my arms. \n",
       "933122     @Avery_Brandon thx 4 hitting me back! We have ...\n",
       "454143     @selenagomez i'm cryin' right outside!!!   but...\n",
       "Name: text, Length: 40000, dtype: object"
      ]
     },
     "execution_count": 255,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, voc_raw, word_index_raw = vectorize_sets(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    vocab_length=max_tokens,\n",
    "    tweet_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(40000, 30), dtype=int64, numpy=\n",
       "array([[    2,    65,   974, ...,     0,     0,     0],\n",
       "       [19946, 39323,  4582, ...,     0,     0,     0],\n",
       "       [ 2599,     2,    18, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [  398,   642,  5276, ...,     0,     0,     0],\n",
       "       [14029,   897,   188, ...,     0,     0,     0],\n",
       "       [ 1925,    14,  6976, ...,     0,     0,     0]], dtype=int64)>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect, X_test_vect, voc, word_index = vectorize_sets(\n",
    "    tokenizer_transformer.transform(X_train).str.join(sep=' '),\n",
    "    tokenizer_transformer.transform(X_test).str.join(sep=' '),\n",
    "    vocab_length=max_tokens,\n",
    "    tweet_length=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect_stem, X_test_vect_stem, voc_stem, word_index_stem = vectorize_sets(\n",
    "    stemmer_transformer.transform(tokenizer_transformer.transform(X_train)).str.join(sep=' '),\n",
    "    stemmer_transformer.transform(tokenizer_transformer.transform(X_test)).str.join(sep=' '),\n",
    "    vocab_length=max_tokens,\n",
    "    tweet_length=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_vect_lem, X_test_vect_lem, voc_lem, word_index_lem = vectorize_sets(\n",
    "#    lemmatizer_transformer.transform(tokenizer_transformer.transform(X_train)).str.join(sep=' '),\n",
    "#    lemmatizer_transformer.transform(tokenizer_transformer.transform(X_test)).str.join(sep=' '),\n",
    "#    vocab_length=max_tokens,\n",
    "#    tweet_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " raw vocab length 40000 \n",
      " no processing vocab length 40000 \n",
      " stem vocab length 40000 \n",
      " lem vocab length 20000\n"
     ]
    }
   ],
   "source": [
    "print(f' raw vocab length {len(voc_raw)} \\n no processing vocab length {len(voc)} \\n stem vocab length {len(voc_stem)} \\n lem vocab length {len(voc_lem)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing preprocessing on a simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances=pd.DataFrame(columns=[ 'training_time','predict_time','AUC','Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, 30, 50)            2000000   \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 8)                 12008     \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,012,017\n",
      "Trainable params: 2,012,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'simple NN - raw text'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(voc_raw),50 ,input_length = tweet_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "40/40 [==============================] - 2s 53ms/step - loss: 0.6823 - accuracy: 0.5681 - auc: 0.6111 - val_loss: 0.6523 - val_accuracy: 0.6590 - val_auc: 0.7219\n",
      "Epoch 2/15\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.5802 - accuracy: 0.7323 - auc: 0.8014 - val_loss: 0.5480 - val_accuracy: 0.7227 - val_auc: 0.8075\n",
      "Epoch 3/15\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.4328 - accuracy: 0.8195 - auc: 0.8949 - val_loss: 0.5024 - val_accuracy: 0.7540 - val_auc: 0.8340\n",
      "Epoch 4/15\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.3196 - accuracy: 0.8821 - auc: 0.9478 - val_loss: 0.5045 - val_accuracy: 0.7539 - val_auc: 0.8362\n",
      "Epoch 5/15\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.2320 - accuracy: 0.9230 - auc: 0.9749 - val_loss: 0.5250 - val_accuracy: 0.7509 - val_auc: 0.8284\n",
      "Epoch 6/15\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.1685 - accuracy: 0.9489 - auc: 0.9876 - val_loss: 0.5430 - val_accuracy: 0.7465 - val_auc: 0.8253\n",
      "Epoch 7/15\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1256 - accuracy: 0.9645 - auc: 0.9935 - val_loss: 0.5734 - val_accuracy: 0.7411 - val_auc: 0.8207\n",
      "Epoch 8/15\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.0973 - accuracy: 0.9739 - auc: 0.9962 - val_loss: 0.5998 - val_accuracy: 0.7418 - val_auc: 0.8160\n",
      "Epoch 9/15\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.0765 - accuracy: 0.9811 - auc: 0.9977 - val_loss: 0.6337 - val_accuracy: 0.7384 - val_auc: 0.8115\n",
      "Epoch 10/15\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.0622 - accuracy: 0.9848 - auc: 0.9985 - val_loss: 0.6622 - val_accuracy: 0.7367 - val_auc: 0.8089\n",
      "Epoch 11/15\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.0513 - accuracy: 0.9878 - auc: 0.9990 - val_loss: 0.6921 - val_accuracy: 0.7337 - val_auc: 0.8066\n",
      "Epoch 12/15\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.0432 - accuracy: 0.9902 - auc: 0.9993 - val_loss: 0.7246 - val_accuracy: 0.7309 - val_auc: 0.8037\n",
      "Epoch 13/15\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.0370 - accuracy: 0.9913 - auc: 0.9995 - val_loss: 0.7514 - val_accuracy: 0.7312 - val_auc: 0.8012\n",
      "Epoch 14/15\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.0330 - accuracy: 0.9923 - auc: 0.9995 - val_loss: 0.7825 - val_accuracy: 0.7276 - val_auc: 0.7990\n",
      "Epoch 15/15\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.0277 - accuracy: 0.9943 - auc: 0.9997 - val_loss: 0.8105 - val_accuracy: 0.7267 - val_auc: 0.7977\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_raw, y_train, batch_size=1024, epochs=15, validation_data=(X_test_raw, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8362065553665161"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(hist.history['val_auc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'training_time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "                    'Accuracy': max(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (None, 30, 50)            2000000   \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 8)                 12008     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,012,017\n",
      "Trainable params: 2,012,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'simple NN - Basic preprocessing'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(voc),50 ,input_length = tweet_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.6851 - accuracy: 0.5638 - auc: 0.5964 - val_loss: 0.6607 - val_accuracy: 0.6579 - val_auc: 0.7298\n",
      "Epoch 2/15\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.5918 - accuracy: 0.7493 - auc: 0.8162 - val_loss: 0.5506 - val_accuracy: 0.7341 - val_auc: 0.8059\n",
      "Epoch 3/15\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.4454 - accuracy: 0.8127 - auc: 0.8887 - val_loss: 0.5061 - val_accuracy: 0.7571 - val_auc: 0.8333\n",
      "Epoch 4/15\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.3359 - accuracy: 0.8740 - auc: 0.9415 - val_loss: 0.5027 - val_accuracy: 0.7551 - val_auc: 0.8370\n",
      "Epoch 5/15\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.2450 - accuracy: 0.9185 - auc: 0.9716 - val_loss: 0.5151 - val_accuracy: 0.7545 - val_auc: 0.8323\n",
      "Epoch 6/15\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.1797 - accuracy: 0.9463 - auc: 0.9855 - val_loss: 0.5398 - val_accuracy: 0.7499 - val_auc: 0.8274\n",
      "Epoch 7/15\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.1344 - accuracy: 0.9622 - auc: 0.9921 - val_loss: 0.5678 - val_accuracy: 0.7447 - val_auc: 0.8216\n",
      "Epoch 8/15\n",
      "40/40 [==============================] - 2s 41ms/step - loss: 0.1034 - accuracy: 0.9724 - auc: 0.9955 - val_loss: 0.5942 - val_accuracy: 0.7448 - val_auc: 0.8172\n",
      "Epoch 9/15\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.0817 - accuracy: 0.9793 - auc: 0.9972 - val_loss: 0.6348 - val_accuracy: 0.7365 - val_auc: 0.8139\n",
      "Epoch 10/15\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.0655 - accuracy: 0.9846 - auc: 0.9982 - val_loss: 0.6625 - val_accuracy: 0.7373 - val_auc: 0.8081\n",
      "Epoch 11/15\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.0545 - accuracy: 0.9866 - auc: 0.9987 - val_loss: 0.7010 - val_accuracy: 0.7330 - val_auc: 0.8076\n",
      "Epoch 12/15\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.0455 - accuracy: 0.9895 - auc: 0.9991 - val_loss: 0.7241 - val_accuracy: 0.7359 - val_auc: 0.8041\n",
      "Epoch 13/15\n",
      "40/40 [==============================] - 2s 48ms/step - loss: 0.0382 - accuracy: 0.9913 - auc: 0.9994 - val_loss: 0.7570 - val_accuracy: 0.7365 - val_auc: 0.8024\n",
      "Epoch 14/15\n",
      "40/40 [==============================] - 2s 49ms/step - loss: 0.0329 - accuracy: 0.9930 - auc: 0.9995 - val_loss: 0.7794 - val_accuracy: 0.7334 - val_auc: 0.8008\n",
      "Epoch 15/15\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.0287 - accuracy: 0.9941 - auc: 0.9996 - val_loss: 0.8241 - val_accuracy: 0.7291 - val_auc: 0.7997\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=15, validation_data=(X_test_vect, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'training_time': stop-start,\n",
    "                    'AUC': max(hist.history['val_auc']),\n",
    "                    'Accuracy': max(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>28.199898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836207</td>\n",
       "      <td>0.7540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>29.217246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836986</td>\n",
       "      <td>0.7571</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 training_time  predict_time       AUC  \\\n",
       "simple NN - raw text                 28.199898           NaN  0.836207   \n",
       "simple NN - Basic preprocessing      29.217246           NaN  0.836986   \n",
       "\n",
       "                                 Accuracy  \n",
       "simple NN - raw text               0.7540  \n",
       "simple NN - Basic preprocessing    0.7571  "
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_28 (Embedding)     (None, 30, 50)            2000000   \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 8)                 12008     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,012,017\n",
      "Trainable params: 2,012,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'simple NN - Stemming'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(voc_stem),50 ,input_length = tweet_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "40/40 [==============================] - 2s 51ms/step - loss: 0.6856 - accuracy: 0.5656 - auc: 0.6051 - val_loss: 0.6608 - val_accuracy: 0.6564 - val_auc: 0.7201\n",
      "Epoch 2/15\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.5845 - accuracy: 0.7398 - auc: 0.8106 - val_loss: 0.5414 - val_accuracy: 0.7322 - val_auc: 0.8134\n",
      "Epoch 3/15\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.4362 - accuracy: 0.8184 - auc: 0.8922 - val_loss: 0.5016 - val_accuracy: 0.7561 - val_auc: 0.8360\n",
      "Epoch 4/15\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.3294 - accuracy: 0.8777 - auc: 0.9438 - val_loss: 0.5041 - val_accuracy: 0.7576 - val_auc: 0.8363\n",
      "Epoch 5/15\n",
      "40/40 [==============================] - 2s 47ms/step - loss: 0.2427 - accuracy: 0.9192 - auc: 0.9720 - val_loss: 0.5182 - val_accuracy: 0.7580 - val_auc: 0.8308\n",
      "Epoch 6/15\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1782 - accuracy: 0.9452 - auc: 0.9860 - val_loss: 0.5447 - val_accuracy: 0.7513 - val_auc: 0.8225\n",
      "Epoch 7/15\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.1347 - accuracy: 0.9607 - auc: 0.9922 - val_loss: 0.5868 - val_accuracy: 0.7414 - val_auc: 0.8175\n",
      "Epoch 8/15\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.1058 - accuracy: 0.9707 - auc: 0.9955 - val_loss: 0.6085 - val_accuracy: 0.7412 - val_auc: 0.8118\n",
      "Epoch 9/15\n",
      "40/40 [==============================] - 2s 44ms/step - loss: 0.0833 - accuracy: 0.9778 - auc: 0.9974 - val_loss: 0.6343 - val_accuracy: 0.7374 - val_auc: 0.8080\n",
      "Epoch 10/15\n",
      "40/40 [==============================] - 2s 42ms/step - loss: 0.0677 - accuracy: 0.9834 - auc: 0.9983 - val_loss: 0.6685 - val_accuracy: 0.7329 - val_auc: 0.8041\n",
      "Epoch 11/15\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.0563 - accuracy: 0.9866 - auc: 0.9989 - val_loss: 0.6983 - val_accuracy: 0.7307 - val_auc: 0.8008\n",
      "Epoch 12/15\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.0467 - accuracy: 0.9894 - auc: 0.9993 - val_loss: 0.7357 - val_accuracy: 0.7286 - val_auc: 0.7988\n",
      "Epoch 13/15\n",
      "40/40 [==============================] - 2s 46ms/step - loss: 0.0401 - accuracy: 0.9906 - auc: 0.9995 - val_loss: 0.7659 - val_accuracy: 0.7286 - val_auc: 0.7963\n",
      "Epoch 14/15\n",
      "40/40 [==============================] - 2s 45ms/step - loss: 0.0341 - accuracy: 0.9923 - auc: 0.9996 - val_loss: 0.8009 - val_accuracy: 0.7245 - val_auc: 0.7945\n",
      "Epoch 15/15\n",
      "40/40 [==============================] - 2s 43ms/step - loss: 0.0296 - accuracy: 0.9934 - auc: 0.9997 - val_loss: 0.8280 - val_accuracy: 0.7230 - val_auc: 0.7931\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect_stem, y_train, batch_size=1024, epochs=15, validation_data=(X_test_vect_stem, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'training_time': stop-start,\n",
    "                    'AUC': max(hist.history['val_auc']),\n",
    "                    'Accuracy': max(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'simple NN - Lemmatization'\n",
    "\n",
    "# model = Sequential()\n",
    "\n",
    "# model.add(Embedding(len(voc_lem),50 ,input_length = tweet_length))\n",
    "# model.add(Flatten())\n",
    "# model.add(Dense(8,activation='relu'))\n",
    "# model.add(Dense(1,activation='sigmoid'))\n",
    "# model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start = time.time()\n",
    "# hist = model.fit(X_train_vect_lem, y_train, batch_size=1024, epochs=15, validation_data=(X_test_vect_lem, y_test))\n",
    "# stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# models_performances = models_performances.append(\n",
    "#     pd.Series(data={'training_time': stop-start,\n",
    "#                     'AUC': max(hist.history['val_auc']),\n",
    "#                     'Accuracy': max(hist.history['val_accuracy'])},\n",
    "#               name=model_name)\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Preprocessing performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>28.199898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836207</td>\n",
       "      <td>0.7540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>29.217246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836986</td>\n",
       "      <td>0.7571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Stemming</th>\n",
       "      <td>28.503772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836302</td>\n",
       "      <td>0.7580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 training_time  predict_time       AUC  \\\n",
       "simple NN - raw text                 28.199898           NaN  0.836207   \n",
       "simple NN - Basic preprocessing      29.217246           NaN  0.836986   \n",
       "simple NN - Stemming                 28.503772           NaN  0.836302   \n",
       "\n",
       "                                 Accuracy  \n",
       "simple NN - raw text               0.7540  \n",
       "simple NN - Basic preprocessing    0.7571  \n",
       "simple NN - Stemming               0.7580  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances.to_pickle('data/models_performances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = pd.read_pickle('data/models_performances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the embedding matrix ( word / coeff matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Glove embedding shows better results, we'll use it from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(\"D:/Data OC/P7/glove.twitter.27B.50d.txt\",encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.4952e-01,  6.3531e-01, -2.7482e-01, -5.6774e-01,  2.3838e-01,\n",
       "        4.6456e-01,  4.9520e-01,  1.2078e+00,  6.8083e-01,  1.2944e+00,\n",
       "       -3.1729e-01,  9.3355e-01, -3.6110e+00, -4.2190e-01,  1.3131e-01,\n",
       "        3.1559e-01,  3.1746e-01, -5.9327e-01, -1.0953e+00,  1.2101e-01,\n",
       "       -6.5495e-01,  5.6309e-01, -8.1480e-01,  3.1958e-01, -1.7309e-01,\n",
       "       -3.6612e-01,  2.4165e-01, -9.3716e-01,  7.4686e-02, -4.9986e-01,\n",
       "       -6.8015e-01,  1.0903e+00, -5.8925e-02,  6.2869e-01,  3.2314e-01,\n",
       "        1.8576e-01,  2.3479e-01,  7.7135e-01, -2.5224e-01,  7.4506e-01,\n",
       "       -1.3210e+00,  2.9938e-01,  8.3398e-01,  2.4541e-01, -5.4673e-01,\n",
       "       -8.6595e-06, -2.7880e-01,  2.5472e-02,  4.1780e-01,  2.7636e-02],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index.get('bro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the embedding matrix which can be used in a Keras Embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 23138 words (16862 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 50\n",
    "hits = 0\n",
    "misses = 0\n",
    "misses_word=[]\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        misses_word.append(word)\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['whyyy',\n",
       " 'wayyy',\n",
       " 'tyresereal',\n",
       " 'twitgoo',\n",
       " 'tireddd',\n",
       " 'thomasfiss',\n",
       " 'thisisrobthomas',\n",
       " 'thedebbyryan',\n",
       " 'shhh',\n",
       " 'rustyrockets',\n",
       " 'rubyrose',\n",
       " 'ohhhhh',\n",
       " 'officialcharice',\n",
       " 'nicksantino',\n",
       " 'nickkkjonasss',\n",
       " 'mrskutcher',\n",
       " 'moonfrye',\n",
       " 'misstattoo',\n",
       " 'mellalicious',\n",
       " 'matthardybrand',\n",
       " 'lucascruikshank',\n",
       " 'lolll',\n",
       " 'lisahopecyrus',\n",
       " 'kimsherrell',\n",
       " 'kevinspacey',\n",
       " 'kalebnation',\n",
       " 'johncmayer',\n",
       " 'jennamadison',\n",
       " 'jasonmanford',\n",
       " 'hummm',\n",
       " 'guykawasaki',\n",
       " 'greggarbo',\n",
       " 'gokey',\n",
       " 'ginoandfran',\n",
       " 'gahhh',\n",
       " 'enamoredsoul',\n",
       " 'davidhenrie',\n",
       " 'collectivesoul',\n",
       " 'chrisdjmoyles',\n",
       " 'buzzedition',\n",
       " 'buckhollywood',\n",
       " 'brodyjenner',\n",
       " 'blahhh',\n",
       " 'babygirlparis',\n",
       " 'arghhh',\n",
       " 'amandapalmer',\n",
       " 'alll',\n",
       " 'zenjar',\n",
       " 'yummmm',\n",
       " 'yummm',\n",
       " 'youuuuu',\n",
       " 'yesssss',\n",
       " 'yessss',\n",
       " 'yayyy',\n",
       " 'wellll',\n",
       " 'veryyy',\n",
       " 'twitteriffic',\n",
       " 'twilightfairy',\n",
       " 'tumblrity',\n",
       " 'trentreznor',\n",
       " 'tonfue',\n",
       " 'ticklemejoey',\n",
       " 'thesupergirl',\n",
       " 'thepistol',\n",
       " 'sooooooooooo',\n",
       " 'snipeyhead',\n",
       " 'simx',\n",
       " 'shaunjumpnow',\n",
       " 'shandrab',\n",
       " 'sethsimonds',\n",
       " 'secondpower',\n",
       " 'sandimon',\n",
       " 'rhettroberts',\n",
       " 'realhughjackman',\n",
       " 'rachmurrayx',\n",
       " 'princesammie',\n",
       " 'pleaseee',\n",
       " 'pcdmelodyt',\n",
       " 'omgggg',\n",
       " 'omggg',\n",
       " 'mussomitchel',\n",
       " 'mrpaulevans',\n",
       " 'missmelbourne',\n",
       " 'meeeee',\n",
       " 'mcflyharry',\n",
       " 'lofnotc',\n",
       " 'littlefletcher',\n",
       " 'ktbeeper',\n",
       " 'krisallenmusic',\n",
       " 'kchenoweth',\n",
       " 'jessicaveronica',\n",
       " 'jessemccartney',\n",
       " 'jellicle',\n",
       " 'jantunstill',\n",
       " 'itxiitx',\n",
       " 'iamjonathancook',\n",
       " 'hooo',\n",
       " 'homeee',\n",
       " 'hiiii',\n",
       " 'heyyyyy']"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misses_word[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "import keras\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    input_length=tweet_length,\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (None, 30, 50)            2000100   \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 1500)              0         \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 8)                 12008     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,012,117\n",
      "Trainable params: 12,017\n",
      "Non-trainable params: 2,000,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'simple NN - GLoVe embedding'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "40/40 [==============================] - 1s 19ms/step - loss: 0.6721 - accuracy: 0.5944 - auc: 0.6202 - val_loss: 0.6220 - val_accuracy: 0.6609 - val_auc: 0.7175\n",
      "Epoch 2/15\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.5961 - accuracy: 0.6813 - auc: 0.7451 - val_loss: 0.5844 - val_accuracy: 0.6914 - val_auc: 0.7587\n",
      "Epoch 3/15\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.5648 - accuracy: 0.7089 - auc: 0.7788 - val_loss: 0.5682 - val_accuracy: 0.7036 - val_auc: 0.7761\n",
      "Epoch 4/15\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.5481 - accuracy: 0.7206 - auc: 0.7944 - val_loss: 0.5596 - val_accuracy: 0.7102 - val_auc: 0.7838\n",
      "Epoch 5/15\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.5379 - accuracy: 0.7289 - auc: 0.8039 - val_loss: 0.5566 - val_accuracy: 0.7125 - val_auc: 0.7868\n",
      "Epoch 6/15\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.5298 - accuracy: 0.7327 - auc: 0.8106 - val_loss: 0.5543 - val_accuracy: 0.7166 - val_auc: 0.7890\n",
      "Epoch 7/15\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.5244 - accuracy: 0.7366 - auc: 0.8153 - val_loss: 0.5592 - val_accuracy: 0.7126 - val_auc: 0.7889\n",
      "Epoch 8/15\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.5204 - accuracy: 0.7394 - auc: 0.8184 - val_loss: 0.5541 - val_accuracy: 0.7170 - val_auc: 0.7896\n",
      "Epoch 9/15\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.5148 - accuracy: 0.7429 - auc: 0.8230 - val_loss: 0.5547 - val_accuracy: 0.7164 - val_auc: 0.7895\n",
      "Epoch 10/15\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.5108 - accuracy: 0.7459 - auc: 0.8262 - val_loss: 0.5551 - val_accuracy: 0.7159 - val_auc: 0.7892\n",
      "Epoch 11/15\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.5080 - accuracy: 0.7474 - auc: 0.8286 - val_loss: 0.5560 - val_accuracy: 0.7134 - val_auc: 0.7888\n",
      "Epoch 12/15\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.5053 - accuracy: 0.7488 - auc: 0.8304 - val_loss: 0.5570 - val_accuracy: 0.7141 - val_auc: 0.7890\n",
      "Epoch 13/15\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.5018 - accuracy: 0.7531 - auc: 0.8332 - val_loss: 0.5569 - val_accuracy: 0.7126 - val_auc: 0.7882\n",
      "Epoch 14/15\n",
      "40/40 [==============================] - 0s 11ms/step - loss: 0.4989 - accuracy: 0.7519 - auc: 0.8352 - val_loss: 0.5586 - val_accuracy: 0.7130 - val_auc: 0.7879\n",
      "Epoch 15/15\n",
      "40/40 [==============================] - 0s 10ms/step - loss: 0.4959 - accuracy: 0.7548 - auc: 0.8377 - val_loss: 0.5602 - val_accuracy: 0.7104 - val_auc: 0.7876\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=15, validation_data=(X_test_vect, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'training_time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "                    'Accuracy': max(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>28.199898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836207</td>\n",
       "      <td>0.7540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>29.217246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836986</td>\n",
       "      <td>0.7571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Stemming</th>\n",
       "      <td>28.503772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836302</td>\n",
       "      <td>0.7580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - GLoVe embedding</th>\n",
       "      <td>7.534557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.789571</td>\n",
       "      <td>0.7170</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 training_time  predict_time       AUC  \\\n",
       "simple NN - raw text                 28.199898           NaN  0.836207   \n",
       "simple NN - Basic preprocessing      29.217246           NaN  0.836986   \n",
       "simple NN - Stemming                 28.503772           NaN  0.836302   \n",
       "simple NN - GLoVe embedding           7.534557           NaN  0.789571   \n",
       "\n",
       "                                 Accuracy  \n",
       "simple NN - raw text               0.7540  \n",
       "simple NN - Basic preprocessing    0.7571  \n",
       "simple NN - Stemming               0.7580  \n",
       "simple NN - GLoVe embedding        0.7170  "
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_30 (Embedding)     (None, 30, 50)            2000000   \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "dense_62 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,091,777\n",
      "Trainable params: 2,091,777\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'LSTM - Own embedding and stem -dp=0.5'\n",
    "\n",
    "lstm_out=128\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(voc),50 ,input_length = tweet_length))\n",
    "model.add(LSTM(lstm_out,dropout=0.5))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "40/40 [==============================] - 23s 566ms/step - loss: 0.6717 - accuracy: 0.5545 - auc: 0.5949 - val_loss: 0.5797 - val_accuracy: 0.7053 - val_auc: 0.7787\n",
      "Epoch 2/15\n",
      "40/40 [==============================] - 23s 564ms/step - loss: 0.5219 - accuracy: 0.7483 - auc: 0.8196 - val_loss: 0.5057 - val_accuracy: 0.7580 - val_auc: 0.8427\n",
      "Epoch 3/15\n",
      "40/40 [==============================] - 23s 571ms/step - loss: 0.4256 - accuracy: 0.8094 - auc: 0.8856 - val_loss: 0.4953 - val_accuracy: 0.7511 - val_auc: 0.8479\n",
      "Epoch 4/15\n",
      "40/40 [==============================] - 23s 578ms/step - loss: 0.3703 - accuracy: 0.8398 - auc: 0.9148 - val_loss: 0.5232 - val_accuracy: 0.7475 - val_auc: 0.8384\n",
      "Epoch 5/15\n",
      "40/40 [==============================] - 23s 577ms/step - loss: 0.3148 - accuracy: 0.8692 - auc: 0.9385 - val_loss: 0.5156 - val_accuracy: 0.7489 - val_auc: 0.8317\n",
      "Epoch 6/15\n",
      "40/40 [==============================] - 22s 558ms/step - loss: 0.2770 - accuracy: 0.8890 - auc: 0.9521 - val_loss: 0.5536 - val_accuracy: 0.7358 - val_auc: 0.8188\n",
      "Epoch 7/15\n",
      "40/40 [==============================] - 22s 562ms/step - loss: 0.2444 - accuracy: 0.9018 - auc: 0.9627 - val_loss: 0.6198 - val_accuracy: 0.7339 - val_auc: 0.8109\n",
      "Epoch 8/15\n",
      "40/40 [==============================] - 22s 561ms/step - loss: 0.2200 - accuracy: 0.9129 - auc: 0.9699 - val_loss: 0.6666 - val_accuracy: 0.7335 - val_auc: 0.8075\n",
      "Epoch 9/15\n",
      "40/40 [==============================] - 23s 566ms/step - loss: 0.2018 - accuracy: 0.9197 - auc: 0.9743 - val_loss: 0.6587 - val_accuracy: 0.7297 - val_auc: 0.8038\n",
      "Epoch 10/15\n",
      "40/40 [==============================] - 23s 569ms/step - loss: 0.1891 - accuracy: 0.9254 - auc: 0.9774 - val_loss: 0.6750 - val_accuracy: 0.7245 - val_auc: 0.7988\n",
      "Epoch 11/15\n",
      "40/40 [==============================] - 22s 561ms/step - loss: 0.1742 - accuracy: 0.9328 - auc: 0.9808 - val_loss: 0.7660 - val_accuracy: 0.7244 - val_auc: 0.7934\n",
      "Epoch 12/15\n",
      "40/40 [==============================] - 23s 573ms/step - loss: 0.1666 - accuracy: 0.9358 - auc: 0.9824 - val_loss: 0.7738 - val_accuracy: 0.7248 - val_auc: 0.7948\n",
      "Epoch 13/15\n",
      "40/40 [==============================] - 23s 579ms/step - loss: 0.1606 - accuracy: 0.9377 - auc: 0.9833 - val_loss: 0.7701 - val_accuracy: 0.7187 - val_auc: 0.7914\n",
      "Epoch 14/15\n",
      "40/40 [==============================] - 23s 567ms/step - loss: 0.1571 - accuracy: 0.9396 - auc: 0.9841 - val_loss: 0.8352 - val_accuracy: 0.7198 - val_auc: 0.7861\n",
      "Epoch 15/15\n",
      "40/40 [==============================] - 23s 564ms/step - loss: 0.1450 - accuracy: 0.9428 - auc: 0.9865 - val_loss: 0.8235 - val_accuracy: 0.7141 - val_auc: 0.7845\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=15, validation_data=(X_test_vect, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'training_time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "                    'Accuracy': max(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>28.199898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836207</td>\n",
       "      <td>0.7540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>29.217246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836986</td>\n",
       "      <td>0.7571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Stemming</th>\n",
       "      <td>28.503772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836302</td>\n",
       "      <td>0.7580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - GLoVe embedding</th>\n",
       "      <td>7.534557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.789571</td>\n",
       "      <td>0.7170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - Own embedding and stem -dp=0.5</th>\n",
       "      <td>351.181513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847916</td>\n",
       "      <td>0.7580</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       training_time  predict_time       AUC  \\\n",
       "simple NN - raw text                       28.199898           NaN  0.836207   \n",
       "simple NN - Basic preprocessing            29.217246           NaN  0.836986   \n",
       "simple NN - Stemming                       28.503772           NaN  0.836302   \n",
       "simple NN - GLoVe embedding                 7.534557           NaN  0.789571   \n",
       "LSTM - Own embedding and stem -dp=0.5     351.181513           NaN  0.847916   \n",
       "\n",
       "                                       Accuracy  \n",
       "simple NN - raw text                     0.7540  \n",
       "simple NN - Basic preprocessing          0.7571  \n",
       "simple NN - Stemming                     0.7580  \n",
       "simple NN - GLoVe embedding              0.7170  \n",
       "LSTM - Own embedding and stem -dp=0.5    0.7580  "
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With GLoVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (None, 30, 50)            2000100   \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 128)               91648     \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 2,091,877\n",
      "Trainable params: 91,777\n",
      "Non-trainable params: 2,000,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "\n",
    "lstm_out=128\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),50 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=0.5))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "40/40 [==============================] - 18s 446ms/step - loss: 0.6406 - accuracy: 0.6206 - auc: 0.6793 - val_loss: 0.5664 - val_accuracy: 0.7085 - val_auc: 0.7799\n",
      "Epoch 2/30\n",
      "40/40 [==============================] - 17s 425ms/step - loss: 0.5972 - accuracy: 0.6757 - auc: 0.7426 - val_loss: 0.5596 - val_accuracy: 0.7096 - val_auc: 0.7886\n",
      "Epoch 3/30\n",
      "40/40 [==============================] - 18s 456ms/step - loss: 0.5927 - accuracy: 0.6787 - auc: 0.7475 - val_loss: 0.5523 - val_accuracy: 0.7153 - val_auc: 0.7941\n",
      "Epoch 4/30\n",
      "40/40 [==============================] - 18s 446ms/step - loss: 0.5814 - accuracy: 0.6919 - auc: 0.7593 - val_loss: 0.5536 - val_accuracy: 0.7223 - val_auc: 0.8003\n",
      "Epoch 5/30\n",
      "40/40 [==============================] - 18s 445ms/step - loss: 0.5804 - accuracy: 0.6921 - auc: 0.7614 - val_loss: 0.5376 - val_accuracy: 0.7286 - val_auc: 0.8061\n",
      "Epoch 6/30\n",
      "40/40 [==============================] - 18s 444ms/step - loss: 0.5767 - accuracy: 0.6950 - auc: 0.7646 - val_loss: 0.5651 - val_accuracy: 0.7060 - val_auc: 0.8077\n",
      "Epoch 7/30\n",
      "40/40 [==============================] - 18s 444ms/step - loss: 0.5728 - accuracy: 0.6963 - auc: 0.7687 - val_loss: 0.5277 - val_accuracy: 0.7385 - val_auc: 0.8146\n",
      "Epoch 8/30\n",
      "40/40 [==============================] - 18s 445ms/step - loss: 0.5608 - accuracy: 0.7062 - auc: 0.7802 - val_loss: 0.5250 - val_accuracy: 0.7399 - val_auc: 0.8226\n",
      "Epoch 9/30\n",
      "40/40 [==============================] - 18s 454ms/step - loss: 0.5598 - accuracy: 0.7052 - auc: 0.7810 - val_loss: 0.5645 - val_accuracy: 0.6930 - val_auc: 0.8197\n",
      "Epoch 10/30\n",
      "40/40 [==============================] - 18s 461ms/step - loss: 0.5618 - accuracy: 0.7036 - auc: 0.7794 - val_loss: 0.5230 - val_accuracy: 0.7417 - val_auc: 0.8200\n",
      "Epoch 11/30\n",
      "40/40 [==============================] - 18s 458ms/step - loss: 0.5624 - accuracy: 0.7096 - auc: 0.7808 - val_loss: 0.5110 - val_accuracy: 0.7469 - val_auc: 0.8267\n",
      "Epoch 12/30\n",
      "40/40 [==============================] - 18s 458ms/step - loss: 0.5548 - accuracy: 0.7107 - auc: 0.7864 - val_loss: 0.5178 - val_accuracy: 0.7423 - val_auc: 0.8274\n",
      "Epoch 13/30\n",
      "40/40 [==============================] - 18s 462ms/step - loss: 0.5506 - accuracy: 0.7151 - auc: 0.7903 - val_loss: 0.5153 - val_accuracy: 0.7411 - val_auc: 0.8318\n",
      "Epoch 14/30\n",
      "40/40 [==============================] - 19s 471ms/step - loss: 0.5502 - accuracy: 0.7153 - auc: 0.7905 - val_loss: 0.5098 - val_accuracy: 0.7452 - val_auc: 0.8300\n",
      "Epoch 15/30\n",
      "40/40 [==============================] - 19s 476ms/step - loss: 0.5506 - accuracy: 0.7171 - auc: 0.7916 - val_loss: 0.5064 - val_accuracy: 0.7524 - val_auc: 0.8344\n",
      "Epoch 16/30\n",
      "40/40 [==============================] - 19s 469ms/step - loss: 0.5485 - accuracy: 0.7179 - auc: 0.7937 - val_loss: 0.5020 - val_accuracy: 0.7514 - val_auc: 0.8360\n",
      "Epoch 17/30\n",
      "40/40 [==============================] - 21s 527ms/step - loss: 0.5451 - accuracy: 0.7184 - auc: 0.7961 - val_loss: 0.5082 - val_accuracy: 0.7549 - val_auc: 0.8366\n",
      "Epoch 18/30\n",
      "40/40 [==============================] - 20s 503ms/step - loss: 0.5489 - accuracy: 0.7163 - auc: 0.7926 - val_loss: 0.4982 - val_accuracy: 0.7576 - val_auc: 0.8379\n",
      "Epoch 19/30\n",
      "40/40 [==============================] - 20s 495ms/step - loss: 0.5406 - accuracy: 0.7206 - auc: 0.7994 - val_loss: 0.5263 - val_accuracy: 0.7295 - val_auc: 0.8360\n",
      "Epoch 20/30\n",
      "40/40 [==============================] - 20s 498ms/step - loss: 0.5374 - accuracy: 0.7232 - auc: 0.8025 - val_loss: 0.4999 - val_accuracy: 0.7547 - val_auc: 0.8387\n",
      "Epoch 21/30\n",
      "40/40 [==============================] - 19s 487ms/step - loss: 0.5400 - accuracy: 0.7222 - auc: 0.8003 - val_loss: 0.5047 - val_accuracy: 0.7467 - val_auc: 0.8387\n",
      "Epoch 22/30\n",
      "40/40 [==============================] - 20s 507ms/step - loss: 0.5390 - accuracy: 0.7223 - auc: 0.8013 - val_loss: 0.4968 - val_accuracy: 0.7587 - val_auc: 0.8402\n",
      "Epoch 23/30\n",
      "40/40 [==============================] - 19s 487ms/step - loss: 0.5373 - accuracy: 0.7242 - auc: 0.8032 - val_loss: 0.5098 - val_accuracy: 0.7499 - val_auc: 0.8407\n",
      "Epoch 24/30\n",
      "40/40 [==============================] - 19s 470ms/step - loss: 0.5337 - accuracy: 0.7246 - auc: 0.8055 - val_loss: 0.4891 - val_accuracy: 0.7641 - val_auc: 0.8449\n",
      "Epoch 25/30\n",
      "40/40 [==============================] - 19s 473ms/step - loss: 0.5344 - accuracy: 0.7267 - auc: 0.8053 - val_loss: 0.4977 - val_accuracy: 0.7632 - val_auc: 0.8414\n",
      "Epoch 26/30\n",
      "40/40 [==============================] - 19s 486ms/step - loss: 0.5318 - accuracy: 0.7291 - auc: 0.8080 - val_loss: 0.4881 - val_accuracy: 0.7635 - val_auc: 0.8442\n",
      "Epoch 27/30\n",
      "40/40 [==============================] - 22s 555ms/step - loss: 0.5335 - accuracy: 0.7289 - auc: 0.8065 - val_loss: 0.4895 - val_accuracy: 0.7642 - val_auc: 0.8442\n",
      "Epoch 28/30\n",
      "40/40 [==============================] - 19s 487ms/step - loss: 0.5304 - accuracy: 0.7285 - auc: 0.8087 - val_loss: 0.4993 - val_accuracy: 0.7561 - val_auc: 0.8427\n",
      "Epoch 29/30\n",
      "40/40 [==============================] - 21s 514ms/step - loss: 0.5337 - accuracy: 0.7275 - auc: 0.8063 - val_loss: 0.4988 - val_accuracy: 0.7581 - val_auc: 0.8476\n",
      "Epoch 30/30\n",
      "40/40 [==============================] - 21s 527ms/step - loss: 0.5332 - accuracy: 0.7263 - auc: 0.8062 - val_loss: 0.4870 - val_accuracy: 0.7631 - val_auc: 0.8451\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'training_time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "                    'Accuracy': max(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_29 (Embedding)     (None, 30, 50)            2000100   \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 256)               183296    \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 1)                 257       \n",
      "=================================================================\n",
      "Total params: 2,183,653\n",
      "Trainable params: 183,553\n",
      "Non-trainable params: 2,000,100\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'biLSTM - GLoVe embedding'\n",
    "\n",
    "lstm_out=128\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),50 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(Bidirectional(LSTM(lstm_out,dropout=0.5)))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "40/40 [==============================] - 39s 984ms/step - loss: 0.6251 - accuracy: 0.6465 - auc: 0.7048 - val_loss: 0.5914 - val_accuracy: 0.6881 - val_auc: 0.7816\n",
      "Epoch 2/15\n",
      "40/40 [==============================] - 39s 978ms/step - loss: 0.5791 - accuracy: 0.6941 - auc: 0.7629 - val_loss: 0.5520 - val_accuracy: 0.7195 - val_auc: 0.7975\n",
      "Epoch 3/15\n",
      "40/40 [==============================] - 39s 986ms/step - loss: 0.5739 - accuracy: 0.6991 - auc: 0.7681 - val_loss: 0.5428 - val_accuracy: 0.7266 - val_auc: 0.8035\n",
      "Epoch 4/15\n",
      "40/40 [==============================] - 40s 993ms/step - loss: 0.5653 - accuracy: 0.7028 - auc: 0.7771 - val_loss: 0.5527 - val_accuracy: 0.7169 - val_auc: 0.8039\n",
      "Epoch 5/15\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.5624 - accuracy: 0.7065 - auc: 0.7792 - val_loss: 0.5357 - val_accuracy: 0.7251 - val_auc: 0.8110\n",
      "Epoch 6/15\n",
      "40/40 [==============================] - 40s 1s/step - loss: 0.5574 - accuracy: 0.7093 - auc: 0.7840 - val_loss: 0.5572 - val_accuracy: 0.7065 - val_auc: 0.8157\n",
      "Epoch 7/15\n",
      "40/40 [==============================] - 40s 1s/step - loss: 0.5590 - accuracy: 0.7070 - auc: 0.7827 - val_loss: 0.5267 - val_accuracy: 0.7369 - val_auc: 0.8174\n",
      "Epoch 8/15\n",
      "40/40 [==============================] - 40s 1s/step - loss: 0.5442 - accuracy: 0.7185 - auc: 0.7959 - val_loss: 0.5190 - val_accuracy: 0.7403 - val_auc: 0.8221\n",
      "Epoch 9/15\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.5441 - accuracy: 0.7191 - auc: 0.7963 - val_loss: 0.5076 - val_accuracy: 0.7456 - val_auc: 0.8295\n",
      "Epoch 10/15\n",
      "40/40 [==============================] - 43s 1s/step - loss: 0.5409 - accuracy: 0.7206 - auc: 0.7990 - val_loss: 0.5064 - val_accuracy: 0.7491 - val_auc: 0.8299\n",
      "Epoch 11/15\n",
      "40/40 [==============================] - 43s 1s/step - loss: 0.5347 - accuracy: 0.7271 - auc: 0.8056 - val_loss: 0.5010 - val_accuracy: 0.7527 - val_auc: 0.8340\n",
      "Epoch 12/15\n",
      "40/40 [==============================] - 43s 1s/step - loss: 0.5330 - accuracy: 0.7275 - auc: 0.8065 - val_loss: 0.5027 - val_accuracy: 0.7539 - val_auc: 0.8359\n",
      "Epoch 13/15\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.5269 - accuracy: 0.7308 - auc: 0.8118 - val_loss: 0.4945 - val_accuracy: 0.7605 - val_auc: 0.8392\n",
      "Epoch 14/15\n",
      "40/40 [==============================] - 40s 1s/step - loss: 0.5239 - accuracy: 0.7351 - auc: 0.8146 - val_loss: 0.5160 - val_accuracy: 0.7384 - val_auc: 0.8371\n",
      "Epoch 15/15\n",
      "40/40 [==============================] - 41s 1s/step - loss: 0.5242 - accuracy: 0.7330 - auc: 0.8139 - val_loss: 0.5177 - val_accuracy: 0.7363 - val_auc: 0.8407\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=15, validation_data=(X_test_vect, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'training_time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "                    'Accuracy': max(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time</th>\n",
       "      <th>predict_time</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>28.199898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836207</td>\n",
       "      <td>0.7540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>29.217246</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836986</td>\n",
       "      <td>0.7571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Stemming</th>\n",
       "      <td>28.503772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.836302</td>\n",
       "      <td>0.7580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - GLoVe embedding</th>\n",
       "      <td>7.534557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.789571</td>\n",
       "      <td>0.7170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - Own embedding and stem -dp=0.5</th>\n",
       "      <td>351.181513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.847916</td>\n",
       "      <td>0.7580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>315.666649</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.830517</td>\n",
       "      <td>0.7467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biLSTM - GLoVe embedding</th>\n",
       "      <td>628.626900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.840677</td>\n",
       "      <td>0.7605</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       training_time  predict_time       AUC  \\\n",
       "simple NN - raw text                       28.199898           NaN  0.836207   \n",
       "simple NN - Basic preprocessing            29.217246           NaN  0.836986   \n",
       "simple NN - Stemming                       28.503772           NaN  0.836302   \n",
       "simple NN - GLoVe embedding                 7.534557           NaN  0.789571   \n",
       "LSTM - Own embedding and stem -dp=0.5     351.181513           NaN  0.847916   \n",
       "LSTM - GLoVe embedding                    315.666649           NaN  0.830517   \n",
       "biLSTM - GLoVe embedding                  628.626900           NaN  0.840677   \n",
       "\n",
       "                                       Accuracy  \n",
       "simple NN - raw text                     0.7540  \n",
       "simple NN - Basic preprocessing          0.7571  \n",
       "simple NN - Stemming                     0.7580  \n",
       "simple NN - GLoVe embedding              0.7170  \n",
       "LSTM - Own embedding and stem -dp=0.5    0.7580  \n",
       "LSTM - GLoVe embedding                   0.7467  \n",
       "biLSTM - GLoVe embedding                 0.7605  "
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "acc = hist.history['accuracy']\n",
    "val = hist.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, '-', label='Training accuracy')\n",
    "plt.plot(epochs, val, ':', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "408.767px",
    "left": "1625px",
    "right": "20px",
    "top": "120px",
    "width": "275px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
