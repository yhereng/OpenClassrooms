{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"black\"><font size=\"7\"><br>\n",
    "     Project 7 - Advanced Model\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "import nltk\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from gensim.models import doc2vec\n",
    "\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"D:/Data OC/P7/sentiment140/training.1600000.processed.noemoticon.csv\",header=None,names=['target','text'],usecols=[0,5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>@switchfoot http://twitpic.com/2y1zl - Awww, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>is upset that he can't update his Facebook by ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>@Kenichan I dived many times for the ball. Man...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>my whole body feels itchy and like its on fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>@nationwideclass no, it's not behaving at all....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target                                               text\n",
       "0       0  @switchfoot http://twitpic.com/2y1zl - Awww, t...\n",
       "1       0  is upset that he can't update his Facebook by ...\n",
       "2       0  @Kenichan I dived many times for the ball. Man...\n",
       "3       0    my whole body feels itchy and like its on fire \n",
       "4       0  @nationwideclass no, it's not behaving at all...."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to noramlize the target, reformat and save for futur use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['target'] = data['target']/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.astype({'target':'int32'},copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/data_full.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('data/data_full')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600000, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a common datasets for comapring performances across the three approachs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_common = data.sample(n=1600,random_state=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_common.to_csv('data/data_common.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1600, 2)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_common.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1516037</th>\n",
       "      <td>1</td>\n",
       "      <td>Wow, its later than I feel, better wrap up ano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589923</th>\n",
       "      <td>0</td>\n",
       "      <td>@lemonissimo I think the reason I twitted so m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213819</th>\n",
       "      <td>0</td>\n",
       "      <td>@GericaQuinn ahhhhh! dude u suck! lmao. jk! bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10047</th>\n",
       "      <td>0</td>\n",
       "      <td>...aaaand there goes that great day  RIP Mrs W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330460</th>\n",
       "      <td>1</td>\n",
       "      <td>another morning joe free morning ahhhh ... sun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622620</th>\n",
       "      <td>0</td>\n",
       "      <td>Damn packing trumps Xsport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232219</th>\n",
       "      <td>0</td>\n",
       "      <td>bout 2 call it a NIGHT... madd TIRED..gotta he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368574</th>\n",
       "      <td>1</td>\n",
       "      <td>@IneffableNothin I love Pandora, but I am real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441029</th>\n",
       "      <td>0</td>\n",
       "      <td>@simoncurtis wish i could</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393237</th>\n",
       "      <td>1</td>\n",
       "      <td>@GulcinG Hala  in arabic.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text\n",
       "1516037       1  Wow, its later than I feel, better wrap up ano...\n",
       "589923        0  @lemonissimo I think the reason I twitted so m...\n",
       "213819        0  @GericaQuinn ahhhhh! dude u suck! lmao. jk! bu...\n",
       "10047         0  ...aaaand there goes that great day  RIP Mrs W...\n",
       "1330460       1  another morning joe free morning ahhhh ... sun...\n",
       "...         ...                                                ...\n",
       "622620        0                        Damn packing trumps Xsport \n",
       "232219        0  bout 2 call it a NIGHT... madd TIRED..gotta he...\n",
       "1368574       1  @IneffableNothin I love Pandora, but I am real...\n",
       "441029        0                         @simoncurtis wish i could \n",
       "1393237       1                          @GulcinG Hala  in arabic.\n",
       "\n",
       "[1600 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_common"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### creating Json file for Azure deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_common.to_json('data/data_common.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_json = pd.read_json('data/data_common.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1516037</th>\n",
       "      <td>1</td>\n",
       "      <td>Wow, its later than I feel, better wrap up ano...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>589923</th>\n",
       "      <td>0</td>\n",
       "      <td>@lemonissimo I think the reason I twitted so m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213819</th>\n",
       "      <td>0</td>\n",
       "      <td>@GericaQuinn ahhhhh! dude u suck! lmao. jk! bu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10047</th>\n",
       "      <td>0</td>\n",
       "      <td>...aaaand there goes that great day  RIP Mrs W...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1330460</th>\n",
       "      <td>1</td>\n",
       "      <td>another morning joe free morning ahhhh ... sun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622620</th>\n",
       "      <td>0</td>\n",
       "      <td>Damn packing trumps Xsport</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>232219</th>\n",
       "      <td>0</td>\n",
       "      <td>bout 2 call it a NIGHT... madd TIRED..gotta he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368574</th>\n",
       "      <td>1</td>\n",
       "      <td>@IneffableNothin I love Pandora, but I am real...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>441029</th>\n",
       "      <td>0</td>\n",
       "      <td>@simoncurtis wish i could</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1393237</th>\n",
       "      <td>1</td>\n",
       "      <td>@GulcinG Hala  in arabic.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1600 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         target                                               text\n",
       "1516037       1  Wow, its later than I feel, better wrap up ano...\n",
       "589923        0  @lemonissimo I think the reason I twitted so m...\n",
       "213819        0  @GericaQuinn ahhhhh! dude u suck! lmao. jk! bu...\n",
       "10047         0  ...aaaand there goes that great day  RIP Mrs W...\n",
       "1330460       1  another morning joe free morning ahhhh ... sun...\n",
       "...         ...                                                ...\n",
       "622620        0                        Damn packing trumps Xsport \n",
       "232219        0  bout 2 call it a NIGHT... madd TIRED..gotta he...\n",
       "1368574       1  @IneffableNothin I love Pandora, but I am real...\n",
       "441029        0                         @simoncurtis wish i could \n",
       "1393237       1                          @GulcinG Hala  in arabic.\n",
       "\n",
       "[1600 rows x 2 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing common dataset from data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(index=data_common.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1598400, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('data/data_training.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Target distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.histplot(data['target'])\n",
    "plt.title('target distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acuuracy is a good metric for measuring a balanced classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Number of words per tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitted_text = data.text.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_words =[len(text) for text in splitted_text.values]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Number of words per tweet')\n",
    "sns.histplot(nb_words)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionnary = {}\n",
    "for sentence in splitted_text:\n",
    "    for word in sentence:\n",
    "        if word in dictionnary.keys():\n",
    "            dictionnary[word]+=1\n",
    "        else:\n",
    "            dictionnary[word]=1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = pd.DataFrame.from_dict(dictionnary,orient='index',columns=['nb_occur'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1349319, 1)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20193, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[vocab['nb_occur']>46].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65637, 1)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[vocab['nb_occur']>10].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(data, y = None):\n",
    "    '''tokenizes input dataframe considering words of 2 and more characters\n",
    "       and lowercase text and remove numbers\n",
    "    \n",
    "       Parameters\n",
    "       ----------\n",
    "       data : Pandas series to tokenize\n",
    "       \n",
    "       Returns\n",
    "       --------\n",
    "       Pandas series list of tokens'''\n",
    "              \n",
    "        \n",
    "    tokenizer = nltk.RegexpTokenizer(r'\\w{2,}')\n",
    "    sentences = data.str.lower()\n",
    "    sentences = sentences.str.replace('\\d+', '',regex=True)\n",
    "    results = sentences.apply(tokenizer.tokenize)\n",
    "  \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a transformer for pipeline integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import FunctionTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_transformer = FunctionTransformer(func=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemmer(data, y = None, stemmer = PorterStemmer()):\n",
    "    ''' Stems data using stemmer returns stems as a list of strings'''\n",
    "\n",
    "\n",
    "    def stem_sentence(tokenized_sentence):\n",
    "        stems = [stemmer.stem(i) for i in tokenized_sentence]\n",
    "        return stems\n",
    "    \n",
    "    return data.apply(stem_sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a transformer for pipeline integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer_transformer = FunctionTransformer(func=stemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer(data, y = None, lemmatizer = WordNetLemmatizer()):\n",
    "    \n",
    "    def get_wordnet_pos(word):\n",
    "    #Map POS tag to first character lemmatize() accepts\n",
    "        tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "        tag_dict = {\"J\": wordnet.ADJ,\n",
    "                    \"N\": wordnet.NOUN,\n",
    "                    \"V\": wordnet.VERB,\n",
    "                    \"R\": wordnet.ADV}\n",
    "        return tag_dict.get(tag, wordnet.NOUN)\n",
    "\n",
    "\n",
    "    def lem_sentence(tokenized_sentence):\n",
    "        lems = [lemmatizer.lemmatize(i,pos=get_wordnet_pos(i)) for i in tokenized_sentence]\n",
    "        return lems \n",
    "\n",
    "    \n",
    "    return data.apply(lem_sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a transformer for pipeline integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer_transformer = FunctionTransformer(func=lemmatizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## removing stop words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(data, stopwords = nltk.corpus.stopwords.words('english')):\n",
    "    '''Remove stopwords from data'''\n",
    "\n",
    "    # remove stopwords from stems and create a new column\n",
    "    results = [[stem for stem in stems if (\n",
    "        not(stem in stopwords))] for stems in data]\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a transformer for pipeline integration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_stopwords_transformer = FunctionTransformer(remove_stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_stem = Pipeline([('Tokenizer',tokenizer_transformer),\n",
    "                      ('Stemmer',stemmer_transformer),\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_lem = Pipeline([('Tokenizer',tokenizer_transformer),\n",
    "                      ('lemmatizer',lemmatizer_transformer),\n",
    "                      ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.fasttext import FastText as FT_gensim\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Fastext_Transformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = FT_gensim(size=50,min_count=10,)     \n",
    "        \n",
    "        \n",
    "    def build_doc2vec_corpus(self,texts):\n",
    "        '''Returns a training corpus in the appropriate gensim Taggeddocument format'''\n",
    "        results = []\n",
    "        for tag,text in enumerate(texts):\n",
    "            results.append(gensim.models.doc2vec.TaggedDocument(text,[tag]))\n",
    "        return results\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        self.train_corpus = list(self.build_doc2vec_corpus(X))\n",
    "        self.model.build_vocab(sentences=X.values)\n",
    "        self.model.train(X.values,\n",
    "                         epochs=self.model.epochs,\n",
    "                         total_examples=self.model.corpus_count,\n",
    "                         total_words=self.model.corpus_total_words\n",
    "                        )\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def vectorized_sentence(self,sentence):\n",
    "        wordvecs_sent = [self.model.wv[word] for word in sentence]\n",
    "        meanvec_sent = np.array(wordvecs_sent).mean(axis=0)\n",
    "        return meanvec_sent\n",
    "        \n",
    "    \n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self.vectorized_sentence(text) for text in X]\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre trained Glove Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we'll use the glove pretrained vector with a dimension of 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_vectors = gensim.downloader.load('glove-twitter-100')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sentence_pretrained(sentence,Keyedvectors= glove_vectors):\n",
    "    wordvecs_sent = [Keyedvectors[word] for word in sentence if word in Keyedvectors]\n",
    "    if len(wordvecs_sent)>0:\n",
    "        meanvec_sent = np.array(wordvecs_sent).mean(axis=0)\n",
    "    else:\n",
    "        meanvec_sent = np.zeros(Keyedvectors.vector_size)\n",
    "    return meanvec_sent\n",
    "\n",
    "def vectorize_corpus_glove(data):\n",
    "    return [vectorize_sentence_pretrained(text) for text in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "Glove_transformer = FunctionTransformer(func=vectorize_corpus_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Doc2vec_Transformer(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.model = gensim.models.doc2vec.Doc2Vec(vector_size=100, min_count=10, epochs=60)        \n",
    "        self.train_corpus=[]\n",
    "        \n",
    "    def build_doc2vec_corpus(self,texts):\n",
    "        '''Returns a training corpus in the appropriate gensim Taggeddocument format'''\n",
    "        results = []\n",
    "        for tag,text in enumerate(texts):\n",
    "            results.append(gensim.models.doc2vec.TaggedDocument(text,[tag]))\n",
    "        return results\n",
    "\n",
    "    def fit(self, X, y = None):\n",
    "        self.train_corpus = list(self.build_doc2vec_corpus(X))\n",
    "        self.model.build_vocab(self.train_corpus)\n",
    "        self.model.train(self.train_corpus, total_examples=self.model.corpus_count, epochs=self.model.epochs)\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return [self.model.infer_vector(text) for text in X]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing preprocessings with Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from sklearn.metrics import accuracy_score,auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downsampling dataset for reducing training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a sample dataset for testing\n",
    "data_sample = data.sample(n=1000,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data_sample['text']\n",
    "y = data_sample['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataframe for storing results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing_performances=pd.DataFrame(columns=['training_time (s)','Accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time (s)</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [training_time (s), Accuracy]\n",
       "Index: []"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fastext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='Fasttext - No preprocess'\n",
    "\n",
    "pipe_fastext = Pipeline([    ('preprocessing',tokenizer_transformer),\n",
    "                             ('embedding',Fastext_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])\n",
    "\n",
    "start = time.time()\n",
    "pipe_fastext.fit(X_train,y_train)\n",
    "stop = time.time()\n",
    "\n",
    "y_pred = pipe_fastext.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time (s)</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fasttext - No preprocess</th>\n",
       "      <td>23.022785</td>\n",
       "      <td>0.51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          training_time (s)  Accuracy\n",
       "Fasttext - No preprocess          23.022785      0.51"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe_lem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-6ad99a62634a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'Fasttext - Lemmatization'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m pipe_lem_fastext = Pipeline([('preprocessing',pipe_lem),\n\u001b[0m\u001b[0;32m      4\u001b[0m                              \u001b[1;33m(\u001b[0m\u001b[1;34m'embedding'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mFastext_Transformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                              \u001b[1;33m(\u001b[0m\u001b[1;34m'scaler'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pipe_lem' is not defined"
     ]
    }
   ],
   "source": [
    "model_name='Fasttext - Lemmatization'\n",
    "\n",
    "pipe_lem_fastext = Pipeline([('preprocessing',pipe_lem),\n",
    "                             ('embedding',Fastext_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pipe_lem_fastext.fit(X_train,y_train)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_lem_fastext.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Fasttext - stemming'\n",
    "\n",
    "pipe_stem_fastext = Pipeline([('preprocessing',pipe_stem),\n",
    "                             ('embedding',Fastext_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pipe_stem_fastext.fit(X_train,y_train)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_stem_fastext.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time (s)</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fasttext - No preprocess</th>\n",
       "      <td>23.022785</td>\n",
       "      <td>0.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fasttext - stemming</th>\n",
       "      <td>7.574217</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          training_time (s)  Accuracy\n",
       "Fasttext - No preprocess          23.022785     0.510\n",
       "Fasttext - stemming                7.574217     0.515"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre trained Glove"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='Glove - No preprocess'\n",
    "\n",
    "pipe_glove = Pipeline([      ('preprocessing',tokenizer_transformer),\n",
    "                             ('embedding',Glove_transformer),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])\n",
    "\n",
    "start = time.time()\n",
    "pipe_glove.fit(X_train,y_train)\n",
    "stop = time.time()\n",
    "\n",
    "y_pred = pipe_glove.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wtih lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Glove - lemmatization'\n",
    "\n",
    "pipe_lem_glove = Pipeline([('preprocessing',pipe_lem),\n",
    "                             ('embedding',Glove_transformer),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pipe_lem_glove.fit(X_train,y_train)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_lem_glove.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wtih stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Glove - stemming'\n",
    "\n",
    "pipe_stem_glove = Pipeline([('preprocessing',pipe_stem),\n",
    "                             ('embedding',Glove_transformer),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pipe_stem_glove.fit(X_train,y_train)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_stem_glove.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## No preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name='Doc2vec - No preprocess'\n",
    "\n",
    "pipe_doc2vec = Pipeline([    ('preprocessing',tokenizer_transformer),\n",
    "                             ('embedding',Doc2vec_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])\n",
    "\n",
    "start = time.time()\n",
    "pipe_doc2vec.fit(X_train,y_train)\n",
    "stop = time.time()\n",
    "\n",
    "y_pred = pipe_doc2vec.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wtih lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Doc2vec - lemmatization'\n",
    "\n",
    "pipe_lem_doc2vec = Pipeline([('preprocessing',pipe_lem),\n",
    "                             ('embedding',Doc2vec_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pipe_lem_doc2vec.fit(X_train,y_train)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_lem_doc2vec.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wtih stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'Doc2vec - stemming'\n",
    "\n",
    "pipe_stem_doc2vec = Pipeline([('preprocessing',pipe_stem),\n",
    "                             ('embedding',Doc2vec_Transformer()),\n",
    "                             ('scaler',StandardScaler()),\n",
    "                             ('classifier', LogisticRegression(C=1e-2))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "pipe_stem_doc2vec.fit(X_train,y_train)\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_stem_doc2vec.predict(X_test)\n",
    "preprocessing_performances = preprocessing_performances.append(\n",
    "    pd.Series(data={'training_time (s)': stop-start,\n",
    "              'Accuracy': accuracy_score(y_pred,y_test)},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>training_time (s)</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Fasttext - No preprocess</th>\n",
       "      <td>2.917658</td>\n",
       "      <td>0.510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fasttext - Lemmatization</th>\n",
       "      <td>8.671020</td>\n",
       "      <td>0.540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fasttext - stemming</th>\n",
       "      <td>7.859769</td>\n",
       "      <td>0.515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glove - No preprocess</th>\n",
       "      <td>2.781776</td>\n",
       "      <td>0.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glove - lemmatization</th>\n",
       "      <td>6.510423</td>\n",
       "      <td>0.715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Glove - stemming</th>\n",
       "      <td>1.543808</td>\n",
       "      <td>0.695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2vec - No preprocess</th>\n",
       "      <td>3.841180</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2vec - lemmatization</th>\n",
       "      <td>11.377107</td>\n",
       "      <td>0.610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc2vec - stemming</th>\n",
       "      <td>4.476753</td>\n",
       "      <td>0.595</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          training_time (s)  Accuracy\n",
       "Fasttext - No preprocess           2.917658     0.510\n",
       "Fasttext - Lemmatization           8.671020     0.540\n",
       "Fasttext - stemming                7.859769     0.515\n",
       "Glove - No preprocess              2.781776     0.740\n",
       "Glove - lemmatization              6.510423     0.715\n",
       "Glove - stemming                   1.543808     0.695\n",
       "Doc2vec - No preprocess            3.841180     0.595\n",
       "Doc2vec - lemmatization           11.377107     0.610\n",
       "Doc2vec - stemming                 4.476753     0.595"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessing_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing text data to fit Keras requirement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the NN needs an input matrix with documents represented as an interger list, each interger is a word. we'll choose sequence length to be tweet_length(based on EDA it makes sense, if less than tweet_length use 0 padding) and vocabulary size max_token (based on preliminary EDA). We'll use Keras' vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_length = 30\n",
    "max_tokens = 60000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "vectorizer = TextVectorization(max_tokens=max_tokens,output_sequence_length=tweet_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating test and train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a sample dataset for testing\n",
    "data_sample = data.sample(n=15000,random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X = data_sample['text']\n",
    "y = data_sample['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=33,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_sets(X_train,X_test,vocab_length=20000,tweet_length=30):\n",
    "    '''Compute and return the vectors of the documents in X_train and X_test with a fixed length'''\n",
    "    vectorizer = TextVectorization(max_tokens=vocab_length,output_sequence_length=tweet_length)\n",
    "    vectorizer.adapt(X_train.values)\n",
    "    voc = vectorizer.get_vocabulary() # vocabulary for futur use\n",
    "    word_index = dict(zip(voc, range(len(voc)))) # word index for futur use\n",
    "    return (vectorizer(X_train.values),vectorizer(X_test.values),voc,word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_raw, X_test_raw, voc_raw, word_index_raw = vectorize_sets(\n",
    "    X_train,\n",
    "    X_test,\n",
    "    vocab_length=max_tokens,\n",
    "    tweet_length=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### basic preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect, X_test_vect, voc, word_index = vectorize_sets(\n",
    "    tokenizer_transformer.transform(X_train).str.join(sep=' '),\n",
    "    tokenizer_transformer.transform(X_test).str.join(sep=' '),\n",
    "    vocab_length=max_tokens,\n",
    "    tweet_length=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vect_stem, X_test_vect_stem, voc_stem, word_index_stem = vectorize_sets(\n",
    "    stemmer_transformer.transform(tokenizer_transformer.transform(X_train)).str.join(sep=' '),\n",
    "    stemmer_transformer.transform(tokenizer_transformer.transform(X_test)).str.join(sep=' '),\n",
    "    vocab_length=max_tokens,\n",
    "    tweet_length=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\Code\\Anaconda\\lib\\genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] Le fichier spÃ©cifiÃ© est introuvable: 'C:\\\\Users\\\\Soyann/nltk_data'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-568-8bda6fcceb05>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m X_train_vect_lem, X_test_vect_lem, voc_lem, word_index_lem = vectorize_sets(\n\u001b[1;32m----> 2\u001b[1;33m     \u001b[0mlemmatizer_transformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer_transformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mlemmatizer_transformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer_transformer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m' '\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mvocab_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_tokens\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     tweet_length=30)\n",
      "\u001b[1;32m~\\Code\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    145\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m         \"\"\"\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkw_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkw_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minverse_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\Anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_function_transformer.py\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X, func, kw_args)\u001b[0m\n\u001b[0;32m    169\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_identity\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 171\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkw_args\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mkw_args\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    173\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-2c24c69093e1>\u001b[0m in \u001b[0;36mlemmatizer\u001b[1;34m(data, y, lemmatizer)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlem_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Code\\Anaconda\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4136\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4137\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4138\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4140\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-2c24c69093e1>\u001b[0m in \u001b[0;36mlem_sentence\u001b[1;34m(tokenized_sentence)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlem_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenized_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mlems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_wordnet_pos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenized_sentence\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlems\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-2c24c69093e1>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mlem_sentence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenized_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[0mlems\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mlemmatizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mget_wordnet_pos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenized_sentence\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mlems\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-13-2c24c69093e1>\u001b[0m in \u001b[0;36mget_wordnet_pos\u001b[1;34m(word)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_wordnet_pos\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;31m#Map POS tag to first character lemmatize() accepts\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         tag_dict = {\"J\": wordnet.ADJ,\n\u001b[0;32m      7\u001b[0m                     \u001b[1;34m\"N\"\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\Anaconda\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36mpos_tag\u001b[1;34m(tokens, tagset, lang)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mrtype\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m     \"\"\"\n\u001b[1;32m--> 164\u001b[1;33m     \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_pos_tag\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\Anaconda\\lib\\site-packages\\nltk\\tag\\__init__.py\u001b[0m in \u001b[0;36m_get_tagger\u001b[1;34m(lang)\u001b[0m\n\u001b[0;32m    104\u001b[0m         \u001b[0mtagger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0map_russian_model_loc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m         \u001b[0mtagger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mPerceptronTagger\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    107\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtagger\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\Anaconda\\lib\\site-packages\\nltk\\tag\\perceptron.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, load)\u001b[0m\n\u001b[0;32m    166\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mload\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m             AP_MODEL_LOC = \"file:\" + str(\n\u001b[1;32m--> 168\u001b[1;33m                 \u001b[0mfind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"taggers/averaged_perceptron_tagger/\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mPICKLE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m             )\n\u001b[0;32m    170\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAP_MODEL_LOC\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\Anaconda\\lib\\site-packages\\nltk\\data.py\u001b[0m in \u001b[0;36mfind\u001b[1;34m(resource_name, paths)\u001b[0m\n\u001b[0;32m    520\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mpath_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpaths\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    521\u001b[0m         \u001b[1;31m# Is the path item a zipfile?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 522\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mpath_\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mpath_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\".zip\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    523\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mZipFilePathPointer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresource_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Code\\Anaconda\\lib\\genericpath.py\u001b[0m in \u001b[0;36misfile\u001b[1;34m(path)\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;34m\"\"\"Test whether a path is a regular file\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m         \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mOSError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "X_train_vect_lem, X_test_vect_lem, voc_lem, word_index_lem = vectorize_sets(\n",
    "    lemmatizer_transformer.transform(tokenizer_transformer.transform(X_train)).str.join(sep=' '),\n",
    "    lemmatizer_transformer.transform(tokenizer_transformer.transform(X_test)).str.join(sep=' '),\n",
    "    vocab_length=max_tokens,\n",
    "    tweet_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " raw vocab length 3163 \n",
      " no processing vocab length 3002 \n",
      " stem vocab length 2683 \n",
      " lem vocab length 2717\n"
     ]
    }
   ],
   "source": [
    "print(f' raw vocab length {len(voc_raw)} \\n no processing vocab length {len(voc)} \\n stem vocab length {len(voc_stem)} \\n lem vocab length {len(voc_lem)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f' raw vocab length {len(voc_raw)} \\n no processing vocab length {len(voc)}  \\n stem vocab length {len(voc_stem)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing preprocessing on a simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances=pd.DataFrame(columns=['AUC','Accuracy','Epoch max reach'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 30, 100)           2295300   \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 24008     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 2,319,317\n",
      "Trainable params: 2,319,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'simple NN - raw text'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(voc_raw),100 ,input_length = tweet_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "12/12 [==============================] - 1s 85ms/step - loss: 0.6920 - accuracy: 0.5223 - auc: 0.5310 - val_loss: 0.6885 - val_accuracy: 0.5617 - val_auc: 0.5818\n",
      "Epoch 2/15\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.6702 - accuracy: 0.6313 - auc: 0.6976 - val_loss: 0.6737 - val_accuracy: 0.5747 - val_auc: 0.6621\n",
      "Epoch 3/15\n",
      "12/12 [==============================] - 1s 56ms/step - loss: 0.6152 - accuracy: 0.7582 - auc: 0.8456 - val_loss: 0.6369 - val_accuracy: 0.6500 - val_auc: 0.7376\n",
      "Epoch 4/15\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.5116 - accuracy: 0.8492 - auc: 0.9248 - val_loss: 0.5906 - val_accuracy: 0.6963 - val_auc: 0.7699\n",
      "Epoch 5/15\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.3880 - accuracy: 0.8988 - auc: 0.9604 - val_loss: 0.5580 - val_accuracy: 0.7140 - val_auc: 0.7914\n",
      "Epoch 6/15\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.2756 - accuracy: 0.9370 - auc: 0.9820 - val_loss: 0.5391 - val_accuracy: 0.7233 - val_auc: 0.8054\n",
      "Epoch 7/15\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.1877 - accuracy: 0.9647 - auc: 0.9936 - val_loss: 0.5306 - val_accuracy: 0.7337 - val_auc: 0.8125\n",
      "Epoch 8/15\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.1271 - accuracy: 0.9807 - auc: 0.9979 - val_loss: 0.5330 - val_accuracy: 0.7360 - val_auc: 0.8130\n",
      "Epoch 9/15\n",
      "12/12 [==============================] - 1s 60ms/step - loss: 0.0886 - accuracy: 0.9883 - auc: 0.9992 - val_loss: 0.5434 - val_accuracy: 0.7373 - val_auc: 0.8107\n",
      "Epoch 10/15\n",
      "12/12 [==============================] - 1s 62ms/step - loss: 0.0633 - accuracy: 0.9933 - auc: 0.9997 - val_loss: 0.5556 - val_accuracy: 0.7367 - val_auc: 0.8085\n",
      "Epoch 11/15\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0473 - accuracy: 0.9955 - auc: 0.9999 - val_loss: 0.5673 - val_accuracy: 0.7330 - val_auc: 0.8067\n",
      "Epoch 12/15\n",
      "12/12 [==============================] - 1s 57ms/step - loss: 0.0365 - accuracy: 0.9973 - auc: 0.9999 - val_loss: 0.5800 - val_accuracy: 0.7290 - val_auc: 0.8052\n",
      "Epoch 13/15\n",
      "12/12 [==============================] - 1s 59ms/step - loss: 0.0292 - accuracy: 0.9975 - auc: 1.0000 - val_loss: 0.5926 - val_accuracy: 0.7313 - val_auc: 0.8034\n",
      "Epoch 14/15\n",
      "12/12 [==============================] - 1s 58ms/step - loss: 0.0237 - accuracy: 0.9984 - auc: 1.0000 - val_loss: 0.6050 - val_accuracy: 0.7290 - val_auc: 0.8023\n",
      "Epoch 15/15\n",
      "12/12 [==============================] - 1s 61ms/step - loss: 0.0195 - accuracy: 0.9987 - auc: 1.0000 - val_loss: 0.6184 - val_accuracy: 0.7280 - val_auc: 0.8014\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_raw, y_train, batch_size=1024, epochs=15, validation_data=(X_test_raw, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "\n",
    "def vectorize_request(X,vocab_length=60000,tweet_length=30):\n",
    "    \n",
    "    '''Compute and return the vectors of the documents in X_train and X_test with a fixed length'''\n",
    "    X_pre=tokenizer_transformer.transform(X).str.join(sep=' ')\n",
    "    vectorizer = TextVectorization(max_tokens=vocab_length,output_sequence_length=tweet_length)\n",
    "    vectorizer.adapt(X_pre.values)     \n",
    "    return (vectorizer(X_pre.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>0.812993</td>\n",
       "      <td>0.737333</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.552917</td>\n",
       "      <td>6.694889</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           AUC  Accuracy  Epoch max reach  \\\n",
       "simple NN - raw text  0.812993  0.737333              8.0   \n",
       "\n",
       "                      total training time  training time to opt  \n",
       "simple NN - raw text            12.552917              6.694889  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Basic preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_30\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_24 (Embedding)     (None, 30, 100)           300200    \n",
      "_________________________________________________________________\n",
      "flatten_21 (Flatten)         (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense_51 (Dense)             (None, 8)                 24008     \n",
      "_________________________________________________________________\n",
      "dense_52 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 324,217\n",
      "Trainable params: 324,217\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'simple NN - Basic preprocessing'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1/1 [==============================] - 0s 297ms/step - loss: 0.6934 - accuracy: 0.4762 - auc: 0.4836 - val_loss: 0.6935 - val_accuracy: 0.5200 - val_auc: 0.4852\n",
      "Epoch 2/15\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6908 - accuracy: 0.5312 - auc: 0.6154 - val_loss: 0.6935 - val_accuracy: 0.5150 - val_auc: 0.4672\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6869 - accuracy: 0.5575 - auc: 0.7482 - val_loss: 0.6935 - val_accuracy: 0.5050 - val_auc: 0.4965\n",
      "Epoch 4/15\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6816 - accuracy: 0.6087 - auc: 0.8015 - val_loss: 0.6934 - val_accuracy: 0.4700 - val_auc: 0.4957\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6762 - accuracy: 0.6575 - auc: 0.8289 - val_loss: 0.6930 - val_accuracy: 0.4800 - val_auc: 0.5100\n",
      "Epoch 6/15\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6704 - accuracy: 0.7125 - auc: 0.8571 - val_loss: 0.6925 - val_accuracy: 0.5150 - val_auc: 0.5235\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 0s 18ms/step - loss: 0.6639 - accuracy: 0.7600 - auc: 0.8763 - val_loss: 0.6921 - val_accuracy: 0.5350 - val_auc: 0.5200\n",
      "Epoch 8/15\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6568 - accuracy: 0.7800 - auc: 0.8982 - val_loss: 0.6917 - val_accuracy: 0.5500 - val_auc: 0.5286\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6490 - accuracy: 0.8012 - auc: 0.9157 - val_loss: 0.6913 - val_accuracy: 0.5550 - val_auc: 0.5320\n",
      "Epoch 10/15\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6404 - accuracy: 0.8150 - auc: 0.9341 - val_loss: 0.6910 - val_accuracy: 0.5650 - val_auc: 0.5390\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6311 - accuracy: 0.8400 - auc: 0.9512 - val_loss: 0.6907 - val_accuracy: 0.5700 - val_auc: 0.5427\n",
      "Epoch 12/15\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6210 - accuracy: 0.8725 - auc: 0.9647 - val_loss: 0.6903 - val_accuracy: 0.5750 - val_auc: 0.5464\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6101 - accuracy: 0.8925 - auc: 0.9754 - val_loss: 0.6900 - val_accuracy: 0.5700 - val_auc: 0.5463\n",
      "Epoch 14/15\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.5984 - accuracy: 0.9250 - auc: 0.9837 - val_loss: 0.6896 - val_accuracy: 0.5750 - val_auc: 0.5508\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5859 - accuracy: 0.9388 - auc: 0.9892 - val_loss: 0.6893 - val_accuracy: 0.5800 - val_auc: 0.5522\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=15, validation_data=(X_test_vect, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>0.565709</td>\n",
       "      <td>0.545</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.864824</td>\n",
       "      <td>1.616180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>0.552197</td>\n",
       "      <td>0.580</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.833601</td>\n",
       "      <td>1.711361</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      AUC  Accuracy  Epoch max reach  \\\n",
       "simple NN - raw text             0.565709     0.545             13.0   \n",
       "simple NN - Basic preprocessing  0.552197     0.580             14.0   \n",
       "\n",
       "                                 total training time  training time to opt  \n",
       "simple NN - raw text                        1.864824              1.616180  \n",
       "simple NN - Basic preprocessing             1.833601              1.711361  "
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_31\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_25 (Embedding)     (None, 30, 100)           268300    \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense_53 (Dense)             (None, 8)                 24008     \n",
      "_________________________________________________________________\n",
      "dense_54 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 292,317\n",
      "Trainable params: 292,317\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'simple NN - Stemming'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(voc_stem),100 ,input_length = tweet_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1/1 [==============================] - 0s 241ms/step - loss: 0.6945 - accuracy: 0.4975 - auc: 0.4486 - val_loss: 0.6930 - val_accuracy: 0.5100 - val_auc: 0.4861\n",
      "Epoch 2/15\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6889 - accuracy: 0.6037 - auc: 0.6771 - val_loss: 0.6929 - val_accuracy: 0.4850 - val_auc: 0.5033\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6824 - accuracy: 0.6938 - auc: 0.7906 - val_loss: 0.6924 - val_accuracy: 0.5000 - val_auc: 0.5158\n",
      "Epoch 4/15\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6752 - accuracy: 0.7262 - auc: 0.8296 - val_loss: 0.6915 - val_accuracy: 0.4950 - val_auc: 0.5172\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.6673 - accuracy: 0.7188 - auc: 0.8574 - val_loss: 0.6904 - val_accuracy: 0.5050 - val_auc: 0.5339\n",
      "Epoch 6/15\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6586 - accuracy: 0.7362 - auc: 0.8873 - val_loss: 0.6896 - val_accuracy: 0.5150 - val_auc: 0.5462\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6489 - accuracy: 0.7775 - auc: 0.9154 - val_loss: 0.6887 - val_accuracy: 0.5400 - val_auc: 0.5532\n",
      "Epoch 8/15\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6385 - accuracy: 0.8350 - auc: 0.9339 - val_loss: 0.6878 - val_accuracy: 0.5700 - val_auc: 0.5561\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6269 - accuracy: 0.8737 - auc: 0.9503 - val_loss: 0.6870 - val_accuracy: 0.5600 - val_auc: 0.5627\n",
      "Epoch 10/15\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.6144 - accuracy: 0.9038 - auc: 0.9676 - val_loss: 0.6860 - val_accuracy: 0.5650 - val_auc: 0.5696\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.6007 - accuracy: 0.9212 - auc: 0.9780 - val_loss: 0.6850 - val_accuracy: 0.5700 - val_auc: 0.5774\n",
      "Epoch 12/15\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5861 - accuracy: 0.9225 - auc: 0.9855 - val_loss: 0.6840 - val_accuracy: 0.5800 - val_auc: 0.5782\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5704 - accuracy: 0.9312 - auc: 0.9912 - val_loss: 0.6830 - val_accuracy: 0.5750 - val_auc: 0.5865\n",
      "Epoch 14/15\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5536 - accuracy: 0.9538 - auc: 0.9946 - val_loss: 0.6820 - val_accuracy: 0.6050 - val_auc: 0.5894\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5357 - accuracy: 0.9675 - auc: 0.9967 - val_loss: 0.6809 - val_accuracy: 0.5950 - val_auc: 0.5954\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect_stem, y_train, batch_size=1024, epochs=15, validation_data=(X_test_vect_stem, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_32\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_26 (Embedding)     (None, 30, 100)           271700    \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 8)                 24008     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 295,717\n",
      "Trainable params: 295,717\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'simple NN - Lemmatization'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Embedding(len(voc_lem),100 ,input_length = tweet_length))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "1/1 [==============================] - 1s 580ms/step - loss: 0.6923 - accuracy: 0.5288 - auc: 0.5157 - val_loss: 0.6910 - val_accuracy: 0.5500 - val_auc: 0.5585\n",
      "Epoch 2/15\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6863 - accuracy: 0.6325 - auc: 0.6744 - val_loss: 0.6901 - val_accuracy: 0.5250 - val_auc: 0.5569\n",
      "Epoch 3/15\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.6799 - accuracy: 0.6538 - auc: 0.7489 - val_loss: 0.6896 - val_accuracy: 0.5350 - val_auc: 0.5627\n",
      "Epoch 4/15\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6727 - accuracy: 0.6700 - auc: 0.8193 - val_loss: 0.6892 - val_accuracy: 0.5400 - val_auc: 0.5629\n",
      "Epoch 5/15\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.6651 - accuracy: 0.6750 - auc: 0.8794 - val_loss: 0.6888 - val_accuracy: 0.5350 - val_auc: 0.5576\n",
      "Epoch 6/15\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.6573 - accuracy: 0.7050 - auc: 0.9143 - val_loss: 0.6883 - val_accuracy: 0.5300 - val_auc: 0.5569\n",
      "Epoch 7/15\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6486 - accuracy: 0.7663 - auc: 0.9289 - val_loss: 0.6878 - val_accuracy: 0.5450 - val_auc: 0.5628\n",
      "Epoch 8/15\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.6391 - accuracy: 0.8250 - auc: 0.9419 - val_loss: 0.6872 - val_accuracy: 0.5500 - val_auc: 0.5605\n",
      "Epoch 9/15\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6287 - accuracy: 0.8562 - auc: 0.9546 - val_loss: 0.6867 - val_accuracy: 0.5450 - val_auc: 0.5633\n",
      "Epoch 10/15\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6176 - accuracy: 0.8725 - auc: 0.9654 - val_loss: 0.6864 - val_accuracy: 0.5450 - val_auc: 0.5672\n",
      "Epoch 11/15\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.6055 - accuracy: 0.8988 - auc: 0.9761 - val_loss: 0.6862 - val_accuracy: 0.5500 - val_auc: 0.5668\n",
      "Epoch 12/15\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5925 - accuracy: 0.9137 - auc: 0.9831 - val_loss: 0.6859 - val_accuracy: 0.5650 - val_auc: 0.5679\n",
      "Epoch 13/15\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.5786 - accuracy: 0.9312 - auc: 0.9882 - val_loss: 0.6856 - val_accuracy: 0.5600 - val_auc: 0.5712\n",
      "Epoch 14/15\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5640 - accuracy: 0.9463 - auc: 0.9911 - val_loss: 0.6852 - val_accuracy: 0.5600 - val_auc: 0.5746\n",
      "Epoch 15/15\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.5485 - accuracy: 0.9563 - auc: 0.9934 - val_loss: 0.6850 - val_accuracy: 0.5650 - val_auc: 0.5756\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect_lem, y_train, batch_size=1024, epochs=15, validation_data=(X_test_vect_lem, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary of Preprocessing performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>0.565709</td>\n",
       "      <td>0.545</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.864824</td>\n",
       "      <td>1.616180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>0.552197</td>\n",
       "      <td>0.580</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.833601</td>\n",
       "      <td>1.711361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Stemming</th>\n",
       "      <td>0.595386</td>\n",
       "      <td>0.605</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.769638</td>\n",
       "      <td>1.533687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Lemmatization</th>\n",
       "      <td>0.575568</td>\n",
       "      <td>0.565</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.058595</td>\n",
       "      <td>2.242970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      AUC  Accuracy  Epoch max reach  \\\n",
       "simple NN - raw text             0.565709     0.545             13.0   \n",
       "simple NN - Basic preprocessing  0.552197     0.580             14.0   \n",
       "simple NN - Stemming             0.595386     0.605             13.0   \n",
       "simple NN - Lemmatization        0.575568     0.565             11.0   \n",
       "\n",
       "                                 total training time  training time to opt  \n",
       "simple NN - raw text                        1.864824              1.616180  \n",
       "simple NN - Basic preprocessing             1.833601              1.711361  \n",
       "simple NN - Stemming                        1.769638              1.533687  \n",
       "simple NN - Lemmatization                   3.058595              2.242970  "
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances.to_pickle('data/models_performances')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 437,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = pd.read_pickle('data/models_performances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the embedding matrix ( word / coeff matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since Glove embedding shows better results, we'll use it from now on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1193514 word vectors.\n"
     ]
    }
   ],
   "source": [
    "embeddings_index = {}\n",
    "with open(\"D:/Data OC/P7/glove.twitter.27B.100d.txt\",encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        word, coefs = line.split(maxsplit=1)\n",
    "        coefs = np.fromstring(coefs, \"f\", sep=\" \")\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "print(\"Found %s word vectors.\" % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the embedding matrix which can be used in a Keras Embedding layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converted 26680 words (21494 misses)\n"
     ]
    }
   ],
   "source": [
    "num_tokens = len(voc) + 2\n",
    "embedding_dim = 100\n",
    "hits = 0\n",
    "misses = 0\n",
    "misses_word=[]\n",
    "\n",
    "# Prepare embedding matrix\n",
    "embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        # Words not found in embedding index will be all-zeros.\n",
    "        # This includes the representation for \"padding\" and \"OOV\"\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        hits += 1\n",
    "    else:\n",
    "        misses += 1\n",
    "        misses_word.append(word)\n",
    "print(\"Converted %d words (%d misses)\" % (hits, misses))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['timothyho',\n",
       " 'ticklemejoey',\n",
       " 'thomasfiss',\n",
       " 'thisisrobthomas',\n",
       " 'thewockeez',\n",
       " 'thebrandicyrus',\n",
       " 'silverlines',\n",
       " 'revrunwisdom',\n",
       " 'pmvry',\n",
       " 'pleaseee',\n",
       " 'peterfacinelli',\n",
       " 'owwww',\n",
       " 'nicksantino',\n",
       " 'nickcarter',\n",
       " 'mrskutcher',\n",
       " 'moonfrye',\n",
       " 'mikeyway',\n",
       " 'mattpro',\n",
       " 'krisallenmusic',\n",
       " 'johncmayer',\n",
       " 'jaylastarr',\n",
       " 'itttt',\n",
       " 'inaperfectworld',\n",
       " 'heyyy',\n",
       " 'heartmileycyrus',\n",
       " 'haveyouever',\n",
       " 'goodsex',\n",
       " 'gailporter',\n",
       " 'frankiethesats',\n",
       " 'flylady',\n",
       " 'errr',\n",
       " 'chuckmemondays',\n",
       " 'buckhollywood',\n",
       " 'bkite',\n",
       " 'babygirlparis',\n",
       " 'anoopdoggdesai',\n",
       " 'youuuu',\n",
       " 'yayyyyy',\n",
       " 'woohooo',\n",
       " 'wilw',\n",
       " 'wethetravis',\n",
       " 'wethedan',\n",
       " 'tyresereal',\n",
       " 'twtrcon',\n",
       " 'tsarnick',\n",
       " 'thedebbyryan',\n",
       " 'tdlq',\n",
       " 'symphnysldr',\n",
       " 'shhh',\n",
       " 'schaeferj',\n",
       " 'realhughjackman',\n",
       " 'potface',\n",
       " 'popits',\n",
       " 'petewentz',\n",
       " 'papercakes',\n",
       " 'otalia',\n",
       " 'oliviamunn',\n",
       " 'offf',\n",
       " 'oceanup',\n",
       " 'noelclarke',\n",
       " 'nicolerichie',\n",
       " 'nickybyrneoffic',\n",
       " 'neilhimself',\n",
       " 'necolebitchie',\n",
       " 'nawww',\n",
       " 'nahhh',\n",
       " 'mgiraudofficial',\n",
       " 'mellalicious',\n",
       " 'mcflyharry',\n",
       " 'mannn',\n",
       " 'maddd',\n",
       " 'lvbu',\n",
       " 'longestpoemintheworld',\n",
       " 'lmaoooo',\n",
       " 'lisaveronica',\n",
       " 'lalavazquez',\n",
       " 'knowww',\n",
       " 'kimsherrell',\n",
       " 'kendrawilkinson',\n",
       " 'kathyireland',\n",
       " 'jlsofficial',\n",
       " 'jeweljk',\n",
       " 'itagg',\n",
       " 'isplayer',\n",
       " 'iamjonathancook',\n",
       " 'honorsociety',\n",
       " 'heycassadee',\n",
       " 'hellooo',\n",
       " 'grrrrrr',\n",
       " 'greggarbo',\n",
       " 'garethcliff',\n",
       " 'freddurst',\n",
       " 'dazzlemethis',\n",
       " 'custardcuppcake',\n",
       " 'crystalchappell',\n",
       " 'coollike',\n",
       " 'comedyqueen',\n",
       " 'colorblindfish',\n",
       " 'chriscornell',\n",
       " 'booooo']"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "misses_word[100:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "import keras\n",
    "\n",
    "embedding_layer = Embedding(\n",
    "    num_tokens,\n",
    "    embedding_dim,\n",
    "    embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "    input_length=tweet_length,\n",
    "    trainable=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_33\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (None, 30, 100)           300400    \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 3000)              0         \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 8)                 24008     \n",
      "_________________________________________________________________\n",
      "dense_58 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 324,417\n",
      "Trainable params: 24,017\n",
      "Non-trainable params: 300,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'simple NN - GLoVe embedding'\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(embedding_layer)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 0s 269ms/step - loss: 0.7413 - accuracy: 0.4613 - auc: 0.4289 - val_loss: 0.7007 - val_accuracy: 0.4950 - val_auc: 0.5034\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.7021 - accuracy: 0.5138 - auc: 0.5186 - val_loss: 0.6925 - val_accuracy: 0.5150 - val_auc: 0.5384\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.6715 - accuracy: 0.5825 - auc: 0.6201 - val_loss: 0.6859 - val_accuracy: 0.5250 - val_auc: 0.5688\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.6459 - accuracy: 0.6463 - auc: 0.7031 - val_loss: 0.6803 - val_accuracy: 0.5400 - val_auc: 0.5885\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.6222 - accuracy: 0.6800 - auc: 0.7619 - val_loss: 0.6750 - val_accuracy: 0.5650 - val_auc: 0.6033\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.5987 - accuracy: 0.7163 - auc: 0.8059 - val_loss: 0.6694 - val_accuracy: 0.5900 - val_auc: 0.6163\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5747 - accuracy: 0.7487 - auc: 0.8402 - val_loss: 0.6645 - val_accuracy: 0.5950 - val_auc: 0.6293\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5509 - accuracy: 0.7750 - auc: 0.8666 - val_loss: 0.6605 - val_accuracy: 0.6050 - val_auc: 0.6387\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.5284 - accuracy: 0.8087 - auc: 0.8871 - val_loss: 0.6575 - val_accuracy: 0.6050 - val_auc: 0.6420\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.5072 - accuracy: 0.8238 - auc: 0.9010 - val_loss: 0.6553 - val_accuracy: 0.5850 - val_auc: 0.6472\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4868 - accuracy: 0.8350 - auc: 0.9131 - val_loss: 0.6529 - val_accuracy: 0.6000 - val_auc: 0.6535\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 10ms/step - loss: 0.4673 - accuracy: 0.8413 - auc: 0.9226 - val_loss: 0.6513 - val_accuracy: 0.6150 - val_auc: 0.6569\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 17ms/step - loss: 0.4490 - accuracy: 0.8413 - auc: 0.9310 - val_loss: 0.6502 - val_accuracy: 0.6200 - val_auc: 0.6604\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.4317 - accuracy: 0.8512 - auc: 0.9381 - val_loss: 0.6495 - val_accuracy: 0.6150 - val_auc: 0.6644\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 14ms/step - loss: 0.4150 - accuracy: 0.8600 - auc: 0.9453 - val_loss: 0.6491 - val_accuracy: 0.6050 - val_auc: 0.6683\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3990 - accuracy: 0.8737 - auc: 0.9520 - val_loss: 0.6489 - val_accuracy: 0.6100 - val_auc: 0.6705\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3837 - accuracy: 0.8900 - auc: 0.9579 - val_loss: 0.6489 - val_accuracy: 0.6150 - val_auc: 0.6707\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3692 - accuracy: 0.8950 - auc: 0.9629 - val_loss: 0.6487 - val_accuracy: 0.6100 - val_auc: 0.6756\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3553 - accuracy: 0.9025 - auc: 0.9674 - val_loss: 0.6484 - val_accuracy: 0.6100 - val_auc: 0.6776\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3420 - accuracy: 0.9075 - auc: 0.9712 - val_loss: 0.6482 - val_accuracy: 0.6150 - val_auc: 0.6803\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3295 - accuracy: 0.9100 - auc: 0.9745 - val_loss: 0.6483 - val_accuracy: 0.6200 - val_auc: 0.6820\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.3177 - accuracy: 0.9162 - auc: 0.9774 - val_loss: 0.6489 - val_accuracy: 0.6200 - val_auc: 0.6836\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.3065 - accuracy: 0.9287 - auc: 0.9800 - val_loss: 0.6498 - val_accuracy: 0.6150 - val_auc: 0.6850\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2958 - accuracy: 0.9337 - auc: 0.9821 - val_loss: 0.6512 - val_accuracy: 0.6050 - val_auc: 0.6869\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2856 - accuracy: 0.9362 - auc: 0.9842 - val_loss: 0.6529 - val_accuracy: 0.6200 - val_auc: 0.6880\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2761 - accuracy: 0.9413 - auc: 0.9859 - val_loss: 0.6549 - val_accuracy: 0.6200 - val_auc: 0.6881\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 19ms/step - loss: 0.2670 - accuracy: 0.9463 - auc: 0.9872 - val_loss: 0.6571 - val_accuracy: 0.6200 - val_auc: 0.6891\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2583 - accuracy: 0.9475 - auc: 0.9885 - val_loss: 0.6597 - val_accuracy: 0.6100 - val_auc: 0.6894\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2501 - accuracy: 0.9500 - auc: 0.9895 - val_loss: 0.6626 - val_accuracy: 0.6050 - val_auc: 0.6888\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 20ms/step - loss: 0.2422 - accuracy: 0.9538 - auc: 0.9906 - val_loss: 0.6658 - val_accuracy: 0.6050 - val_auc: 0.6889\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>0.565709</td>\n",
       "      <td>0.545</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.864824</td>\n",
       "      <td>1.616180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>0.552197</td>\n",
       "      <td>0.580</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.833601</td>\n",
       "      <td>1.711361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Stemming</th>\n",
       "      <td>0.595386</td>\n",
       "      <td>0.605</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.769638</td>\n",
       "      <td>1.533687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Lemmatization</th>\n",
       "      <td>0.575568</td>\n",
       "      <td>0.565</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.058595</td>\n",
       "      <td>2.242970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - GLoVe embedding</th>\n",
       "      <td>0.689370</td>\n",
       "      <td>0.620</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.257652</td>\n",
       "      <td>0.903061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      AUC  Accuracy  Epoch max reach  \\\n",
       "simple NN - raw text             0.565709     0.545             13.0   \n",
       "simple NN - Basic preprocessing  0.552197     0.580             14.0   \n",
       "simple NN - Stemming             0.595386     0.605             13.0   \n",
       "simple NN - Lemmatization        0.575568     0.565             11.0   \n",
       "simple NN - GLoVe embedding      0.689370     0.620             12.0   \n",
       "\n",
       "                                 total training time  training time to opt  \n",
       "simple NN - raw text                        1.864824              1.616180  \n",
       "simple NN - Basic preprocessing             1.833601              1.711361  \n",
       "simple NN - Stemming                        1.769638              1.533687  \n",
       "simple NN - Lemmatization                   3.058595              2.242970  \n",
       "simple NN - GLoVe embedding                 2.257652              0.903061  "
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recurrent Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_34\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_28 (Embedding)     (None, 30, 100)           300200    \n",
      "_________________________________________________________________\n",
      "lstm_9 (LSTM)                (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense_59 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 342,505\n",
      "Trainable params: 342,505\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'LSTM - Own embedding '\n",
    "\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(LSTM(lstm_out,dropout=0.4))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 5s 5s/step - loss: 0.6930 - accuracy: 0.5138 - auc: 0.4902 - val_loss: 0.6929 - val_accuracy: 0.5150 - val_auc: 0.4948\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6930 - accuracy: 0.5138 - auc: 0.4969 - val_loss: 0.6927 - val_accuracy: 0.5150 - val_auc: 0.4903\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6925 - accuracy: 0.5138 - auc: 0.5386 - val_loss: 0.6926 - val_accuracy: 0.5150 - val_auc: 0.4951\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6926 - accuracy: 0.5138 - auc: 0.5075 - val_loss: 0.6925 - val_accuracy: 0.5150 - val_auc: 0.5241\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6922 - accuracy: 0.5138 - auc: 0.5671 - val_loss: 0.6923 - val_accuracy: 0.5150 - val_auc: 0.5443\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6918 - accuracy: 0.5138 - auc: 0.5465 - val_loss: 0.6921 - val_accuracy: 0.5150 - val_auc: 0.5272\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6916 - accuracy: 0.5138 - auc: 0.5749 - val_loss: 0.6918 - val_accuracy: 0.5150 - val_auc: 0.5426\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6912 - accuracy: 0.5100 - auc: 0.5618 - val_loss: 0.6915 - val_accuracy: 0.5150 - val_auc: 0.5344\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6901 - accuracy: 0.5300 - auc: 0.5877 - val_loss: 0.6911 - val_accuracy: 0.5100 - val_auc: 0.5407\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6895 - accuracy: 0.5238 - auc: 0.5770 - val_loss: 0.6905 - val_accuracy: 0.5150 - val_auc: 0.5515\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6887 - accuracy: 0.5387 - auc: 0.5696 - val_loss: 0.6899 - val_accuracy: 0.5200 - val_auc: 0.5438\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6870 - accuracy: 0.5487 - auc: 0.5812 - val_loss: 0.6890 - val_accuracy: 0.5300 - val_auc: 0.5513\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6838 - accuracy: 0.5663 - auc: 0.6029 - val_loss: 0.6880 - val_accuracy: 0.5450 - val_auc: 0.5507\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6807 - accuracy: 0.5738 - auc: 0.6146 - val_loss: 0.6868 - val_accuracy: 0.5250 - val_auc: 0.5578\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6761 - accuracy: 0.5763 - auc: 0.6237 - val_loss: 0.6854 - val_accuracy: 0.5350 - val_auc: 0.5620\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6702 - accuracy: 0.5825 - auc: 0.6330 - val_loss: 0.6838 - val_accuracy: 0.5450 - val_auc: 0.5687\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6595 - accuracy: 0.5938 - auc: 0.6589 - val_loss: 0.6821 - val_accuracy: 0.5500 - val_auc: 0.5732\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6465 - accuracy: 0.6100 - auc: 0.6829 - val_loss: 0.6801 - val_accuracy: 0.5600 - val_auc: 0.5856\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.6246 - accuracy: 0.6250 - auc: 0.7192 - val_loss: 0.6780 - val_accuracy: 0.5750 - val_auc: 0.5998\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5937 - accuracy: 0.6862 - auc: 0.7609 - val_loss: 0.6763 - val_accuracy: 0.6000 - val_auc: 0.6146\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5544 - accuracy: 0.7150 - auc: 0.7994 - val_loss: 0.6769 - val_accuracy: 0.5900 - val_auc: 0.6290\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4980 - accuracy: 0.7675 - auc: 0.8530 - val_loss: 0.6826 - val_accuracy: 0.6000 - val_auc: 0.6487\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4345 - accuracy: 0.8037 - auc: 0.8964 - val_loss: 0.6949 - val_accuracy: 0.6350 - val_auc: 0.6707\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.3735 - accuracy: 0.8462 - auc: 0.9308 - val_loss: 0.7145 - val_accuracy: 0.6550 - val_auc: 0.6850\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3042 - accuracy: 0.8913 - auc: 0.9566 - val_loss: 0.7528 - val_accuracy: 0.6450 - val_auc: 0.6984\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.2408 - accuracy: 0.9212 - auc: 0.9734 - val_loss: 0.8036 - val_accuracy: 0.6450 - val_auc: 0.7066\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2154 - accuracy: 0.9362 - auc: 0.9775 - val_loss: 0.8574 - val_accuracy: 0.6450 - val_auc: 0.7122\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1874 - accuracy: 0.9362 - auc: 0.9832 - val_loss: 0.9117 - val_accuracy: 0.6300 - val_auc: 0.7079\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.1691 - accuracy: 0.9500 - auc: 0.9883 - val_loss: 0.9759 - val_accuracy: 0.6300 - val_auc: 0.7081\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.1588 - accuracy: 0.9500 - auc: 0.9883 - val_loss: 1.0302 - val_accuracy: 0.6250 - val_auc: 0.7070\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 449,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 450,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>0.565709</td>\n",
       "      <td>0.545</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.864824</td>\n",
       "      <td>1.616180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>0.552197</td>\n",
       "      <td>0.580</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.833601</td>\n",
       "      <td>1.711361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Stemming</th>\n",
       "      <td>0.595386</td>\n",
       "      <td>0.605</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.769638</td>\n",
       "      <td>1.533687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Lemmatization</th>\n",
       "      <td>0.575568</td>\n",
       "      <td>0.565</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.058595</td>\n",
       "      <td>2.242970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - GLoVe embedding</th>\n",
       "      <td>0.689370</td>\n",
       "      <td>0.620</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.257652</td>\n",
       "      <td>0.903061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - Own embedding</th>\n",
       "      <td>0.712241</td>\n",
       "      <td>0.655</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.925077</td>\n",
       "      <td>16.809226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      AUC  Accuracy  Epoch max reach  \\\n",
       "simple NN - raw text             0.565709     0.545             13.0   \n",
       "simple NN - Basic preprocessing  0.552197     0.580             14.0   \n",
       "simple NN - Stemming             0.595386     0.605             13.0   \n",
       "simple NN - Lemmatization        0.575568     0.565             11.0   \n",
       "simple NN - GLoVe embedding      0.689370     0.620             12.0   \n",
       "LSTM - Own embedding             0.712241     0.655             23.0   \n",
       "\n",
       "                                 total training time  training time to opt  \n",
       "simple NN - raw text                        1.864824              1.616180  \n",
       "simple NN - Basic preprocessing             1.833601              1.711361  \n",
       "simple NN - Stemming                        1.769638              1.533687  \n",
       "simple NN - Lemmatization                   3.058595              2.242970  \n",
       "simple NN - GLoVe embedding                 2.257652              0.903061  \n",
       "LSTM - Own embedding                       21.925077             16.809226  "
      ]
     },
     "execution_count": 450,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### With GLoVe embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 451,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (None, 30, 100)           300400    \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               (None, 64)                42240     \n",
      "_________________________________________________________________\n",
      "dense_60 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 342,705\n",
      "Trainable params: 42,305\n",
      "Non-trainable params: 300,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=0.2))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 860ms/step - loss: 0.6919 - accuracy: 0.5325 - auc: 0.5297 - val_loss: 0.6887 - val_accuracy: 0.5150 - val_auc: 0.5816\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6903 - accuracy: 0.5138 - auc: 0.5592 - val_loss: 0.6869 - val_accuracy: 0.5150 - val_auc: 0.5605\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6890 - accuracy: 0.5113 - auc: 0.5526 - val_loss: 0.6855 - val_accuracy: 0.5150 - val_auc: 0.5723\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6877 - accuracy: 0.5125 - auc: 0.5646 - val_loss: 0.6844 - val_accuracy: 0.5150 - val_auc: 0.5700\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6872 - accuracy: 0.5125 - auc: 0.5732 - val_loss: 0.6831 - val_accuracy: 0.5200 - val_auc: 0.5720\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6861 - accuracy: 0.5163 - auc: 0.5747 - val_loss: 0.6816 - val_accuracy: 0.5150 - val_auc: 0.5900\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6842 - accuracy: 0.5562 - auc: 0.5839 - val_loss: 0.6797 - val_accuracy: 0.5600 - val_auc: 0.5943\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6831 - accuracy: 0.5587 - auc: 0.5930 - val_loss: 0.6774 - val_accuracy: 0.5800 - val_auc: 0.6033\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.6800 - accuracy: 0.5663 - auc: 0.6171 - val_loss: 0.6747 - val_accuracy: 0.6050 - val_auc: 0.6472\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6780 - accuracy: 0.5763 - auc: 0.6346 - val_loss: 0.6714 - val_accuracy: 0.6000 - val_auc: 0.6661\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.6750 - accuracy: 0.5938 - auc: 0.6628 - val_loss: 0.6673 - val_accuracy: 0.6000 - val_auc: 0.6830\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6718 - accuracy: 0.6075 - auc: 0.6848 - val_loss: 0.6616 - val_accuracy: 0.6100 - val_auc: 0.6992\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6659 - accuracy: 0.6338 - auc: 0.7007 - val_loss: 0.6537 - val_accuracy: 0.6350 - val_auc: 0.7149\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6593 - accuracy: 0.6463 - auc: 0.7137 - val_loss: 0.6437 - val_accuracy: 0.6550 - val_auc: 0.7195\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6524 - accuracy: 0.6500 - auc: 0.7130 - val_loss: 0.6317 - val_accuracy: 0.6750 - val_auc: 0.7358\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6416 - accuracy: 0.6650 - auc: 0.7304 - val_loss: 0.6174 - val_accuracy: 0.6800 - val_auc: 0.7457\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6303 - accuracy: 0.6812 - auc: 0.7434 - val_loss: 0.6010 - val_accuracy: 0.7050 - val_auc: 0.7622\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6146 - accuracy: 0.6988 - auc: 0.7589 - val_loss: 0.5879 - val_accuracy: 0.6950 - val_auc: 0.7760\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6064 - accuracy: 0.6800 - auc: 0.7549 - val_loss: 0.5796 - val_accuracy: 0.7000 - val_auc: 0.7761\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5845 - accuracy: 0.7050 - auc: 0.7710 - val_loss: 0.5747 - val_accuracy: 0.7000 - val_auc: 0.7774\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5796 - accuracy: 0.7163 - auc: 0.7698 - val_loss: 0.5705 - val_accuracy: 0.6950 - val_auc: 0.7745\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5773 - accuracy: 0.7013 - auc: 0.7783 - val_loss: 0.5908 - val_accuracy: 0.6750 - val_auc: 0.7630\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5764 - accuracy: 0.6975 - auc: 0.7741 - val_loss: 0.5879 - val_accuracy: 0.6950 - val_auc: 0.7627\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5646 - accuracy: 0.7100 - auc: 0.7848 - val_loss: 0.5801 - val_accuracy: 0.6950 - val_auc: 0.7693\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5601 - accuracy: 0.7300 - auc: 0.7929 - val_loss: 0.5735 - val_accuracy: 0.7000 - val_auc: 0.7738\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5465 - accuracy: 0.7188 - auc: 0.8073 - val_loss: 0.5831 - val_accuracy: 0.7000 - val_auc: 0.7699\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.5389 - accuracy: 0.7400 - auc: 0.8046 - val_loss: 0.5912 - val_accuracy: 0.6900 - val_auc: 0.7656\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5325 - accuracy: 0.7412 - auc: 0.8226 - val_loss: 0.5763 - val_accuracy: 0.6950 - val_auc: 0.7673\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5321 - accuracy: 0.7300 - auc: 0.8142 - val_loss: 0.5756 - val_accuracy: 0.6700 - val_auc: 0.7624\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.5271 - accuracy: 0.7412 - auc: 0.8196 - val_loss: 0.5764 - val_accuracy: 0.6750 - val_auc: 0.7592\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 453,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "acc = hist.history['accuracy']\n",
    "val = hist.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, '-', label='Training accuracy')\n",
    "plt.plot(epochs, val, ':', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>0.565709</td>\n",
       "      <td>0.545</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.864824</td>\n",
       "      <td>1.616180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>0.552197</td>\n",
       "      <td>0.580</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.833601</td>\n",
       "      <td>1.711361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Stemming</th>\n",
       "      <td>0.595386</td>\n",
       "      <td>0.605</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.769638</td>\n",
       "      <td>1.533687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Lemmatization</th>\n",
       "      <td>0.575568</td>\n",
       "      <td>0.565</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.058595</td>\n",
       "      <td>2.242970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - GLoVe embedding</th>\n",
       "      <td>0.689370</td>\n",
       "      <td>0.620</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.257652</td>\n",
       "      <td>0.903061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - Own embedding</th>\n",
       "      <td>0.712241</td>\n",
       "      <td>0.655</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.925077</td>\n",
       "      <td>16.809226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.777450</td>\n",
       "      <td>0.705</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.750703</td>\n",
       "      <td>7.867042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      AUC  Accuracy  Epoch max reach  \\\n",
       "simple NN - raw text             0.565709     0.545             13.0   \n",
       "simple NN - Basic preprocessing  0.552197     0.580             14.0   \n",
       "simple NN - Stemming             0.595386     0.605             13.0   \n",
       "simple NN - Lemmatization        0.575568     0.565             11.0   \n",
       "simple NN - GLoVe embedding      0.689370     0.620             12.0   \n",
       "LSTM - Own embedding             0.712241     0.655             23.0   \n",
       "LSTM - GLoVe embedding           0.777450     0.705             16.0   \n",
       "\n",
       "                                 total training time  training time to opt  \n",
       "simple NN - raw text                        1.864824              1.616180  \n",
       "simple NN - Basic preprocessing             1.833601              1.711361  \n",
       "simple NN - Stemming                        1.769638              1.533687  \n",
       "simple NN - Lemmatization                   3.058595              2.242970  \n",
       "simple NN - GLoVe embedding                 2.257652              0.903061  \n",
       "LSTM - Own embedding                       21.925077             16.809226  \n",
       "LSTM - GLoVe embedding                     14.750703              7.867042  "
      ]
     },
     "execution_count": 455,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bi directional LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_36\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_27 (Embedding)     (None, 30, 100)           300400    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 128)               84480     \n",
      "_________________________________________________________________\n",
      "dense_61 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 385,009\n",
      "Trainable params: 84,609\n",
      "Non-trainable params: 300,400\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model_name = 'biLSTM - GLoVe embedding'\n",
    "\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(Bidirectional(LSTM(lstm_out,dropout=0.2)))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "model.compile(loss = 'binary_crossentropy', optimizer='adam',metrics = ['accuracy','AUC'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "1/1 [==============================] - 1s 1s/step - loss: 0.7278 - accuracy: 0.4863 - auc: 0.4318 - val_loss: 0.6932 - val_accuracy: 0.5300 - val_auc: 0.5595\n",
      "Epoch 2/30\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.7068 - accuracy: 0.4950 - auc: 0.4686 - val_loss: 0.6844 - val_accuracy: 0.5300 - val_auc: 0.5773\n",
      "Epoch 3/30\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.6966 - accuracy: 0.4787 - auc: 0.4968 - val_loss: 0.6812 - val_accuracy: 0.5500 - val_auc: 0.5782\n",
      "Epoch 4/30\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6936 - accuracy: 0.5063 - auc: 0.5157 - val_loss: 0.6807 - val_accuracy: 0.5600 - val_auc: 0.5875\n",
      "Epoch 5/30\n",
      "1/1 [==============================] - 0s 168ms/step - loss: 0.6897 - accuracy: 0.5300 - auc: 0.5569 - val_loss: 0.6803 - val_accuracy: 0.5600 - val_auc: 0.5944\n",
      "Epoch 6/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6873 - accuracy: 0.5400 - auc: 0.5773 - val_loss: 0.6787 - val_accuracy: 0.5650 - val_auc: 0.6071\n",
      "Epoch 7/30\n",
      "1/1 [==============================] - 0s 90ms/step - loss: 0.6834 - accuracy: 0.5450 - auc: 0.6057 - val_loss: 0.6759 - val_accuracy: 0.5750 - val_auc: 0.6184\n",
      "Epoch 8/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6798 - accuracy: 0.5487 - auc: 0.6210 - val_loss: 0.6724 - val_accuracy: 0.5750 - val_auc: 0.6296\n",
      "Epoch 9/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6759 - accuracy: 0.5487 - auc: 0.6398 - val_loss: 0.6690 - val_accuracy: 0.5700 - val_auc: 0.6476\n",
      "Epoch 10/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6698 - accuracy: 0.5838 - auc: 0.6635 - val_loss: 0.6660 - val_accuracy: 0.5800 - val_auc: 0.6662\n",
      "Epoch 11/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.6658 - accuracy: 0.6062 - auc: 0.6868 - val_loss: 0.6636 - val_accuracy: 0.6000 - val_auc: 0.6769\n",
      "Epoch 12/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6591 - accuracy: 0.6275 - auc: 0.7083 - val_loss: 0.6617 - val_accuracy: 0.6650 - val_auc: 0.6867\n",
      "Epoch 13/30\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.6567 - accuracy: 0.6562 - auc: 0.7180 - val_loss: 0.6601 - val_accuracy: 0.6600 - val_auc: 0.6928\n",
      "Epoch 14/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6505 - accuracy: 0.6762 - auc: 0.7394 - val_loss: 0.6583 - val_accuracy: 0.6350 - val_auc: 0.6956\n",
      "Epoch 15/30\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.6501 - accuracy: 0.6612 - auc: 0.7368 - val_loss: 0.6560 - val_accuracy: 0.6350 - val_auc: 0.7003\n",
      "Epoch 16/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6441 - accuracy: 0.6812 - auc: 0.7509 - val_loss: 0.6528 - val_accuracy: 0.6300 - val_auc: 0.7037\n",
      "Epoch 17/30\n",
      "1/1 [==============================] - 0s 75ms/step - loss: 0.6431 - accuracy: 0.6612 - auc: 0.7415 - val_loss: 0.6488 - val_accuracy: 0.6450 - val_auc: 0.7026\n",
      "Epoch 18/30\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6351 - accuracy: 0.6862 - auc: 0.7582 - val_loss: 0.6440 - val_accuracy: 0.6450 - val_auc: 0.7075\n",
      "Epoch 19/30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6287 - accuracy: 0.6963 - auc: 0.7607 - val_loss: 0.6391 - val_accuracy: 0.6600 - val_auc: 0.7078\n",
      "Epoch 20/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6243 - accuracy: 0.6888 - auc: 0.7598 - val_loss: 0.6341 - val_accuracy: 0.6500 - val_auc: 0.7099\n",
      "Epoch 21/30\n",
      "1/1 [==============================] - 0s 78ms/step - loss: 0.6151 - accuracy: 0.6875 - auc: 0.7697 - val_loss: 0.6288 - val_accuracy: 0.6600 - val_auc: 0.7136\n",
      "Epoch 22/30\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.6097 - accuracy: 0.6975 - auc: 0.7701 - val_loss: 0.6218 - val_accuracy: 0.6700 - val_auc: 0.7206\n",
      "Epoch 23/30\n",
      "1/1 [==============================] - 0s 69ms/step - loss: 0.5999 - accuracy: 0.6975 - auc: 0.7822 - val_loss: 0.6125 - val_accuracy: 0.6650 - val_auc: 0.7311\n",
      "Epoch 24/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5895 - accuracy: 0.7113 - auc: 0.7899 - val_loss: 0.6022 - val_accuracy: 0.6850 - val_auc: 0.7439\n",
      "Epoch 25/30\n",
      "1/1 [==============================] - 0s 76ms/step - loss: 0.5780 - accuracy: 0.7237 - auc: 0.7981 - val_loss: 0.5934 - val_accuracy: 0.6850 - val_auc: 0.7542\n",
      "Epoch 26/30\n",
      "1/1 [==============================] - 0s 72ms/step - loss: 0.5664 - accuracy: 0.7262 - auc: 0.7995 - val_loss: 0.5857 - val_accuracy: 0.6800 - val_auc: 0.7611\n",
      "Epoch 27/30\n",
      "1/1 [==============================] - 0s 73ms/step - loss: 0.5578 - accuracy: 0.7163 - auc: 0.7967 - val_loss: 0.5780 - val_accuracy: 0.6900 - val_auc: 0.7631\n",
      "Epoch 28/30\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.5554 - accuracy: 0.7125 - auc: 0.7907 - val_loss: 0.5785 - val_accuracy: 0.6900 - val_auc: 0.7633\n",
      "Epoch 29/30\n",
      "1/1 [==============================] - 0s 80ms/step - loss: 0.5508 - accuracy: 0.7113 - auc: 0.7932 - val_loss: 0.5828 - val_accuracy: 0.6850 - val_auc: 0.7646\n",
      "Epoch 30/30\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.5461 - accuracy: 0.7175 - auc: 0.7978 - val_loss: 0.5856 - val_accuracy: 0.6800 - val_auc: 0.7654\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test))\n",
    "stop = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances = models_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy': max(hist.history['val_accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_performances.to_excel('data/perf_1K.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 462,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set()\n",
    "acc = hist.history['accuracy']\n",
    "val = hist.history['val_accuracy']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, '-', label='Training accuracy')\n",
    "plt.plot(epochs, val, ':', label='Validation accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>simple NN - raw text</th>\n",
       "      <td>0.565709</td>\n",
       "      <td>0.545</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.864824</td>\n",
       "      <td>1.616180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Basic preprocessing</th>\n",
       "      <td>0.552197</td>\n",
       "      <td>0.580</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.833601</td>\n",
       "      <td>1.711361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Stemming</th>\n",
       "      <td>0.595386</td>\n",
       "      <td>0.605</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.769638</td>\n",
       "      <td>1.533687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - Lemmatization</th>\n",
       "      <td>0.575568</td>\n",
       "      <td>0.565</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.058595</td>\n",
       "      <td>2.242970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>simple NN - GLoVe embedding</th>\n",
       "      <td>0.689370</td>\n",
       "      <td>0.620</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.257652</td>\n",
       "      <td>0.903061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - Own embedding</th>\n",
       "      <td>0.712241</td>\n",
       "      <td>0.655</td>\n",
       "      <td>23.0</td>\n",
       "      <td>21.925077</td>\n",
       "      <td>16.809226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.777450</td>\n",
       "      <td>0.705</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.750703</td>\n",
       "      <td>7.867042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>biLSTM - GLoVe embedding</th>\n",
       "      <td>0.765389</td>\n",
       "      <td>0.690</td>\n",
       "      <td>26.0</td>\n",
       "      <td>27.761546</td>\n",
       "      <td>24.060006</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      AUC  Accuracy  Epoch max reach  \\\n",
       "simple NN - raw text             0.565709     0.545             13.0   \n",
       "simple NN - Basic preprocessing  0.552197     0.580             14.0   \n",
       "simple NN - Stemming             0.595386     0.605             13.0   \n",
       "simple NN - Lemmatization        0.575568     0.565             11.0   \n",
       "simple NN - GLoVe embedding      0.689370     0.620             12.0   \n",
       "LSTM - Own embedding             0.712241     0.655             23.0   \n",
       "LSTM - GLoVe embedding           0.777450     0.705             16.0   \n",
       "biLSTM - GLoVe embedding         0.765389     0.690             26.0   \n",
       "\n",
       "                                 total training time  training time to opt  \n",
       "simple NN - raw text                        1.864824              1.616180  \n",
       "simple NN - Basic preprocessing             1.833601              1.711361  \n",
       "simple NN - Stemming                        1.769638              1.533687  \n",
       "simple NN - Lemmatization                   3.058595              2.242970  \n",
       "simple NN - GLoVe embedding                 2.257652              0.903061  \n",
       "LSTM - Own embedding                       21.925077             16.809226  \n",
       "LSTM - GLoVe embedding                     14.750703              7.867042  \n",
       "biLSTM - GLoVe embedding                   27.761546             24.060006  "
      ]
     },
     "execution_count": 465,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will whoose LSTM+Glove as our best model based on accuracy and training time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of ressource limitation, we'll not perform a cross validation and gridsearch on hyperparameter, insted we'll just try different values and compare performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparamters_performances=pd.DataFrame(columns=['AUC','Accuracy_val','Epoch max reach'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "dp=0.2\n",
    "lr=0.01\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=dp))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy','AUC'])\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test),verbose=0)\n",
    "stop = time.time()\n",
    "\n",
    "hyperparamters_performances = hyperparamters_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "                    'dropout':dp,\n",
    "                    'learning_rate':lr,\n",
    "                    'lstm_out': lstm_out,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy_val': max(hist.history['val_accuracy']),\n",
    "              'Accuracy_test': max(hist.history['accuracy']), \n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "dp=0.2\n",
    "lr=0.1\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=dp))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy','AUC'])\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test),verbose=0)\n",
    "stop = time.time()\n",
    "\n",
    "hyperparamters_performances = hyperparamters_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "                    'dropout':dp,\n",
    "                    'learning_rate':lr,\n",
    "                    'lstm_out': lstm_out,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy_val': max(hist.history['val_accuracy']),\n",
    "              'Accuracy_test': max(hist.history['accuracy']),   \n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "dp=0.2\n",
    "lr=0.001\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=dp))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy','AUC'])\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test),verbose=0)\n",
    "stop = time.time()\n",
    "\n",
    "hyperparamters_performances = hyperparamters_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "                    'dropout':dp,\n",
    "                    'learning_rate':lr,\n",
    "                    'lstm_out': lstm_out,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy_val': max(hist.history['val_accuracy']),\n",
    "              'Accuracy_test': max(hist.history['accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy_val</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>lstm_out</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.882902</td>\n",
       "      <td>0.8012</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.861425</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64.0</td>\n",
       "      <td>674.858426</td>\n",
       "      <td>179.962247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.854841</td>\n",
       "      <td>0.7724</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.765700</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>64.0</td>\n",
       "      <td>788.314442</td>\n",
       "      <td>236.494333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.875561</td>\n",
       "      <td>0.7943</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.808200</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64.0</td>\n",
       "      <td>704.098147</td>\n",
       "      <td>610.218394</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             AUC  Accuracy_val  Epoch max reach  \\\n",
       "LSTM - GLoVe embedding  0.882902        0.8012              8.0   \n",
       "LSTM - GLoVe embedding  0.854841        0.7724              9.0   \n",
       "LSTM - GLoVe embedding  0.875561        0.7943             26.0   \n",
       "\n",
       "                        Accuracy_test  dropout  learning_rate  lstm_out  \\\n",
       "LSTM - GLoVe embedding       0.861425      0.2          0.010      64.0   \n",
       "LSTM - GLoVe embedding       0.765700      0.2          0.100      64.0   \n",
       "LSTM - GLoVe embedding       0.808200      0.2          0.001      64.0   \n",
       "\n",
       "                        total training time  training time to opt  \n",
       "LSTM - GLoVe embedding           674.858426            179.962247  \n",
       "LSTM - GLoVe embedding           788.314442            236.494333  \n",
       "LSTM - GLoVe embedding           704.098147            610.218394  "
      ]
     },
     "execution_count": 577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparamters_performances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drop out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "dp=0\n",
    "lr=0.01\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=dp))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy','AUC'])\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=60, validation_data=(X_test_vect, y_test),verbose=0)\n",
    "stop = time.time()\n",
    "\n",
    "hyperparamters_performances = hyperparamters_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "                    'dropout':dp,\n",
    "                    'learning_rate':lr,\n",
    "                    'lstm_out': lstm_out,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy_val': max(hist.history['val_accuracy']),\n",
    "              'Accuracy_test': max(hist.history['accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "dp=0.1\n",
    "lr=0.01\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=dp))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy','AUC'])\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test),verbose=0)\n",
    "stop = time.time()\n",
    "\n",
    "hyperparamters_performances = hyperparamters_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "                    'dropout':dp,\n",
    "                    'learning_rate':lr,\n",
    "                    'lstm_out': lstm_out,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy_val': max(hist.history['val_accuracy']),\n",
    "              'Accuracy_test': max(hist.history['accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "dp=0.4\n",
    "lr=0.01\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=dp))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy','AUC'])\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test),verbose=0)\n",
    "stop = time.time()\n",
    "\n",
    "hyperparamters_performances = hyperparamters_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "                    'dropout':dp,\n",
    "                    'learning_rate':lr,\n",
    "                    'lstm_out': lstm_out,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy_val': max(hist.history['val_accuracy']),\n",
    "              'Accuracy_test': max(hist.history['accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'LSTM - GLoVe embedding'\n",
    "dp=0.8\n",
    "lr=0.01\n",
    "lstm_out=64\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(Embedding(len(voc),100 ,input_length = tweet_length))\n",
    "model.add(embedding_layer)\n",
    "model.add(LSTM(lstm_out,dropout=dp))\n",
    "#model.add(Dense(8,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = keras.optimizers.Adam(learning_rate=lr)\n",
    "model.compile(loss = 'binary_crossentropy', optimizer=opt,metrics = ['accuracy','AUC'])\n",
    "\n",
    "start = time.time()\n",
    "hist = model.fit(X_train_vect, y_train, batch_size=1024, epochs=30, validation_data=(X_test_vect, y_test),verbose=0)\n",
    "stop = time.time()\n",
    "\n",
    "hyperparamters_performances = hyperparamters_performances.append(\n",
    "    pd.Series(data={'total training time': stop-start,\n",
    "                    'dropout':dp,\n",
    "                    'learning_rate':lr,\n",
    "                    'lstm_out': lstm_out,\n",
    "              'AUC': max(hist.history['val_auc']),\n",
    "              'Accuracy_val': max(hist.history['val_accuracy']),\n",
    "              'Accuracy_test': max(hist.history['accuracy']),\n",
    "              'Epoch max reach': hist.history['val_accuracy'].index(max(hist.history['val_accuracy'])),\n",
    "              'training time to opt' : (stop-start)*hist.history['val_accuracy'].index(max(hist.history['val_accuracy']))/len(hist.history['val_accuracy'])},\n",
    "              name=model_name)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy_val</th>\n",
       "      <th>Epoch max reach</th>\n",
       "      <th>Accuracy_test</th>\n",
       "      <th>dropout</th>\n",
       "      <th>learning_rate</th>\n",
       "      <th>lstm_out</th>\n",
       "      <th>total training time</th>\n",
       "      <th>training time to opt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.882902</td>\n",
       "      <td>0.8012</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.861425</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64.0</td>\n",
       "      <td>674.858426</td>\n",
       "      <td>179.962247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.854841</td>\n",
       "      <td>0.7724</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.765700</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.100</td>\n",
       "      <td>64.0</td>\n",
       "      <td>788.314442</td>\n",
       "      <td>236.494333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.875561</td>\n",
       "      <td>0.7943</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.808200</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.001</td>\n",
       "      <td>64.0</td>\n",
       "      <td>704.098147</td>\n",
       "      <td>610.218394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.875369</td>\n",
       "      <td>0.7991</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.980425</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1312.815621</td>\n",
       "      <td>131.281562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.881005</td>\n",
       "      <td>0.7987</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.898550</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64.0</td>\n",
       "      <td>692.509710</td>\n",
       "      <td>207.752913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.883288</td>\n",
       "      <td>0.8061</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.810675</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64.0</td>\n",
       "      <td>675.575953</td>\n",
       "      <td>630.537556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM - GLoVe embedding</th>\n",
       "      <td>0.850047</td>\n",
       "      <td>0.7701</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.708050</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.010</td>\n",
       "      <td>64.0</td>\n",
       "      <td>792.381678</td>\n",
       "      <td>739.556232</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             AUC  Accuracy_val  Epoch max reach  \\\n",
       "LSTM - GLoVe embedding  0.882902        0.8012              8.0   \n",
       "LSTM - GLoVe embedding  0.854841        0.7724              9.0   \n",
       "LSTM - GLoVe embedding  0.875561        0.7943             26.0   \n",
       "LSTM - GLoVe embedding  0.875369        0.7991              6.0   \n",
       "LSTM - GLoVe embedding  0.881005        0.7987              9.0   \n",
       "LSTM - GLoVe embedding  0.883288        0.8061             28.0   \n",
       "LSTM - GLoVe embedding  0.850047        0.7701             28.0   \n",
       "\n",
       "                        Accuracy_test  dropout  learning_rate  lstm_out  \\\n",
       "LSTM - GLoVe embedding       0.861425      0.2          0.010      64.0   \n",
       "LSTM - GLoVe embedding       0.765700      0.2          0.100      64.0   \n",
       "LSTM - GLoVe embedding       0.808200      0.2          0.001      64.0   \n",
       "LSTM - GLoVe embedding       0.980425      0.0          0.010      64.0   \n",
       "LSTM - GLoVe embedding       0.898550      0.1          0.010      64.0   \n",
       "LSTM - GLoVe embedding       0.810675      0.4          0.010      64.0   \n",
       "LSTM - GLoVe embedding       0.708050      0.8          0.010      64.0   \n",
       "\n",
       "                        total training time  training time to opt  \n",
       "LSTM - GLoVe embedding           674.858426            179.962247  \n",
       "LSTM - GLoVe embedding           788.314442            236.494333  \n",
       "LSTM - GLoVe embedding           704.098147            610.218394  \n",
       "LSTM - GLoVe embedding          1312.815621            131.281562  \n",
       "LSTM - GLoVe embedding           692.509710            207.752913  \n",
       "LSTM - GLoVe embedding           675.575953            630.537556  \n",
       "LSTM - GLoVe embedding           792.381678            739.556232  "
      ]
     },
     "execution_count": 582,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparamters_performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparamters_performances.to_excel('data/hyp_perf_50K.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "notify_time": "10",
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "285px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "408.767px",
    "left": "1625px",
    "right": "20px",
    "top": "120px",
    "width": "275px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
